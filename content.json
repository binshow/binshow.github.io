{"pages":[],"posts":[{"title":"JVM（三）类文件和类加载","text":"java跨平台的实现是基于JVM虚拟机的，编写的java源码，编译后会生成一种.class文件，称为字节码文件。 java虚拟机就是负责将字节码文件翻译成特定平台下的机器码然后运行。 为了保证Class文件在多个平台的通用性，java官方制定了严格的Class文件格式。 了解Class文件结构，有利于我们反编译 .class 文件或在程序编译期间修改字节码做代码注入。 Class文件结构Class文件中包含了Java虚拟机指令集、符号表以及若干其他辅助信息。 每一个 Class 文件对应于一个如下所示的 ClassFile 结构体： 12345678910111213141516171819ClassFile { u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count];}复制代码 简单看一下各项的含义： 由于 Class 文件结构没有任何分隔符，所以无论是每个数据项的的顺序还是数量，都是严格限定的，哪个字节代表什么含义，长度多少，先后顺序如何，都是不允许改变的 魔数将class文件用16进制打开的话 第一行中有一串特殊的字符 cafebabe，它就是一个魔数，是 JVM 识别 class 文件的标志，JVM 会在验证阶段检查 class 文件是否以该魔数开头，如果不是则会抛出 ClassFormatError。 版本号第 5 和第 6 个字节是次版本号（Minor Version），第 7 和第 8 个字节是主版本号（Major Version）。高版本的 JDK 能向下兼容以前版本的 Class 文件，但不能运行以后版本的 Class 文件，即使文件格式未发生变化。 常量池常量池中主要存放两大类常量：字面量（Literal）和符号引用（Symbolic References）。字面量比较接近于Java语言层面的常量概念，如文本字符串、被声明为final的常量值等。而符号引用则属于编译原理方面的概念，主要包括下面几类常量： 被模块导出或者开放的包（Package） 类和接口的全限定名（Fully Qualified Name） 字段的名称和描述符（Descriptor） 方法的名称和描述符 方法句柄和方法类型（Method Handle、Method Type、Invoke Dynamic） 动态调用点和动态常量（Dynamically-Computed Call Site、Dynamically-Computed Constant） 这17类常量结构只有一个相同之处，表结构起始的第一位是个u1类型的标志位（tag），代表着当前常量属于哪种常量类型。 17种常量类型所代表的具体含义如表所示： 类型 标志 描述 CONSTANT_Utf8_info 1 UTF-8 编码的字符串 CONSTANT_Integer_info 3 整型字面量 CONSTANT_Float_info 4 浮点型字面量 CONSTANT_Long_info 5 长整型型字面量 CONSTANT_Double_info 6 双精度浮点型字面量 CONSTANT_Class_info 7 类或接口的符号引用 CONSTANT_String_info 8 字符串类型字面量 CONSTANT_Fieldref_info 9 字段的符号引用 CONSTANT_Methodref_info 10 类中方法的符号引用 CONSTANT_InterfaceMethodref_info 11 接口中方法的符号引用 CONSTANT_NameAndType_info 12 字段或方法的部分符号引用 CONSTANT_MethodHandle_info 15 表示方法句柄 CONSTANT_MethodType_info 16 表示方法类型 CONSTANT_Dynamic_info 17 表示一个动态计算常量 CONSTANT_InvokeDynamic_info 18 表示一个动态方法调用点 CONSTANT_Moudle_info 19 表示一个模块 CONSTANT_Package_info 20 表示一个模块中开放或者导出的包 常量池非常繁琐，17种常量类型各自有着完全独立的数据结构，彼此之间没有什么共性和联系。 访问标志在常量池结束之后，紧接着的2个字节代表访问标志（access_flags），这个标志用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否被声明为final等等。 具体的标志位以及标志的含义如表： 标志名称 标志值 含义 ACC_PUBLIC 0x0001 是否为 Public 类型 ACC_FINAL 0x0010 是否被声明为 final，只有类可以设置 ACC_SUPER 0x0020 是否允许使用 invokespecial 字节码指令的新语义 ACC_INTERFACE 0x0200 标志这是一个接口 ACC_ABSTRACT 0x0400 是否为 abstract 类型，对于接口或者抽象类来说，次标志值为真，其他类型为假 ACC_SYNTHETIC 0x1000 标志这个类并非由用户代码产生 ACC_ANNOTATION 0x2000 标志这是一个注解 ACC_ENUM 0x4000 标志这是一个枚举 access_flags中一共有16个标志位可以使用，当前只定义了其中9个，没有使用到的标志位要求一 律为零。 类索引、父类索引、接口索引这三者用来确定类的继承关系。 类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名。由于Java语言不允许多重继承，所以父类索引只有一个，除了java.lang.Object之外，所有的Java类都有父类，因此除了 java.lang.Object外，所有Java类的父类索引都不为0。 接口索引集合就用来描述这个类实现了哪些接口，这些被实现的接口将按implements关键字（后的接口顺序从左到右排列在接口索引集合中。 字段表集合接口索引结束后，接着是字段表（field_info），它用于描述接口或者类中声明的变量——这里的字段（Field）只包括类级变量以及实例级变量，不包括在方法内部声明的局部变量。 描述的主要信息包括： ①、字段的作用域（public，protected，private修饰） ②、是类级变量还是实例级变量（static修饰） ③、是否可变（final修饰） ④、并发可见性（volatile修饰，是否强制从主从读写） ⑤、是否可序列化（transient修饰） ⑥、字段数据类型（8种基本数据类型，对象，数组等引用类型） ⑦、字段名称 字段表的结构如下： 类型 名称 数量 u2 access_flags 1 u2 name_index 1 u2 descriptor_index 1 u2 attributes_count 1 attribute_info attributes attributes_count access_flags是该字段的的访问标志，它和类中的访问标志很类似，用以描述该字段的权限类型：private、protected、public；并发可见性：volatile；可变性：final； 访问标志详情如下图所示： 由于Java语法规则的约束，ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED三个标志最多只能选择其一，ACC_FINAL、ACC_VOLATILE不能同时选择。接口之中的字段必须有ACC_PUBLIC、ACC_STATIC、ACC_FINAL标志。 方法表集合方法表的结构如同字段表一样，依次包括访问标志（access_flags）、名称索引（name_index）、描述符索引（descriptor_index）、属性表集合（attributes）几项，如表所示： 有区别的部分只有方法访问标志 access_flag, 因为volatile关键字和transient关键字不能修饰方法。 方法表标志位及其取值如下： 属性表集合接下来终于到了最后一项：属性表集合。 前面提到的Class文件、字段表、方法表都可以携带自己的属性表集合，就是引用的这里。 属性表集合中的属性如下所示： 与Class文件中其他的数据项目要求严格的顺序、长度和内容不同，属性表集合的限制宽松一些，不再要求各个属性表具有严格顺序，并且《Java虚拟机规范》允许只要不与已有属性名重复，任何人实现的编译器都可以向属性表中写入自己定义的属性信息，Java虚拟机运行时会忽略掉它不认识的属性。 举例查看12345public class Hello { public static void main(String[] args) { System.out.println(&quot;Hello World&quot;); }} 12javac Hello.java //javac 命令编译成 jvm 能识别的 class 文件xxd Hello.class //以 16 进制的方式查看这个 class 文件 16进制如下： 1234567891011121314151617181920212223242526272800000000: cafe babe 0000 0034 001d 0a00 0600 0f09 .......4........ //cafe babe为魔数00000010: 0010 0011 0800 120a 0013 0014 0700 1507 ................00000020: 0016 0100 063c 696e 6974 3e01 0003 2829 .....&lt;init&gt;...()00000030: 5601 0004 436f 6465 0100 0f4c 696e 654e V...Code...LineN00000040: 756d 6265 7254 6162 6c65 0100 046d 6169 umberTable...mai00000050: 6e01 0016 285b 4c6a 6176 612f 6c61 6e67 n...([Ljava/lang00000060: 2f53 7472 696e 673b 2956 0100 0a53 6f75 /String;)V...Sou00000070: 7263 6546 696c 6501 000a 4865 6c6c 6f2e rceFile...Hello.00000080: 6a61 7661 0c00 0700 0807 0017 0c00 1800 java............00000090: 1901 000b 4865 6c6c 6f20 576f 726c 6407 ....Hello World.000000a0: 001a 0c00 1b00 1c01 0021 636f 6d2f 7869 .........!com/xi000000b0: 6173 6d2f 6173 6d64 656d 6f2f 636c 6173 asm/asmdemo/clas000000c0: 7374 6573 742f 4865 6c6c 6f01 0010 6a61 stest/Hello...ja000000d0: 7661 2f6c 616e 672f 4f62 6a65 6374 0100 va/lang/Object..000000e0: 106a 6176 612f 6c61 6e67 2f53 7973 7465 .java/lang/Syste000000f0: 6d01 0003 6f75 7401 0015 4c6a 6176 612f m...out...Ljava/00000100: 696f 2f50 7269 6e74 5374 7265 616d 3b01 io/PrintStream;.00000110: 0013 6a61 7661 2f69 6f2f 5072 696e 7453 ..java/io/PrintS00000120: 7472 6561 6d01 0007 7072 696e 746c 6e01 tream...println.00000130: 0015 284c 6a61 7661 2f6c 616e 672f 5374 ..(Ljava/lang/St00000140: 7269 6e67 3b29 5600 2100 0500 0600 0000 ring;)V.!.......00000150: 0000 0200 0100 0700 0800 0100 0900 0000 ................00000160: 1d00 0100 0100 0000 052a b700 01b1 0000 .........*......00000170: 0001 000a 0000 0006 0001 0000 0003 0009 ................00000180: 000b 000c 0001 0009 0000 0025 0002 0001 ...........%....00000190: 0000 0009 b200 0212 03b6 0004 b100 0000 ................000001a0: 0100 0a00 0000 0a00 0200 0000 0500 0800 ................000001b0: 0600 0100 0d00 0000 0200 0e ........... 1javap -c xxx 是用来对class文件进行反编译 12345678910111213141516171819xiasmdeMacBook-Pro:test xiasm$ javap -c Hello警告: 二进制文件Hello包含com.xiasm.asmdemo.classtest.Hello1 Compiled from &quot;Hello.java&quot;2 public class com.xiasm.asmdemo.classtest.Hello {3 public com.xiasm.asmdemo.classtest.Hello();4 Code:5 0: aload_06 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V7 4: return89 public static void main(java.lang.String[]);10 Code:11 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream;12 3: ldc #3 // String Hello World13 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V14 8: return15 } 第5行：aload_x 操作码用来把 对象引用 加载到 操作数栈，非静态的函数都有第一个默认参数，那就是 this，这里的 aload_0 就是把 this 入栈 第6行：invokespecial #1 invokespecial指令调用实例初始化方法、私有方法、父类方法，#1 指的是常量池中的第一个，这里是方法引用java/lang/Object.””:()V，也即构造器函数 第7行：return，这个操作码属于 ireturn、lreturn、freturn、dreturn、areturn 和 return 操作码组中的一员，其中 i 表示 int，返回整数，同类的还有 l 表示 long，f 表示 float，d 表示 double，a 表示 对象引用。没有前缀类型字母的 return 表示返回 void 到此，构造器函数就结束了，接下来是 main 函数： 第11行：getstatic #2 getstatic获取指定类的静态域，并将其值压入栈顶，#2 代表常量池中的第 2 个，这里表示的是java/lang/System.out:Ljava/io/PrintStream;，其实就是java.lang.System 类的静态变量 out（类型是 PrintStream） 第12行：ldc #3 ldc表示将int, float或String型常量值从常量池中推送至栈顶，#3 代表常量池的第三个（字符串 Hello, World） 第13行：invokevirtual #4 invokevirutal 指令调用一个对象的实例方法，#4表示 PrintStream.println(String) 函数引用，并把栈顶两个元素出栈 类加载过程 加载就是把字节码文件从IO或内存加载到内存中的过程；初始化就是使用()进行类初始化的过程，这不同于调用构造函数；使用就是字面意思；卸载就是从方法区移除类型。 类加载过程加载 ①、通过一个类的全限定名来获取定义此类的二进制字节流。 ②、将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 ③、在Java堆中生成一个代表这个类的java.lang.Class对象，作为方法区这些数据的访问入口。 它是Java将字节码数据从不同的数据源读取到JVM中，并映射为JVM认可的数据结构（Class对象），这里的数据源可能是各种各样的形态，如jar文件、class文件，甚至是网络数据源等；如果输入数据不是ClassFile的结构，则会抛出ClassFormatError。 加载阶段是用户参与的阶段，我们可以自定义类加载器，去实现自己的类加载过程。 定义此类的二进制流的获取方式有多种： 1、从 ZIP 包中读取。这称为后面的 JAR、EAR、WAR 格式的基础。 2、从网络中获取。比较典型的应用就是 Applet。 3、运行时计算生成。这就是动态代理技术。 4、由其它文件生成。比如 JSP 应用。 5、从数据库中读取。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区中，然后在Java堆中实例化一个 java.lang.Class 类的对象，这个对象将作为程序访问方法区中这些类型数据的外部接口。 注意，加载阶段与连接阶段的部分内容（如一部分字节码文件的格式校验）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始了。 验证作用是为了确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 ①、文件格式验证 ②、元数据验证 ③、字节码验证 ④、符号引用验证 准备创建类或接口中的静态变量，并初始化静态变量的初始值。但这里的“初始化”和下面的显式初始化阶段是有区别的，侧重点在于分配所需要的内存空间，不会去执行更进一步的JVM指令。 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存是在方法区中进行分配。 注意： 一、上面说的是类变量，也就是被 static 修饰的变量，不包括实例变量。实例变量会在对象实例化时随着对象一起分配在堆中。 二、初始值，指的是一些数据类型的默认值。基本的数据类型初始值如下（引用类型的初始值为null）： 解析解析阶段是虚拟机将常量池中的符号引用替换为直接引用的过程。 符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义的定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标不一定已经加载到内存中。 直接引用（Direct References）：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机实现内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那么引用的目标必定已经在内存中存在。 解析动作主要针对类或接口、字段、类方法、接口方法四类符号引用，分别对应于常量池的 CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANTS_InterfaceMethodref_info四种类型常量。 初始化初始化阶段是执行类构造器() 方法的过程。 这一步真正去执行类初始化的代码逻辑，包括静态字段赋值的动作，以及执行类定义中的静态初始化块内的逻辑，编译器在编译阶段就会把这部分逻辑整理好，父类型的初始化逻辑优先于当前类型的逻辑。 ①、() 方法 是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块中可以赋值，但是不能访问。 比如如下代码会报错： 但是你把第 14 行代码放到 static 静态代码块的上面就不会报错了。或者不改变代码顺序，将第 11 行代码移除，也不会报错。 ②、() 方法与类的构造函数（或者说是实例构造器()方法）不同，它不需要显示的调用父类构造器，虚拟机会保证在子类的()方法执行之前，父类的()方法已经执行完毕。因此虚拟机中第一个被执行的()方法的类肯定是 java.lang.Object。 ③、由于父类的() 方法先执行，所以父类中定义的静态语句块要优先于子类的变量赋值操作。 ④、() 方法对于接口来说并不是必须的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成() 方法。 ⑤、接口中不能使用静态语句块，但仍然有变量初始化的赋值操作，因此接口与类一样都会生成() 方法。但接口与类不同的是，执行接口中的() 方法不需要先执行父接口的() 方法。只有当父接口中定义的变量被使用时，父接口才会被初始化。 ⑥、接口的实现类在初始化时也一样不会执行接口的() 方法。 ⑦、虚拟机会保证一个类的() 方法在多线程环境中被正确的加锁和同步。如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的() 方法，其他的线程都需要阻塞等待，直到活动线程执行() 方法完毕。如果在一个类的() 方法中有很耗时的操作，那么可能造成多个进程的阻塞。 比如对于如下代码： View Code 运行结果如下： 线程1抢到了执行() 方法，但是该方法是一个死循环，线程2将一直阻塞等待。 知道了类的初始化过程，那么类的初始化何时被触发呢？JVM大概规定了如下几种情况： ①、当虚拟机启动时，初始化用户指定的类。 ②、当遇到用以新建目标类实例的 new 指令时，初始化 new 指定的目标类。 ③、当遇到调用静态方法的指令时，初始化该静态方法所在的类。 ④、当遇到访问静态字段的指令时，初始化该静态字段所在的类。 ⑤、子类的初始化会触发父类的初始化。 ⑥、如果一个接口定义了 default 方法，那么直接实现或间接实现该接口的类的初始化，会触发该接口的初始化。 ⑦、使用反射 API 对某个类进行反射调用时，会初始化这个类。 ⑧、当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。 类加载器分类①、启动类加载器（Bootstrap ClassLoader） 负责将存放在 /lib 目录中的，或者被**-Xbootclasspath** 参数所指定的路径中的，并且是虚拟机按照文件名识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。**** 启动类加载器无法被Java程序直接引用。**** JDK 中的源码类大都是由启动类加载器加载，比如前面说的 java.lang.String，java.util.List等，需要注意的是，启动类 main Class 也是由启动类加载器加载。 ②、扩展类加载器（Extension ClassLoader） 这个类加载器由 sun.misc.Launcher$ExtClassLoader 实现，负责加载＜JAVA_HOME＞/lib/ext 目录中的，或者被 java.ext.dirs 系统变量所指定的路径中的所有类库。 开发者可以直接使用扩展类加载器。 ③、应用程序类加载器（Application ClassLoader） 由 sun.misc.Launcher$AppClassLoader 实现。由于这个类加载器是 ClassLoader.getSystemClassLoader() 方法的返回值，所以一般也称它为系统类加载器。 它负责加载用户类路径ClassPath上所指定的类库，开发者可以直接使用这个类加载器。如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 通常项目中自定义的类，都会放在类路径下，由应用程序类加载器加载。 ④、自定义类加载器（User ClassLoader） 这是由用户自己定义的类加载器，一般情况下我们不会自定义类加载器，但有些特殊情况，比如JDBC能够通过连接各种不同的数据库就是自定义类加载器来实现的，具体用处会在后文详细介绍。 双亲委派模型双亲委派机制就是如果一个类加载器收到了类加载请求，它首先不会自己尝试去加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有父类加载器反馈到无法完成这个加载请求（它的搜索范围没有找到这个类），子加载器才会尝试自己去加载。 12345678910111213/** * Create by YSOcean */public class ClassLoadTest { public static void main(String[] args) { ClassLoader classLoader1 = ClassLoadTest.class.getClassLoader(); ClassLoader classLoader2 = classLoader1.getParent(); ClassLoader classLoader3 = classLoader2.getParent(); System.out.println(classLoader1); System.out.println(classLoader2); System.out.println(classLoader3); }} 双亲委派机制有什么好处呢? 回到上面提出的问题，如果你自定义了一个 java.lang.String类，你会发现这个自定义的String.java可以正常编译，但是永远无法被加载运行。因为加载这个类的加载器，会一层一层的往上推，最终由启动类加载器来加载，而启动类加载的会是源码包下的String类，不是你自定义的String类。 实现源码： 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } 自定义类加载器先说说我们为什么要自定义类加载器？ ①、加密 我们知道Java字节码是可以进行反编译的，在某些安全性高的场景，是不允许这种情况发生的。那么我们可以将编译后的代码用某种加密算法进行加密，加密后的文件就不能再用常规的类加载器去加载类了。而我们自己可以自定义类加载器在加载的时候先解密，然后在加载。 ②、动态创建 比如很有名的动态代理。 ③、从非标准的来源加载代码 我们不用非要从class文件中获取定义此类的二进制流，还可以从数据库，从网络中，或者从zip包等。 明白了为什么要自定义类加载器，接下来我们再来详述如何自定义类加载器。 通过第 3 小节的 java.lang.ClassLoader 类的源码分析，类加载时根据双亲委派模型会先一层层找到父加载器，如果加载失败，则会调用当前加载器的 findClass() 方法来完成加载。因此我们自定义类加载器，有两个步骤： 1、继承 ClassLoader 2、覆写 findClass() 方法 破坏双亲委派模型的情况 重写 loadClass() 方法 逆向使用类加载器，引入线程上下文类加载器，如果 API 中的基础类想要调用用户的代码(JNDI/JDBC 等),此时双亲委派模型就不能完成.为了解决这个问题,java 设计团队只好 使用一个不优雅的设计方案:Thread 的上下文类加载器,默认就是应用程序的类加载器。 追求程序的动态性：代码热替换、模块热部署等技术，希望应用程序不用重启就可以加载最新的字节码文件.此时就需要破坏双亲委派模型 动态代理的实现对于一个普通的Java动态代理，其实现过程可以简化成为： 提供一个基础的接口，作为被调用类型（com.mycorp.HelloImpl）和代理类之间的统一入口，如com.mycorp.Hello。 实现InvocationHandler，对代理对象方法的调用，会被分派到其invoke方法来真正实现动作。 通过Proxy类，调用其newProxyInstance方法，生成一个实现了相应基础接口的代理类实例，可以看下面的方法签名。 123public satic Object newProxyInsance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) 我们分析一下，动态代码生成是具体发生在什么阶段呢？ 不错，就是在newProxyInstance生成代理类实例的时候。我选取了JDK自己采用的ASM作为示例，一起来看看用ASM实现的简要过程，请参考下面的示例代码片段。 第一步，生成对应的类，其实和我们去写Java代码很类似，只不过改为用ASM方法和指定参数，代替了我们书写的源码。 123456789101112131415161718ClassWriter cw = new ClassWriter(ClassWriter.COMPUTE_FRAMES);cw.visit(V1_8, // 指定Java版本ACC_PUBLIC, // 说明是public类型&quot;com/mycorp/HelloProxy&quot;, // 指定包和类的名称null, // 签名，null表示不是泛型&quot;java/lang/Object&quot;, // 指定父类new String[]{ &quot;com/mycorp/Hello&quot; }); // 指定需要实现的接口更进一步，我们可以按照需要为代理对象实例，生成需要的方法和逻辑。MethodVisitor mv = cw.visitMethod(ACC_PUBLIC, // 声明公共方法&quot;sayHello&quot;, // 方法名称&quot;()Ljava/lang/Object;&quot;, // 描述符null, // 签名，null表示不是泛型null); // 可能抛出的异常，如果有，则指定字符串数组mv.visitCode();// 省略代码逻辑实现细节cw.visitEnd(); // 结束类字节码生成 上面的代码虽然有些晦涩，但总体还是能多少理解其用意，不同的visitX方法提供了创建类型，创建各种方法等逻辑。ASM API，广泛的使用了Visitor模式，如果你熟悉这个模式， 就会知道它所针对的场景是将算法和对象结构解耦，非常适合字节码操纵的场合，因为我们大部分情况都是依赖于特定结构修改或者添加新的方法、变量或者类型等。 按照前面的分析，字节码操作最后大都应该是生成byte数组，ClassWriter提供了一个简便的方法。 cw.toByteArray(); 然后，就可以进入我们熟知的类加载过程了， 总结","link":"/2021/05/11/JVM%EF%BC%88%E4%B8%89%EF%BC%89%E7%B1%BB%E6%96%87%E4%BB%B6%E5%92%8C%E7%B1%BB%E5%8A%A0%E8%BD%BD/"},{"title":"JVM（二）垃圾回收和内存分配","text":"Java技术体系中所提倡的 自动内存管理 最终可以归结为自动化地解决了两个问题：给对象分配内存 以及 回收分配给对象的内存，而且这两个问题针对的内存区域就是Java内存模型中的 堆区 垃圾回收在Java的内存区域中： 程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随线程而灭，栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作，所以这几个区域的内存回收是确定的，随着方法结束或者线程结束，内存自然回收。 Java堆和方法区这两个区域则有着很显著的不确定性：一个接口的多个实现类需要的内存可能会不一样，一个方法所执行的不同条件分支所需要的内存也可能不一样，只有处于运行期间，我们才能知道程序究竟会创建哪些对象，创建多少个对象，这部分内存的分配和回收是动态的。垃圾收集器所关注的正是这部分内存该如何管理 如何判断是否是垃圾 引用计数法：在对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加一；当引用失效时，计数器值就减一；任何时刻计数器为零的对象就是不可能再被使用的。 需要额外的空间来存储计数器，以及繁琐的更新操作，引用计数法还有一个重大的漏洞，那便是无法处理循环引用对象。 12345678910111213141516public static void main(String[] args) { Person father = new Person(); Person son = new Person(); father.setSon(son); son.setFather(father); father = null; son = null; /** * 调用此方法表示希望进行一次垃圾回收。但是它不能保证垃圾回收一定会进行， * 而且具体什么时候进行是取决于具体的虚拟机的，不同的虚拟机有不同的对策。 */ System.gc();} 可达性分析算法:通过一系列名为“GC Roots” 的对象作为终点，当一个对象到GC Roots 之间无法通过引用到达时，便可以进行回收了。 在Java技术体系里面，固定可作为GC Roots的对象包括以下几种： 在虚拟机栈（栈帧中的本地变量表）中引用的对象在方法区中类静态属性引用的对象，譬如Java类的引用类型静态变量。在方法区中常量引用的对象，譬如字符串常量池（String Table）里的引用。在本地方法栈中JNI（即通常所说的Native方法）引用的对象。Java虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象（比如 NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器。所有被同步锁（synchronized关键字）持有的对象。反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。 Java中的引用分类Java中的引用有四种，分为强引用（Strongly Reference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）4种，这4种引用强度依次逐渐减弱。 强引用是最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，无论任何情况下，只要强引用关系还存在，垃圾收集器就永远不会回 收掉被引用的对象。 1Object obj =new Object(); 软引用是用来描述一些还有用，但非必须的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存， 才会抛出内存溢出异常。在JDK 1.2版之后提供了SoftReference类来实现软引用。 12345Object obj = new Object();ReferenceQueue queue = new ReferenceQueue();SoftReference reference = new SoftReference(obj, queue);//强引用对象滞空，保留软引用obj = null; 弱引用也是用来描述那些非必须对象，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生为止。当垃圾收集器开始工作，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK 1.2版之后提供了WeakReference类来实现弱引用。 12345Object obj = new Object();ReferenceQueue queue = new ReferenceQueue();WeakReference reference = new WeakReference(obj, queue);//强引用对象滞空，保留软引用obj = null; 虚引用也称为“幽灵引用”或者“幻影引用”，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知。在JDK 1.2版之后提供了PhantomReference类来实现虚引用。 12345Object obj = new Object();ReferenceQueue queue = new ReferenceQueue();PhantomReference reference = new PhantomReference(obj, queue);//强引用对象滞空，保留软引用obj = null; 分代收集理论它建立在两个分代假说之上： 弱分代假说（Weak Generational Hypothesis）：绝大多数对象都是朝生夕灭的。 强分代假说（Strong Generational Hypothesis）：熬过越多次垃圾收集过程的对象就越难以消亡。 就是把Java堆划分为**新生代 （Young Generation）**和**老年代（Old Generation）两个区域**，新生代存放存活时间短的对象，而每次回收后存活的少量对象，将会逐步晋升到老年代中存放。 堆有新生代和老年代两块区域组成，而新生代区域又分为三个部分，分别是 Eden,From Surivor,To Survivor ,比例是8:1:1。 新生代采用复制算法，每次使用一块Eden区和一块Survivor区，当进行垃圾回收时，将Eden和一块Survivor区域的所有存活对象复制到另一块Survivor区域，然后清理到刚存放对象的区域，依次循环。 老年代采用标记-清除或者标记-整理算法，根据使用的垃圾回收器来进行判断。 基于分代，产生了一些垃圾收集的类型划分： 部分收集（Partial GC）：指目标不是完整收集整个Java堆的垃圾收集，其中又分为： 新生代收集（Minor GC/Young GC）：指目标只是新生代的垃圾收集。 老年代收集（Major GC/Old GC）：指目标只是老年代的垃圾收集。目前只有CMS收集器会有单独收集老年代的行为。 混合收集（Mixed GC）：指目标是收集整个新生代以及部分老年代的垃圾收集。目前只有G1收集器会有这种行为。 整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集。 垃圾回收算法标记清除标记-清除（Mark-Sweep）算法分为两个阶段： 标记 : 标记出所有需要回收的对象 清除：回收所有被标记的对象 标记-清除算法比较基础，但是主要存在两个缺点： 执行效率不稳定，如果Java堆中包含大量对象，而且其中大部分是需要被回收的，这时必须进行大量标记和清除的动作，导致标记和清除两个过程的执行效率都随对象数量增长而降低。 内存空间的碎片化问题，标记、清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致当以后在程序运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 标记-清除算法主要用于老年代，因为老年代可回收的对象比较少。 复制标记-复制算法解决了标记-清除算法面对大量可回收对象时执行效率低的问题。 过程也比较简单：将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 这种算法存在一个明显的缺点：一部分空间没有使用，存在空间的浪费。 新生代垃圾收集主要采用这种算法，因为新生代的存活对象比较少，每次复制的只是少量的存活对象。 一般虚拟机的具体实现不会采用1:1的比例划分，以HotSpot为例，HotSpot虚拟机将内存分为一块较大的Eden空间和两块较小的 Survivor空间，每次分配内存只使用Eden和其中一块Survivor。发生垃圾搜集时，将Eden和Survivor中仍然存活的对象一次性复制到另外一块Survivor空间上，然后直接清理掉Eden和已用过的那块Survivor空间。默认Eden和Survivor的大小比例是8∶1。 标记整理为了降低内存的消耗，引入一种针对性的算法：标记-整理（Mark-Compact）算法。 其中的标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界以外的内存。 标记-整理算法主要用于老年代，在老年代这种大量对象存活的区域，移动对象是个很大的负担，而且这种对象移动操作必须全程暂停用户应用程序（Stop The World）才能进行。 垃圾处理器盘点 Serial收集器它是一个单线程工作的收集器，使用一个处理器或一条收集线程去完成垃圾收集工作。并且进行垃圾收集时，必须暂停其他所有工作线程，直到垃圾收集结束——这就是所谓的“Stop The World”。 Serial/Serial Old收集器的运行过程如图： ParNew收集器ParNew收集器实质上是Serial收集器的多线程并行版本，使用多条线程进行垃圾收集。 ParNew收集器的工作过程如图所示： Parallel Scavenge收集器Parallel Scavenge收集器是一款新生代收集器，基于标记-复制算法实现，也能够并行收集。和ParNew有些类似，但Parallel Scavenge主要关注的是垃圾收集的吞吐量。 所谓吞吐量指的是运行用户代码的时间与处理器总消耗时间的比值。这个比例越高，证明垃圾收集占整个程序运行的比例越小。 Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量: -XX：MaxGCPauseMillis，最大垃圾回收停顿时间。这个参数的原理是空间换时间，收集器会控制新生代的区域大小，从而尽可能保证回收少于这个最大停顿时间。简单的说就是回收的区域越小，那么耗费的时间也越小。 所以这个参数并不是设置得越小越好。设太小的话，新生代空间会太小，从而更频繁的触发GC。 -XX：GCTimeRatio，垃圾收集时间与总时间占比。这个是吞吐量的倒数，原理和MaxGCPauseMillis相同。 由于与吞吐量关系密切，Parallel Scavenge收集器也经常被称作“吞吐量优先收集器”。 Serial Old收集器Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记-整理算法。 Parallel Old收集器Parallel Old是Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于标记-整理算法实现。 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，同样是老年代的收集齐，采用标记-清除算法。 垃圾收集器： 初始标记（CMS initial mark）：单线程运行，需要Stop The World，标记GC Roots能直达的对象。 并发标记（（CMS concurrent mark）：无停顿，和用户线程同时运行，从GC Roots直达对象开始遍历整个对象图。 重新标记（CMS remark）：多线程运行，需要Stop The World，标记并发标记阶段产生对象。 并发清除（CMS concurrent sweep）：无停顿，和用户线程同时运行，清理掉标记阶段标记的死亡的对象。 Concurrent Mark Sweep收集器运行示意图如下： 优点：CMS最主要的优点在名字上已经体现出来——并发收集、低停顿。 缺点：CMS同样有三个明显的缺点。 Mark Sweep算法会导致内存碎片比较多 CMS的并发能力比较依赖于CPU资源，并发回收时垃圾收集线程可能会抢占用户线程的资源，导致用户程序性能下降。 并发清除阶段，用户线程依然在运行，会产生所谓的“浮动垃圾”（Floating Garbage），本次垃圾收集无法处理浮动垃圾，必须到下一次垃圾收集才能处理。如果浮动垃圾太多，会触发新的垃圾回收，导致性能降低。 Garbage First收集器G1把连续的Java堆划分为多个大小相等的独立区域（Region），每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间。收集器能够对扮演不同角色的Region采用不同的策略去处理。 这样就避免了收集整个堆，而是按照若干个Region集进行收集，同时维护一个优先级列表，跟踪各个Region回收的价值，优先收集价值高的Region。 G1收集器的运行过程大致可划分为以下四个步骤： 初始标记（initial mark），标记了从GC Root开始直接关联可达的对象。STW（Stop the World）执行。 并发标记（concurrent marking），和用户线程并发执行，从GC Root开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象、 最终标记（Remark），STW，标记再并发标记过程中产生的垃圾。 筛选回收（Live Data Counting And Evacuation），制定回收计划，选择多个Region 构成回收集，把回收集中Region的存活对象复制到空的Region中，再清理掉整个旧 Region的全部空间。需要STW。 相比CMS，G1的优点有很多，可以指定最大停顿时间、分Region的内存布局、按收益动态确定回收集。 只从内存的角度来看，与CMS的“标记-清除”算法不同，G1从整体来看是基于“标记-整理”算法实现的收集器，但从局部（两个Region 之间）上看又是基于“标记-复制”算法实现，无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，垃圾收集完成之后能提供规整的可用内存。 内存分配原则MinorGC/MajorGC/FullGC的区别 ①、Minor GC 也叫Young GC，指的是新生代 GC，发生在新生代（Eden区和Survivor区）的垃圾回收。因为Java对象大多是朝生夕死的，所以 Minor GC 通常很频繁，一般回收速度也很快。 ②、Major GC 也叫Old GC，指的是老年代的 GC，发生在老年代的垃圾回收，该区域的对象存活时间比较长，通常来讲，发生 Major GC时，会伴随着一次 Minor GC，而 Major GC 的速度一般会比 Minor GC 慢10倍。 ③、Full GC 指的是全区域（整个堆）的垃圾回收，通常来说和 Major GC 是等价的。 内存溢出和内存泄漏的区别 内存溢出（Out Of Memory） ：就是申请内存时，JVM没有足够的内存空间。通俗说法就是去蹲坑发现坑位满了。 内存泄露 （Memory Leak）：就是申请了内存，但是没有释放，导致内存空间浪费。通俗说法就是有人占着茅坑不拉屎。 内存分配的5个策略 对象优先在Eden区分配，当 Eden 区没有足够的空间进行分配时，虚拟机将会发起一次 Minor GC(新生代GC)。 大对象直接分配在老年代，比较典型的就是那种很长的字符串以及数组。 长期存活的对象将进入老年代，新生代对象每熬过一次 Minor GC，年龄就增加1，当它的年龄增加到一定阈值时（默认是15岁），就会被晋升到老年代中。 新生代Survivor 区相同年龄所有对象之和大于 Survivor 所有对象之和的一半，大于等于该年龄的对象进入老年代 空间分配担保原则： 新生代内存分为一块 Eden区，和两块 Survivor 区域，当发生一次 Minor GC时，虚拟机会将Eden和一块Survivor区域的所有存活对象复制到另一块Survivor区域，通常情况下，Java对象朝生夕死，一块 Survivor 区域是能够存放GC后剩余的对象的，但是极端情况下，GC后仍然有大量存活的对象，那么一块 Survivor 区域就会存放不下这么多的对象，那么这时候就需要老年代进行分配担保，让无法放入 Survivor 区域的对象直接进入到老年代，当然前提是老年代还有空间能够存放这些对象。但是实际情况是在完成GC之前，是不知道还有多少对象能够存活下来的，所以老年代也无法确认是否能够存放GC后新生代转移过来的对象，那么这该怎么办呢? 前面我们介绍的都是Minor GC,那么何时会发生 Full GC？ 在发生 Minor GC 时，虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间，如果大于，则改为 Full GC。如果小于，则查看 HandlePromotionFailure 设置是否允许担保失败，如果允许，那只会进行一次 Minor GC，如果不允许，则也要进行一次 Full GC。 1-XX:-HandlePromotionFailure 回到第一个问题，老年代也无法确认是否能够存放GC后新生代转移过来的对象，那么这该怎么办呢? 也就是取之前每一次回收晋升到老年代对象容量的平均大小作为经验值，然后与老年代剩余空间进行比较，来决定是否进行 Full GC，从而让老年代腾出更多的空间。 通常情况下，我们会将 HandlePromotionFaile 设置为允许担保失败，这样能够避免频繁的发生 Full GC。 总结​","link":"/2021/05/10/JVM%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/"},{"title":"JVM（一）内存区域和对象详解","text":"Java是一门可以跨平台的语言，主要就是通过Java虚拟机来实现的: 编译器将Java文件编译为Java字节码文件（.class），接下来JVM对字节码文件进行解释，翻译成特定底层平台匹配的机器指令(win/linux/mac)并运行。 Java内存区域Java虚拟机定义了若干程序运行时的数据区，分为线程私有和公有的: 运行时数据区程序计数器程序计数器（Program Counter Register）也被称为PC寄存器，是一块较小的内存空间。 可以看作是当前线程所执行的字节码的行号指示器，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 线程私有的，在任意时刻，一条 Java 虚拟机线程只会执行一个方法的代码，这个正在被线程执行的方法称为该线程的当前方法。 程序计数器是唯一一个在虚拟机规范中没有规定OutOfMemoryError的区域 虚拟机栈Java虚拟机栈（Java Virtual Machine Stack）也是线程私有的，它的生命周期与线程相同。 每个方法被执行的时候，Java虚拟机都会同步创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息。每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种Java虚拟机基本数据类型（boolean、byte、char、short、int、 float、long、double）、对象引用（reference类型，它并不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress 类型（指向了一条字节码指令的地址）。 这些数据类型在局部变量表中的存储空间以局部变量槽（Slot）来表示，其中64位长度的long和 double类型的数据会占用两个变量槽，其余的数据类型只占用一个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定 的，在方法运行期间不会改变局部变量表的大小。 虚拟机栈会发生以下两种异常： 如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量时，Java 虚拟机将会抛出一个 StackOverflowError 异常。 如果 Java 虚拟机栈可以动态扩展，并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成扩展，或者在建立新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个 OutOfMemoryError 异常。 本地方法栈地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别只是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的本地（Native）方法服务。 会发生的异常和虚拟机栈相同 Java堆Java堆（Java Heap）是虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，Java里“几乎”所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的内存区域，因此一些资料中它也被称作“GC堆”（Garbage Collected Heap，）。从回收内存的角度看，由于现代垃圾收集器大部分都是基于分代收集理论设计的，所以Java堆中经常会出现“新生代”“老年代”“永久代”“Eden空间”“From Survivor空间”“To Survivor空间”等名词，需要注意的是这些区域划分仅仅是一部分垃圾收集器的共同特性或者说设计风格而已，而非某个Java虚拟机具体实现的固有内存布局，更不是《Java虚拟机规范》里对Java堆的进一步细致划分。 如果从分配内存的角度看，所有线程共享的Java堆中可以划分出多个线程私有的分配缓冲区 （Thread Local Allocation Buffer，TLAB），以提升对象分配时的效率。不过无论从什么角度，无论如何划分，都不会改变Java堆中存储内容的共性，无论是哪个区域，存储的都只能是对象的实例，将Java 堆细分的目的只是为了更好地回收内存，或者更快地分配内存。 方法区方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。 这区域的内存回收目标主要是针对常量池的回收和对类型的卸载 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池表（Constant Pool Table），用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 Class文件经过类加载器加载后，之前Class文件常量池的内容会存放到方法区的运行时常量池，需要注意的是Class文件常量池的符号引用会转变直接引用存入运行时常量池。 运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量 一定只有编译期才能产生，也就是说，并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可以将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。 直接内存在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区 （Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的 DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了 在Java堆和Native堆中来回复制数据。 JDK的内存演变 JDK1.6时期和我们上面讲的JVM内存区域是一致的： JDK1.7时发生了一些变化，将字符串常量池、静态变量，存放在堆上 在JDK1.8时彻底干掉了方法区，而在直接内存中划出一块区域作为元空间，运行时常量池、类常量池都移动到元空间。 思考一下，为什么使用元空间替换永久代？ 表面上看是为了避免OOM异常。因为通常使用PermSize和MaxPermSize设置永久代的大小就决定了永久代的上限，但是不是总能知道应该设置为多大合适, 如果使用默认值很容易遇到OOM错误。 当使用元空间时，可以加载多少类的元数据就不再由MaxPermSize控制, 而由系统的实际可用空间来控制。 更深层的原因还是要合并HotSpot和JRockit的代码，JRockit从来没有所谓的永久代，也不需要开发运维人员设置永久代的大小，但是运行良好。同时也不用担心运行性能问题了,在覆盖到的测试中, 程序启动和运行速度降低不超过1%，但是这点性能损失换来了更大的安全保障。 哪些地方会发生OOM 堆内存不足是最常见的OOM原因之一，抛出的错误信息是“java.lang.OutOfMemoryError:Java heap space”，原因可能千奇百怪，例如，可能存在内存泄漏问题；也很有可能就是堆的大小不合理，比如我们要处理比较可观的数据量，但是没有显式指定JVM堆大小或者指定数值偏小；或者出现JVM处理引用不及时，导致堆积起来，内存无法释放等。 对于Java虚拟机栈和本地方法栈，这里要稍微复杂一点。如果我们写一段程序不断的进行递归调用，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM实际会抛出StackOverFlowError；当然，如果JVM试图去扩展栈空间的的时候失败，则会抛出OutOfMemoryError。 对于老版本的Oracle JDK，因为永久代的大小是有限的，并且JVM对永久代垃圾回收（如，常量池回收、卸载不再需要的类型）非常不积极，所以当我们不断添加新类型的时候，永久代出现OutOfMemoryError也非常多见，尤其是在运行时存在大量动态类型生成的场合；类似Intern字符串缓存占用太多空间，也会导致OOM问题。对应的异常信息，会标记出来和永久代相关：“java.lang.OutOfMemoryError: PermGen space”。随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的OOM有所改观，出现OOM，异常信息则变成了：“java.lang.OutOfMemoryError: Metaspace”。 直接内存不足，也会导致OOM。 对象的创建都是在堆上吗我注意到有一些观点，认为通过逃逸分析，JVM会在栈上分配那些不会逃逸的对象，这在理论上是可行的，但是取决于JVM设计者的选择。据我所知，Oracle Hotspot JVM中并未这么做，这一点在逃逸分析相关的文档里已经说明，所以可以明确所有的对象实例都是创建在堆上。 目前很多书籍还是基于JDK 7以前的版本，JDK已经发生了很大变化，Intern字符串的缓存和静态变量曾经都被分配在永久代上，而永久代已经被元数据区取代。但是，Intern字符串缓存和静态变量并不是被转移到元数据区，而是直接在堆上分配，所以这一点同样符合前面一点的结论：对象实例都是分配在堆上。 字符串常量池的底层原理字符串常量池是全局的，JVM 中独此一份，因此也称为全局字符串常量池，在 jdk1.7（含）之后是在堆内存之中，存储的是字符串对象的引用，字符串实例是在堆中； 在HotSpot VM里实现线程池功能的是一个StringTable类，它是一个Hash表，默认值大小长度是1009；这个StringTable在每个HotSpot VM的实例只有一份，被所有的类共享。字符串常量由一个一个字符组成，放在了StringTable上。 12345678String str1 = &quot;图解Java&quot;; //先到常量池中查询有没有`&quot;图解Java&quot;`字符串的引用，如果没有，则会在`Java堆`上创建`&quot;图解Java&quot;`字符串，在常量池中存储字符串的地址，`str1`则指向字符串常量池的地址String str2 = new String(&quot;图解Java&quot;);//直接在Java堆中创建对象。`str2`指向堆中的地址。System.out.println(str1 == str2); //falseString str3 = &quot;图解Java&quot;; //str3发现字符串常量池中已经有了`&quot;图解Java&quot;`字符串的引用，则直接返回，不会创建新的对象System.out.println(str1 == str3); //true JVM中除了字符串常量池，8种基本数据类型中除了两种浮点类型剩余的6种基本数据类型的包装类，都使用了缓冲池技术，但是 Byte、Short、Integer、Long、Character 这5种整型的包装类也只是在对应值在 [-128,127] 时才会使用缓冲池，超出此范围仍然会去创建新的对象。 Java对象详解创建对象的4种方式 new 关键字： 在方法区的常量池中查看是否有new 后面参数（也就是类名）的符号引用，并检查是否有类的加载信息也就是是否被加载解析和初始化过。如果已经加载过了就不在加载，否则执行类的加载全过程。 给实例分配内存：此内存中存放对象自己的实例变量和从父类继承过来的实例变量（即使这些从超类继承过来的实例变量有可能被隐藏也会被分配空间），同时这些实例变量被赋予默认值（零值）； 调用构造函数，初始化成员字段：在Java对象初始化过程中，主要涉及三种执行对象初始化的结构，分别是实例变量初始化、实例代码块初始化以及构造函数初始化； user对象指向分配的内存空间： 注意：new操作不是原子操作，b和c的顺序可能会调换。 clone方法创建对象： 要想让一个对象支持clone，必须让这个对象对应的类实现Cloneable接口（标识接口），同时此类中也要重写clone方法 clone()方法是属于Object类的，clone是在堆内存中用二进制的方式进行拷贝，重新分配给对象一块内存 反射创建对象： 获取类的Class对象实例 1234获取方式如下：Class.forName(&quot;类全路径&quot;);类名.class; 如：Animal.class;对象名.getClass(); 通过反射创建类对象的实例对象 1Class.newInstance()：调用无参的构造方法，必需确保类中有无参数的可见的构造函数，否则将会抛出异常； 强制转换成用户所需类型 Java 反射机制是指在程序运行时，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性。这种动态的获取信息以及动态调用对象的方法的功能称为java 的反射机制。 反射机制很重要的一点就是“运行时”，其使得我们可以在程序运行时加载、探索以及使用编译期间完全未知的 .class 文件。换句话说，Java 程序可以加载一个运行时才得知名称的 .class 文件，然后获悉其完整构造，并生成其对象实体、或对其 fields（变量）设值、或调用其 methods（方法） 反序列化创建对象 Java中要序列化的类必须实现Serializable接口； 所有可在网络上传输的对象都必须是可序列化的；如RMI（remote method invoke，即远程方法调用），传入的参数或返回的对象都是可序列化的，否则会出错； 所有需要保存到磁盘的java对象都必须是可序列化的；通常建议：程序创建的每个JavaBean类都实现Serializeable接口； New对象创建过程我们以虚拟机遇到一个new指令开始： 首先检查这个指令的参数是否能在常量池中定位到一个类的符号引用 检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，就先执行相应的类加载过程 类加载检查通过后，接下来虚拟机将为新生对象分配内存。 内存分配有两种方式，指针碰撞（Bump The Pointer）、空闲列表（Free List） 指针碰撞：假设Java堆中内存是绝对规整的，所有被使用过的内存都被放在一边，空闲的内存被放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间方向挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞” 如果Java堆中的内存并不是规整的，已被使用的内存和空闲的内存相互交错在一起，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表” 两种方式的选择由Java堆是否规整决定 Java堆规整由所采用的垃圾收集器是否带有空间压缩整理（Compact）的能力决定 内存分配完成之后，虚拟机将分配到的内存空间（但不包括对象头）都初始化为零值。 设置对象头，请求头里包含了对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。 从虚拟机角度来看，设置完对象头信息以后初始化就已经完成了，但是对于Java程序而言，new指令之后会接着执行 ()方法，对对象进行初始化，这样一个真正可用的对象才算完全被构造出来。 分配对象内存的时候如何保证线程安全分配内存线程安全问题：对象创建在虚拟机中是非常频繁的行为，即使仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。 线程安全问题有两种解可选方案： 一种是对分配内存空间的动作进行同步处理——实际上虚拟机是采用CAS配上失败重试的方式保证更新操作的原子性 另外一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer，TLAB），哪个线程要分配内存，就在哪个线程的本地缓冲区中分配，只有本地缓冲区用完了，分配新的缓存区时才需要同步锁定。 对象的内存布局在HotSpot虚拟机里，对象在堆内存中的存储布局可以划分为三个部分：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding） 在64位的HotSpot虚拟机中，如对象未被同步锁锁定的状态下，Mark Word的64个比特存储空间中的31个比特用于存储对象哈希码，4个比特用于存储对象分代年龄，2个比特用于存储锁标志位，在其他状态（轻量级锁、重量级锁、偏向锁）下对象的存储内容变化如图示。 对象头的另外一部分是类型指针，即对象指向它的类型元数据的指针，Java虚拟机通过这个指针来确定该对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，查找对象的元数据信息并不一定要经过对象本身， 如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是如果数组的长度是不确定的，将无法通过元数据中的信息推断出数组的大小。 对象的访问定位Java程序会通过栈上的reference数据来操作堆上的具体对象。由于reference类型在《Java虚拟机规范》里面只规定了它是一个指向对象的引用，并没有定义这个引用应该通过什么方式去定位、访问到堆中对象的具体位置，所以对象访问方式也是由虚拟机实现而定的，主流的访问方式主要有使用句柄和直接指针两种： 如果使用句柄访问的话，Java堆中将可能会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自具体的地址信息，其结构如图所示： 如果使用直接指针访问的话，Java堆中对象的内存布局就必须考虑如何放置访问类型数据的相关信息，reference中存储的直接就是对象地址，如果只是访问对象本身的话，就不需要多一次间接访问的开销，如图所示： 这两种对象访问方式各有优势，使用句柄来访问的最大好处就是reference中存储的是稳定句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要被修改。 使用直接指针来访问最大的好处就是速度更快，它节省了一次指针定位的时间开销，由于对象访问在Java中非常频繁，因此这类开销积少成多也是一项极为可观的执行成本。 HotSpot虚拟机主要使用直接指针来进行对象访问。 总结：","link":"/2021/05/10/JVM%EF%BC%88%E4%B8%80%EF%BC%89%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%92%8C%E5%AF%B9%E8%B1%A1%E8%AF%A6%E8%A7%A3/"},{"title":"Java并发理论基础-上","text":"并发编程领域可以抽象成三个核心问题：分配任务、相互协作和互斥： 分配任务：将一个大的任务交给不同的进程/线程来做 相互协作：线程间的协作，比如一个线程执行完了一个任务，如何通知执行后续任务的线程开工 互斥：要实现在同一时刻内只有一个线程访问共享变量 第一部分、并发编程的发展1. 并发编程问题的由来随着CPU 、 内存 、IO设备的不断发展，三者的速度差异一直是存在的（CPU一天 ， 内存一年 ， IO设备十年） 为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为： CPU 增加了缓存，以均衡与内存的速度差异； 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异； 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用 1.1 缓存导致的可见性问题 一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为可见性。 单核时代，电脑只有1个CPU，所有的线程操作的是同一个CPU的缓存，也就不存在可见性问题。 多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存，如下图 1.2 线程切换带来的原子性问题 一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性 在一个时间片内，如果一个进程进行一个 IO 操作，例如读个文件，这个时候该进程可以把自己标记为“休眠状态”并出让 CPU 的使用权，待文件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得 CPU 的使用权了。 早期的操作系统基于进程来调度 CPU，不同进程间是不共享内存空间的，所以进程要做任务切换就要切换内存映射地址，而一个进程创建的所有线程，都是共享一个内存空间的，所以线程做任务切换成本就很低了。现代的操作系统都基于更轻量的线程来调度，现在我们提到的“任务切换”都是指“线程切换”。 Java 并发程序都是基于多线程的，自然也会涉及到任务切换，也许你想不到，任务切换竟然也是并发编程里诡异 Bug 的源头之一。任务切换的时机大多数是在时间片结束的时候，我们现在基本都使用高级语言编程，高级语言里一条语句往往需要多条 CPU 指令完成，例如上面代码中的count += 1，至少需要三条 CPU 指令。 指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器； 指令 2：之后，在寄存器中执行 +1 操作； 指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存） 1.3 编译优化带来的有序性问题有序性指的是程序按照代码的先后顺序执行。编译器为了优化性能，有时候会进行指令重排序。 重排序分3种类型。 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术(Instruction-Level Parallelism，ILP)来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应 机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上 去可能是在乱序执行 例如程序中：“a=6；b=7；”编译器优化后可能变成“b=7；a=6；”，在这个例子中，编译器调整了语句的顺序，但是不影响程序的最终结果，但是有时会出现问题。 比如单例模式中的双重检验模式： 1234567891011121314public class Singleton { static Singleton instance; public Singleton getInstance(){ if (instance == null){ synchronized (Singleton.class){ if (instance == null) instance = new Singleton(); //在CPU指令上并不是一步操作 } } return instance; }} new一个新的对象分为如下几步（先在内存中初始化对象再赋值给变量）： 分配一块内存 M； 在内存 M 上初始化 Singleton 对象； 然后 M 的地址赋值给 instance 变量。 经过指令重排序变成了下面这种情况（先将内存赋值给变量再进行初始化）： 分配一块内存 M； 将 M 的地址赋值给 instance 变量； 最后在内存 M 上初始化 Singleton 对象。 不安全的情况：假设线程 A 先执行 getInstance() 方法，当执行完指令 2 时恰好发生了线程切换，切换到了线程 B 上；如果此时线程 B 也执行 getInstance() 方法，那么线程 B 在执行第一个判断时会发现 instance != null ，所以直接返回 instance，而此时的 instance 是没有初始化过的，如果我们这个时候访问 instance 的成员变量就可能触发空指针异常。 2. 并发编程面临的挑战并发编程的目的是为了让程序运行得更快，但是，并不是启动更多的线程就能让程序最大限度地并发执行。 2.1上下文切换所谓的多线程并发执行是通过CPU给每个线程分配CPU时间片来实现的，因为时间片非常短（一般是几十毫秒ms），所以CPU通过不停地切 换线程执行，让我们感觉多个线程是同时执行的。 上下文切换是指：当前任务执行完一个时间片后需要切换到下一个任务，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这 个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换 多线程一定快吗？不一定，因为线程有创建和上下文切换的开销。 如何减少上下文切换： 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一 些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。 CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。 协程:在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。 2.2 死锁及避免办法 避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。 3. 什么是线程安全？线程安全需要保证几个基本特性： 原子性，简单说就是相关操作不会中途被其他线程干扰，一般通过同步机制实现。 可见性，是一个线程修改了某个共享变量，其状态能够立即被其他线程知晓，通常被解释为将线程本地状态反映到主内存上，volatile就是负责保证可见性的。 有序性，是保证线程内串行语义，避免指令重排等。 第二部分、Java中如何实现并发安全由上一部分可知：解决可见性、有序性最直接的办法就是禁用缓存和编译优化，但是性能上会带来问题。因此需要做到按需禁用。站在程序员的视角看就是 Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括 volatile、synchronized 和 final 三个关键字，以及六项 Happens-Before 规则， 1. volatile保证可见性volatile是轻量级的 synchronized，它在多处理器开发中保证了共享变量的“可见性”,不会引起线程上下文的切换和调度。 1volatile int x = 0; //告诉编译器，对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入 1.1 如何实现的可见性有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码: 0x01a3de1d: movb 0×0,0×1104800(0×0,0×1104800(%esi); 0x01a3de24: lock addl 0×0,0×1104800(0×0,(%esp); Lock前缀的指令： 1)将当前处理器缓存行的数据写回到系统内存。 2)这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存(L1，L2或其他)后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的 变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据 写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操 作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一 致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当 处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状 态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存 里。 1.2 volatile的使用优化追加64字节能够提高并发编程的效率？ 处理器的L1、L2或L3缓存的高速缓存行是64个字节宽，如果队列的头节点和尾节点都不足64字节的话，处理器会将 它们都读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头、尾节点，当一 个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致 其他处理器不能访问自己高速缓存中的尾节点，而队列的入队和出队操作则需要不停修改头 节点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率。Doug lea使 用追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存 行，使头、尾节点在修改时不会互相锁定。 2. synchronized保证原子性2.1 应用方法·对于普通同步方法，锁是当前实例对象。 ·对于静态同步方法，锁是当前类的Class对象。 ·对于同步方法块，锁是Synchonized括号里配置的对象。 123456789101112131415161718class X { // 修饰非静态方法,锁定的是当前实例对象 this synchronized void foo() { // 临界区 } // 修饰静态方法,锁定的是当前类的 Class 对象 synchronized static void bar() { // 临界区 } // 修饰代码块 //当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。 Object obj = new Object()； void baz() { synchronized(obj) { // 临界区 } }} 2.2 实现原理 在Java6之前，synchronized完全依靠操作系统的互斥锁来实现，需要进行用户态和内核态的切换，所以开销较大，但随着一系列的锁优化，synchronized的性能也越来越好了 JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。 代码块同步是使用monitorenter 和monitorexit指令实现的，而方法同步是使用另外一种方式实现的 monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。 任何对象都有 一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter 指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。 源代码获取： 首先，synchronized的行为是JVM runtime的一部分，所以我们需要先找到Runtime相关的功能实现。通过在代码中查询类似“monitor_enter”或“Monitor Enter”，很直观的就 可以定位到： sharedRuntime.cpp/hpp，它是解释器和编译器运行时的基类。 synchronizer.cpp/hpp，JVM同步相关的各种基础逻辑。 在sharedRuntime.cpp中，下面代码体现了synchronized的主要逻辑。 1234567Handle h_obj(THREAD, obj); if (UseBiasedLocking) { //检查是否开启了偏向锁 // Retry fas entry if bias is revoked to avoid unnecessary infation ObjectSynchronizer::fast_enter(h_obj, lock, true, CHECK); //完整的流程 } else { ObjectSynchronizer::slow_enter(h_obj, lock, CHECK); //直接进入轻量级锁获取逻辑 } 偏斜锁并不适合所有应用场景，撤销操作（revoke）是比较重的行为，只有当存在较多不会真正竞争的synchronized块儿时，才能体现出明显改善。实践中对于偏斜锁的一直是有 争议的，有人甚至认为，当你需要大量使用并发类库时，往往意味着你不需要偏斜锁。从具体选择来看，我还是建议需要在实践中进行测试，根据结果再决定是否使用。 还有一方面是，偏斜锁会延缓JIT 预热的进程，所以很多性能测试中会显式地关闭偏斜锁， -XX:-UseBiasedLocking 12345678910111213141516171819void ObjectSynchronizer::fas_enter(Handle obj, BasicLock* lock, bool attempt_rebias, TRAPS) { if (UseBiasedLocking) { if (!SafepointSynchronize::is_at_safepoint()) { //revoke_and_rebias是获取偏斜锁的入口方法 BiasedLocking::Condition cond = BiasedLocking::revoke_and_rebias(obj, attempt_rebias, THREAD); if (cond == BiasedLocking::BIAS_REVOKED_AND_REBIASED) { return; } } else { assert(!attempt_rebias, &quot;can not rebias toward VM thread&quot;); //revoke_at_safepoint则定义了当检测到安全点时的处理逻辑 BiasedLocking::revoke_at_safepoint(obj); } assert(!obj-&gt;mark()-&gt;has_bias_pattern(), &quot;biases should be revoked by now&quot;); } slow_enter(obj, lock, THREAD);} 1234567891011121314151617181920212223void ObjectSynchronizer::slow_enter(Handle obj, BasicLock* lock, TRAPS) { markOop mark = obj-&gt;mark(); if (mark-&gt;is_neutral()) { // 将目前的Mark Word复制到Displaced Header上 lock-&gt;set_displaced_header(mark); // 利用CAS设置对象的Mark Word if (mark == obj()-&gt;cas_set_mark((markOop) lock, mark)) { TEVENT(slow_enter: release sacklock); return; } // 检查存在竞争 } else if (mark-&gt;has_locker() &amp;&amp; THREAD-&gt;is_lock_owned((address)mark-&gt;locker())) { // 清除 lock-&gt;set_displaced_header(NULL); return; } // 重置Displaced Header lock-&gt;set_displaced_header(markOopDesc::unused_mark()); ObjectSynchronizer::infate(THREAD, obj(), infate_cause_monitor_enter)-&gt;enter(THREAD);} 2.3 锁的优化过程synchronized用的锁是存在Java对象头里的。如果对象是数组类型，还会存数组类型： 锁一共有4种状态，级别从低到高依次是: 无锁状态、 偏向锁状态、 轻量级锁状态、 重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级 2.3.1 偏向锁经验：大多数情况下，锁都是由同一个线程多次获得。 偏向锁的加锁： 当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出 同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否 存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需 要再测试一下Mark Word中偏向锁的标识是否设置成1(表示当前是偏向锁):如果没有设置，则 使用CAS竞争锁;如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 偏向锁的撤销： 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时， 持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点(在这个时间点上没有正 在执行的字节码)。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着， 如果线程不处于活动状态，则将对象头设置成无锁状态;如果线程仍然活着，拥有偏向锁的栈 会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他 线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。 偏向锁的启用： 偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活 2.3.2 轻量级锁加锁过程： 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并 将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用 CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁 解锁过程： 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成 功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁 因为自旋会消耗CPU，为了避免无用的自旋(比如获得锁的线程被阻塞住了)，一旦锁升级 成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时， 都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮 的夺锁之争 2.3.3 原子操作的实现原理处理器如何实现： 锁总线：多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入 系统内存中。那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享 变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。 处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个 LOCK#信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该 处理器可以独占共享内存。 锁缓存：总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处 理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下 使用缓存锁定代替总线锁定来进行优化。缓存锁定”是指内存区域如果被缓存在处理器的缓存 行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声 言LOCK#信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子 性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处 理器回写已被锁定的缓存行的数据时，会使缓存行无效 Java如何实现： 使用循环CAS实现原子操作：JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。 从Java 1.5开始，JDK的并发包里提供了一些类来支持原子操作，如AtomicBoolean(用原子 方式更新的boolean值)、AtomicInteger(用原子方式更新的int值)和AtomicLong(用原子方式更 新的long值)。这些原子包装类还提供了有用的工具方法，比如以原子的方式将当前值自增1和 自减1。 CAS实现原子操作的三大问题： 1)ABA问题 2)循环时间长开销大 3)只能保证一个共享变量的原子操作 (3)使用锁机制实现原子操作 2.4 转账为例分析锁保护没有关联关系的多个资源，例如，银行业务中有针对账户余额（余额是一种资源）的取款操作，也有针对账户密码（密码也是一种资源）的更改操作，我们可以为账户余额和账户密码分配不同的锁来解决并发问题，这个还是很简单的。 1234567891011121314151617181920212223242526272829303132333435363738394041//不同的资源用不同的锁保护class Account { // 锁：保护账户余额 private final Object balLock = new Object(); // 账户余额 private Integer balance; // 锁：保护账户密码 private final Object pwLock = new Object(); // 账户密码 private String password; // 取款 void withdraw(Integer amt) { synchronized(balLock) { if (this.balance &gt; amt){ this.balance -= amt; } } } // 查看余额 Integer getBalance() { synchronized(balLock) { return balance; } } // 更改密码 void updatePassword(String pw){ synchronized(pwLock) { this.password = pw; } } // 查看密码 String getPassword() { synchronized(pwLock) { return password; } }} 当然，我们也可以用一把互斥锁来保护多个资源，例如我们可以用 this 这一把锁来管理账户类里所有的资源：账户余额和用户密码。具体实现很简单，示例程序中所有的方法都增加同步关键字 synchronized 就可以了. 但是用一把锁有个问题，就是性能太差，会导致取款、查看余额、修改密码、查看密码这四个操作都是串行的。而我们用两把锁，取款和修改密码是可以并行的。用不同的锁对受保护资源进行精细化管理，能够提升性能。这种锁还有个名字，叫细粒度锁。 保护有关联关系的多个资源 例如银行业务里面的转账操作，账户 A 减少 100 元，账户 B 增加 100 元。这两个账户就是有关联关系的。那对于像转账这种有关联关系的操作，我们应该怎么去解决呢？ 12345678910111213class Account { private int balance; // 转账 //临界区内有两个资源，分别是转出账户的余额 this.balance 和转入账户的余额 target.balance，并且用的是一把锁 this //问题就出在 this 这把锁上，this 这把锁可以保护自己的余额 this.balance，却保护不了别人的余额 target.balance，就像你不能用自家的锁来保护别人家的资产 synchronized void transfer( Account target, int amt){ if (this.balance &gt; amt) { this.balance -= amt; target.balance += amt; } } } ​ 下面我们具体分析一下，假设有 A、B、C 三个账户，余额都是 200 元，我们用两个线程分别执行两个转账操作：账户 A 转给账户 B 100 元，账户 B 转给账户 C 100 元，最后我们期望的结果应该是账户 A 的余额是 100 元，账户 B 的余额是 200 元， 账户 C 的余额是 300 元。 我们假设线程 1 执行账户 A 转账户 B 的操作，线程 2 执行账户 B 转账户 C 的操作。这两个线程分别在两颗 CPU 上同时执行，那它们是互斥的吗？我们期望是，但实际上并不是。因为线程 1 锁定的是账户 A 的实例（A.this），而线程 2 锁定的是账户 B 的实例（B.this），所以这两个线程可以同时进入临界区 transfer()。同时进入临界区的结果是什么呢？线程 1 和线程 2 都会读到账户 B 的余额为 200，导致最终账户 B 的余额可能是 300（线程 1 后于线程 2 写 B.balance，线程 2 写的 B.balance 值被线程 1 覆盖），可能是 100（线程 1 先于线程 2 写 B.balance，线程 1 写的 B.balance 值被线程 2 覆盖），就是不可能是 200。 使用锁的正确姿势 很简单，只要我们的锁能覆盖所有受保护资源就可以了。在上面的例子中，this 是对象级别的锁，所以 A 对象和 B 对象都有自己的锁，如何让 A 对象和 B 对象共享一把锁呢？ 用 Account.class 作为共享的锁, 缺点就是转账操作都成串行了 123456789101112class Account { private int balance; // 转账 void transfer(Account target, int amt){ synchronized(Account.class) { if (this.balance &gt; amt) { this.balance -= amt; target.balance += amt; } } } } 现实世界里，账户转账操作是支持并发的，而且绝对是真正的并行，银行所有的窗口都可以做转账操作。只要我们能仿照现实世界做转账操作，串行的问题就解决了。 我们试想在古代，没有信息化，账户的存在形式真的就是一个账本，而且每个账户都有一个账本，这些账本都统一存放在文件架上。银行柜员在给我们做转账时，要去文件架上把转出账本和转入账本都拿到手，然后做转账。这个柜员在拿账本的时候可能遇到以下三种情况： 文件架上恰好有转出账本和转入账本，那就同时拿走； 如果文件架上只有转出账本和转入账本之一，那这个柜员就先把文件架上有的账本拿到手，同时等着其他柜员把另外一个账本送回来； 转出账本和转入账本都没有，那这个柜员就等着两个账本都被送回来。 上面这个过程在编程的世界里怎么实现呢？其实用两把锁就实现了，转出账本一把，转入账本另一把。在 transfer() 方法内部，我们首先尝试锁定转出账户 this（先把转出账本拿到手），然后尝试锁定转入账户 target（再把转入账本拿到手），只有当两者都成功时，才执行转账操作。 12345678910111213141516class Account { private int balance; // 转账 void transfer(Account target, int amt){ // 锁定转出账户 synchronized(this) { // 锁定转入账户 synchronized(target) { if (this.balance &gt; amt) { this.balance -= amt; target.balance += amt; } } } } } 使用细粒度锁可以提高并行度，是性能优化的一个重要手段,但是会出现死锁的情况，比如下面这种情况： 账户 A 转账户 B 100 元，此时另一个客户找柜员李四也做个转账业务：账户 B 转账户 A 100 元，于是张三和李四同时都去文件架上拿账本，这时候有可能凑巧张三拿到了账本 A，李四拿到了账本 B。张三拿到账本 A 后就等着账本 B（账本 B 已经被李四拿走），而李四拿到账本 B 后就等着账本 A（账本 A 已经被张三拿走），他们要等多久呢？他们会永远等待下去…因为张三不会把账本 A 送回去，李四也不会把账本 B 送回去。我们姑且称为死等吧。 解决死锁在第四节讲。 3. Happens-Before 规则前面一个操作的结果对后续操作是可见的,Happens-Before 约束了编译器的优化行为，虽允许编译器优化，但是要求编译器优化后一定遵守 Happens-Before 规则 3.1 程序的顺序性规则在一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作 12345678910111213class VolatileExample { int x = 0; volatile boolean v = false; public void writer() { x = 42; //先发生 v = true; //后发生 } public void reader() { if (v == true) { // 这里 x 会是多少呢？ } }} 3.2 volatile 变量规则对一个 volatile 变量的写操作， Happens-Before 于后续对这个 volatile 变量的读操作 3.3 传递性规则如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C 3.4 管程中锁的规则对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。 管程是一种通用的同步原语，在 Java 中指的就是 synchronized，synchronized 是 Java 里对管程的实现。 123456synchronized (this) { // 此处自动加锁 // x 是共享变量, 初始值 =10 if (this.x &lt; 12) { this.x = 12; } } // 此处自动解锁 假设 x 的初始值是 10，线程 A 执行完代码块后 x 的值会变成 12（执行完自动释放锁），线程 B 进入代码块时，能够看到线程 A 对 x 的写操作，也就是线程 B 能够看到 x==12。这个也是符合我们直觉的 3.5 线程 start() 规则主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。 123456789Thread B = new Thread(()-&gt;{ // 主线程调用 B.start() 之前 // 所有对共享变量的修改，此处皆可见 // 此例中，var==77});// 此处对共享变量 var 修改var = 77;// 主线程启动子线程B.start(); 3.6 线程 join() 规则主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作。当然所谓的“看到”，指的是对共享变量的操作. 换句话说就是，如果在线程 A 中，调用线程 B 的 join() 并成功返回，那么线程 B 中的任意操作 Happens-Before 于该 join() 操作的返回。 123456789101112Thread B = new Thread(()-&gt;{ // 此处对共享变量 var 修改 var = 66;});// 例如此处对共享变量修改，// 则这个修改结果对线程 B 可见// 主线程启动子线程B.start();B.join()// 子线程所有对共享变量的修改// 在主线程调用 B.join() 之后皆可见// 此例中，var==66 4. 如何预防死锁4.1 死锁发生的四个条件 互斥，共享资源 X 和 Y 只能被一个线程占用； 占有且等待，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X； 不可抢占，其他线程不能强行抢占线程 T1 占有的资源； 循环等待，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等待。 4.2 破坏死锁条件 对于“占用且等待”这个条件，我们可以一次性申请所有的资源，这样就不存在等待了。 对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。 对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不存在循环了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//利用上面转账的例子class Allocator { private List&lt;Object&gt; als = new ArrayList&lt;&gt;(); // 一次性申请所有资源 synchronized boolean apply( Object from, Object to){ if(als.contains(from) || als.contains(to)){ return false; } else { als.add(from); als.add(to); } return true; } // 归还资源 synchronized void free( Object from, Object to){ als.remove(from); als.remove(to); }} class Account { // actr 应该为单例 private Allocator actr; private int balance; // 转账 void transfer(Account target, int amt){ // 一次性申请转出账户和转入账户，直到成功 while(!actr.apply(this, target))； //while 死循环 try{ // 锁定转出账户 synchronized(this){ // 锁定转入账户 synchronized(target){ if (this.balance &gt; amt){ this.balance -= amt; target.balance += amt; } } } } finally { actr.free(this, target) } } } 破坏不可抢占条件看上去很简单，核心是要能够主动释放它占有的资源，这一点 synchronized 是做不到的。原因是 synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。 1234567891011121314151617181920212223class Account { private int id; private int balance; // 转账 void transfer(Account target, int amt){ Account left = this ① Account right = target; ② if (this.id &gt; target.id) { ③ left = target; ④ right = this; ⑤ } ⑥ // 锁定序号小的账户 synchronized(left){ // 锁定序号大的账户 synchronized(right){ if (this.balance &gt; amt){ this.balance -= amt; target.balance += amt; } } } } } 5. 等待通知模式优化循环等待最好的方案应该是：如果线程要求的条件（转出账本和转入账本同在文件架上）不满足，则线程阻塞自己，进入等待状态；当线程要求的条件（转出账本和转入账本同在文件架上）满足后，通知等待的线程重新执行。其中，使用线程阻塞的方式就能避免循环等待消耗 CPU 的问题。 类比就医环节： 就医流程基本上是这样： 患者先去挂号，然后到就诊门口分诊，等待叫号； 当叫到自己的号时，患者就可以找大夫就诊了； 就诊过程中，大夫可能会让患者去做检查，同时叫下一位患者； 当患者做完检查后，拿检测报告重新分诊，等待叫号； 当大夫再次叫到自己的号时，患者再去找大夫就诊。 下面我们来对比看一下前面都忽视了哪些细节。 患者到就诊门口分诊，类似于线程要去获取互斥锁；当患者被叫到时，类似线程已经获取到锁了。 大夫让患者去做检查（缺乏检测报告不能诊断病因），类似于线程要求的条件没有满足。 患者去做检查，类似于线程进入等待状态；然后大夫叫下一个患者，这个步骤我们在前面的等待 - 通知机制中忽视了，这个步骤对应到程序里，本质是线程释放持有的互斥锁。 患者做完检查，类似于线程要求的条件已经满足；患者拿检测报告重新分诊，类似于线程需要重新获取互斥锁，这个步骤我们在前面的等待 - 通知机制中也忽视了。 5.1 synchronized 实现等待 - 通知机制wait方法原理（会释放锁）： notify方法原理： 为什么说是曾经满足过呢？因为notify() 只能保证在通知时间点，条件是满足的。而被通知线程的执行时间点和通知的时间点基本上不会重合，所以当线程执行的时候，很可能条件已经不满足了（保不齐有其他线程插队）。 上面我们一直强调 wait()、notify()、notifyAll() 方法操作的等待队列是互斥锁的等待队列，所以如果 synchronized 锁定的是 this，那么对应的一定是 this.wait()、this.notify()、this.notifyAll()；如果 synchronized 锁定的是 target，那么对应的一定是 target.wait()、target.notify()、target.notifyAll() 。而且 wait()、notify()、notifyAll() 这三个方法能够被调用的前提是已经获取了相应的互斥锁，所以我们会发现 wait()、notify()、notifyAll() 都是在 synchronized{}内部被调用的。如果在 synchronized{}外部调用，或者锁定的 this，而用 target.wait() 调用的话，JVM 会抛出一个运行时异常：java.lang.IllegalMonitorStateException。 等待 - 通知机制的基本原理搞清楚后，我们就来看看它如何解决一次性申请转出账户和转入账户的问题吧。在这个等待 - 通知机制中，我们需要考虑以下四个要素。 互斥锁：上一篇文章我们提到 Allocator 需要是单例的，所以我们可以用 this 作为互斥锁。 线程要求的条件：转出账户和转入账户都没有被分配过。 何时等待：线程要求的条件不满足就等待。 何时通知：当有线程释放账户时就通知。 ps：因为当 wait() 返回时，有可能条件已经发生变化了，曾经条件满足，但是现在已经不满足了，所以要重新检验条件是否满足。 12345678910111213141516171819202122class Allocator { private List&lt;Object&gt; als; // 一次性申请所有资源 synchronized void apply(Object from, Object to){ // 经典写法 while(als.contains(from) || als.contains(to)){ try{ wait(); //不满足就wait }catch(Exception e){ } } als.add(from); als.add(to); } // 归还资源 synchronized void free( Object from, Object to){ als.remove(from); als.remove(to); notifyAll(); }} notify() 是会随机地通知等待队列中的一个线程，而 notifyAll() 会通知等待队列中的所有线程。 尽量使用 notifyAll()，因为使用notify可能会造成有的线程再也不能被唤醒了 6. 管程Java 采用的是管程技术，synchronized 关键字及 wait()、notify()、notifyAll() 这三个方法都是管程的组成部分。而管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。但是管程更容易使用，所以 Java 选择了管程。 管程，对应的英文是 Monitor，很多 Java 领域的同学都喜欢将其翻译成“监视器“。所谓管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。翻译为 Java 领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。那管程是怎么管的呢？ 6.1 MESA 模型在管程的发展史上，先后出现过三种不同的管程模型，分别是：Hasen 模型、Hoare 模型和 MESA 模型。其中，现在广泛应用的是 MESA 模型，并且 Java 管程的实现参考的也是 MESA 模型。所以今天我们重点介绍一下 MESA 模型。 在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。 6.1.1 解决互斥管程解决互斥问题的思路很简单，就是将共享变量及其对共享变量的操作统一封装起来。 在下图中，管程 X 将共享变量 queue 这个队列和相关的操作入队 enq()、出队 deq() 都封装起来了； 线程 A 和线程 B 如果想访问共享变量 queue，只能通过调用管程提供的 enq()、deq() 方法来实现； enq()、deq() 保证互斥性，只允许一个线程进入管程。不知你有没有发现，管程模型和面向对象高度契合的。 6.1.2 解决同步在管程模型里，共享变量和对共享变量的操作是被封装起来的，图中最外层的框就代表封装的意思。框的上面只有一个入口，并且在入口旁边还有一个入口等待队列。当多个线程同时试图进入管程内部时，只允许一个线程进入，其他线程则在入口等待队列中等待。这个过程类似就医流程的分诊，只允许一个患者就诊，其他患者都在门口等待。 管程里还引入了条件变量的概念，而且每个条件变量都对应有一个等待队列，如下图，条件变量 A 和条件变量 B 分别都有自己的等待队列。 那条件变量和等待队列的作用是什么呢？其实就是解决线程同步问题。你也可以结合上面提到的入队出队例子加深一下理解。 假设有个线程 T1 执行数据出队操作，不过需要注意的是执行出队操作，有个前提条件，就是队列中的数据不能是空的，而队列不空这个前提条件就是管程里的条件变量。 如果线程 T1 进入管程后恰好发现队列是空的，那怎么办呢？等待啊，去哪里等呢？就去条件变量对应的等待队列里面等。此时线程 T1 就去“队列不空”这个条件变量的等待队列中等待。这个过程类似于大夫发现你要去验个血，于是给你开了个验血的单子，你呢就去验血的队伍里排队。线程 T1 进入条件变量的等待队列后，是允许其他线程进入管程的。这和你去验血的时候，医生可以给其他患者诊治，道理都是一样的。 再假设之后另外一个线程 T2 执行数据入队操作，入队操作执行成功之后，“队列不空”这个条件对于线程 T1 来说已经满足了，此时线程 T2 要通知 T1，告诉它需要的条件已经满足了。当线程 T1 得到通知后，会从等待队列里面出来，但是出来之后不是马上执行，而是重新进入到入口等待队列里面。这个过程类似你验血完，回来找大夫，需要重新分诊。 条件变量及其等待队列我们讲清楚了，下面再说说 wait()、notify()、notifyAll() 这三个操作。前面提到线程 T1 发现“队列不空”这个条件不满足，需要进到对应的等待队列里等待。这个过程就是通过调用 wait() 来实现的。如果我们用对象 A 代表“队列不空”这个条件，那么线程 T1 需要调用 A.wait()。同理当“队列不空”这个条件满足时，线程 T2 需要调用 A.notify() 来通知 A 等待队列中的一个线程，此时这个队列里面只有线程 T1。至于 notifyAll() 这个方法，它可以通知等待队列中的所有线程。 这里我还是来一段代码再次说明一下吧。下面的代码实现的是一个阻塞队列，阻塞队列有两个操作分别是入队和出队，这两个方法都是先获取互斥锁，类比管程模型中的入口。 对于入队操作，如果队列已满，就需要等待直到队列不满，所以这里用了notFull.await();。 对于出队操作，如果队列为空，就需要等待直到队列不空，所以就用了notEmpty.await();。 如果入队成功，那么队列就不空了，就需要通知条件变量：队列不空notEmpty对应的等待队列。 如果出队成功，那就队列就不满了，就需要通知条件变量：队列不满notFull对应的等待队列。 123456789101112131415161718192021222324252627282930313233343536373839//实现的是一个阻塞队列，阻塞队列有两个操作分别是入队和出队，这两个方法都是先获取互斥锁public class BlockedQueue&lt;T&gt;{ final Lock lock = new ReentrantLock(); // 条件变量：队列不满 final Condition notFull = lock.newCondition(); // 条件变量：队列不空 final Condition notEmpty = lock.newCondition(); // 入队 void enq(T x) { lock.lock(); try { while (队列已满){ // 等待队列不满 notFull.await(); } // 省略入队操作... // 入队后, 通知可出队 notEmpty.signal(); }finally { lock.unlock(); } } // 出队 void deq(){ lock.lock(); try { while (队列已空){ // 等待队列不空 notEmpty.await(); } // 省略出队操作... // 出队后，通知可入队 notFull.signal(); }finally { lock.unlock(); } }} 6.1.3 wait() 的正确姿势1234//编程范式：用if会造成虚假唤醒while(条件不满足) { wait();} Hasen 模型、Hoare 模型和 MESA 模型的一个核心区别就是当条件满足后，如何通知相关线程。管程要求同一时刻只允许一个线程执行，那当线程 T2 的操作使线程 T1 等待的条件满足时，T1 和 T2 究竟谁可以执行呢？ Hasen 模型里面，要求 notify() 放在代码的最后，这样 T2 通知完 T1 后，T2 就结束了，然后 T1 再执行，这样就能保证同一时刻只有一个线程执行。hasen 是执行完，再去唤醒另外一个线程，能够保证线程的执行。 Hoare 模型里面，T2 通知完 T1 后，T2 阻塞，T1 马上执行；等 T1 执行完，再唤醒 T2，也能保证同一时刻只有一个线程执行。但是相比 Hasen 模型，T2 多了一次阻塞唤醒操作。hoare，是中断当前线程，唤醒另外一个线程，执行玩再去唤醒，也能够保证完成。 MESA 管程里面，T2 通知完 T1 后，T2 还是会接着执行，T1 并不立即执行，仅仅是从条件变量的等待队列进到入口等待队列里面。这样做的好处是 notify() 不用放到代码的最后，T2 也没有多余的阻塞唤醒操作。但是也有个副作用，就是当 T1 再次执行的时候，可能曾经满足的条件，现在已经不满足了，所以需要以循环方式检验条件变量。 6.1.4 notify什么时候使用 所有等待线程拥有相同的等待条件； 所有等待线程被唤醒后，执行相同的操作； 只需要唤醒一个线程。 wait和sleep的区别 相同点： 都是让线程阻塞 都可以接受到中断通知 不同点： 在同步代码块中，sleep不会释放锁，wait会释放锁。所以wait方法必须在synchronized 保护的代码中使用，而sleep没有这个要求。 sleep方法必须定义一个时间，时间到期后自动恢复。而wait可以不设置参数，意味着永久等待 wait是Object类的方法，sleep是Thread的方法。 第三部分、Java中的线程现代操作系统调度的最小单元是线程，也叫轻量级进程(Light Weight Process)，在一个进程里可以创建多个线程，这些线程都拥有各自的计数器、堆栈和局部变量等属性，并且能够访问共享的内存变量。处理器在这些线程上高速切换，让使用者感觉到这些线程在同时执行。 1. 线程的发展路程1.1 操作系统的发展操作系统的发展经历了三个阶段： 手工操作： 单道批处理系统：输入机与主机之间增加了一个存储设备磁带(盘)，单道批处理系统是将作业一个一个加入内存的，那么某一个作业因为等待磁带（盘）或者其他I/O操作而暂停时，那计算机就只能一直阻塞，直到该I/O完成。对于CPU操作密集型的程序，I/O操作相对较少，因此浪费的时间也很少。但是对于I/O操作较多的场景来说，CPU的资源是属于严重浪费的。 多道批处理系统： 为了解决单道批处理系统因为输入/输出（I/O）请求后，导致计算机等待I/O完成而造成的计算机的资源的浪费。接下来又出现了多道批处理系统。多道批处理系统与单道批处理系统的主要区别是在内存中允许一个或多个作业，当一个作业在等待I/O处理时，多批处理系统会通过相应调度算法调度另外一个作业让计算机执行。从而使CPU的利用率得到更大的提高 1.2 进程的由来在多道批处理系统中引申出了一个非常重要的模式，即允许多个作业进入内存并运行。由于在内存中存储了多个作业，那么多个作业如何进行区分？当某个作业因为等待I/O暂停时，怎么恢复到之前的运行状态呢？ 所以这个时候，人们就发明了进程这一概念，用进程来保存每个作业的数据与运行状态，同时对每个进程划分对应的内存地址空间（代码、数据、进程空间、打开的文件），并且要求进程只能使用它自己的内存空间。那么就可以达到作业的区分及恢复。 1.3 线程的由来因为一个进程在一个时间段内只能做一件事情。如果某个程序有多个任务，只能逐个执行这些任务。同时进程中存储了大量信息（数据，进程运行状态信息等）。那么当计算机进行进程切换的时候，必然存在着很大的时间与空间消耗（因为每个进程对应不同内存地址空间，进程的切换，实际是处理器处理不同的地址空间） 为了实现一个进程中任务的切换同时又避免地址空间的切换：发明了线程这一概念，用线程表示进程中的不同任务，同时又将计算机实际调度的单元转到线程。这样就避免了进程的内存地址空间的切换，也达到了多任务的并发执行。 1.4 进程和线程的区别 进程是CPU分配系统资源的基本单位，线程是CPU调度和执行的基本单位。 一个进程可以包含多个线程，进程拥有自己独立的地址空间，而进程中的不同线程共享该进程的地址空间 进程的切换会涉及到虚拟地址空间的切换，开销比较大，线程的切换开销比较小 1.5 为什么要使用多线程 更多的处理器核心：一个 单线程程序在运行时只能使用一个处理器核心，那么再多的处理器核心加入也无法显著提升 该程序的执行效率。相反，如果该程序使用多线程技术，将计算逻辑分配到多个处理器核心 上，就会显著减少程序的处理时间，并且随着更多处理器核心的加入而变得更有效率 更快的响应时间：一笔订单的创建，它包括插入订单数据、生成订单快照、发送邮件通知卖家和记录 货品销售数量等。可以使用多线程技术，即将数据一致性不强的操作派发给其他线程处 理(也可以使用消息队列)，如生成订单快照、发送邮件等。这样做的好处是响应用户请求的线 程能够尽可能快地处理完成，缩短了响应时间，提升了用户体验 更好的编程模型 1.6 线程的优先级现代操作系统基本采用时分的形式调度运行的线程，操作系统会分出一个个时间片，线程会分配到若干时间片，当线程的时间片用完了就会发生线程调度，并等待着下次分配。线程分配到的时间片多少也就决定了线程使用处理器资源的多少，而线程优先级就是决定线程需要多或者少分配一些处理器资源的线程属性。 在Java线程中，通过一个整型成员变量priority来控制优先级，优先级的范围从1~10，在线程构建的时候可以通过setPriority(int)方法来修改优先级，默认优先级是5，优先级高的线程分配时间片的数量要多于优先级低的线程。 1.7 线程的6种状态 NEW（初始化状态） RUNNABLE（可运行 / 运行状态） BLOCKED（阻塞状态） WAITING（无时限等待） TIMED_WAITING（有时限等待） TERMINATED（终止状态） 1.8 Daemon线程Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持性工作。这 意味着，当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。可以通过调 用Thread.setDaemon(true)将线程设置为Daemon线程。 2. 启动和终止线程调用线程的start()方法进行启动，随着run()方法的执行完毕，线程也随之终止 2.1 构造线程的三种方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package server.doc.thread;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;public class ThreadTest { public static void main(String[] args) throws ExecutionException, InterruptedException { A a = new A(); Thread threadA = new Thread(a); threadA.start(); B b = new B(); Thread threadB = new Thread(b); threadB.start(); C c = new C(); FutureTask&lt;Integer&gt; integerFutureTask = new FutureTask&lt;&gt;(c); //FutureTask&lt;V&gt;()是Runnable的实现类 Thread threadC = new Thread(integerFutureTask); threadC.start(); System.out.println(integerFutureTask.get());//可通过get方法获得返回值 }}class A extends Thread{ @Override public void run() { System.out.println(&quot;=======继承Thread类创建线程====&quot;); }}class B implements Runnable{ @Override public void run() { System.out.println(&quot;=======实现runnable接口创建线程====&quot;); }}//实现Callable接口创建线程,Integer就是返回值class C implements Callable&lt;Integer&gt; { @Override public Integer call() throws Exception { System.out.println(&quot;=======实现Callable接口创建线程====&quot;); return 2; }} 2.2 启动线程start源码1234567891011121314151617181920212223242526272829// 该方法可以创建一个新的线程出来public synchronized void start() { // 如果没有初始化，抛异常 if (threadStatus != 0) throw new IllegalThreadStateException(); group.add(this); // started 是个标识符，我们在做一些事情的时候，经常这么写 // 动作发生之前标识符是 false，发生完成之后变成 true boolean started = false; try {// 这里会创建一个新的线程，执行完成之后，新的线程已经在运行了，既 target 的内容已经在运行了 start0(); // 这里执行的还是主线程 started = true; } finally { try { // 如果失败，把线程从线程组中删除 if (!started) { group.threadStartFailed(this); } // Throwable 可以捕捉一些 Exception 捕捉不到的异常，比如说子线程抛出的异常 } catch (Throwable ignore) { /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ } }}// 开启新线程使用的是 native 方法private native void start0(); 2.3 正确的停止线程中断可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程的interrupt() 方法对其进行中断操作。 从原理上讲应该用 interrupt 来请求中断，而不是强制停止，因为这样可以避免数据错乱，也可以让线程有时间结束收尾工作。 123while (!Thread.currentThread().islnterrupted() &amp;&amp; more work to do) { do more work} 我们一旦调用某个线程的 interrupt() 之后，这个线程的中断标记位就会被设置成 true。每个线程都有这样的标记位，当线程执行时，应该定期检查这个标记位，如果标记位被设置成 true，就说明有程序想终止该线程。回到源码，可以看到在 while 循环体判断语句中，首先通过 Thread.currentThread().isInterrupt() 判断线程是否被中断，随后检查是否还有工作要做。 被 interrupt 的线程，是怎么收到通知的呢？一种是异常，另一种是主动检测。 异常： 当线程 A 处于 WAITING、TIMED_WAITING 状态时，如果其他线程调用线程 A 的 interrupt() 方法，会使线程 A 返回到 RUNNABLE 状态，同时线程 A 的代码会触发 InterruptedException 异常。上面我们提到转换到 WAITING、TIMED_WAITING 状态的触发条件，都是调用了类似 wait()、join()、sleep() 这样的方法，我们看这些方法的签名，发现都会 throws InterruptedException 这个异常。这个异常的触发条件就是：其他线程调用了该线程的 interrupt() 方法。 当线程 A 处于 RUNNABLE 状态时，并且阻塞在 java.nio.channels.InterruptibleChannel 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 会触发 java.nio.channels.ClosedByInterruptException 这个异常；而阻塞在 java.nio.channels.Selector 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 的 java.nio.channels.Selector 会立即返回。 主动监测： 线程通过检查自身是否被中断来进行响应，线程通过方法isInterrupted()来进行判断是否 被中断，也可以调用静态方法Thread.interrupted()对当前线程的中断标识位进行复位。 sleep情况下能否感召到打断位？ 如果 sleep、wait 等可以让线程进入阻塞的方法使线程休眠了，而处于休眠中的线程被中断，那么线程是可以感受到中断信号的，并且会抛出一个 InterruptedException 异常，同时清除中断信号，将中断标记位设置成 false。这样一来就不用担心长时间休眠中线程感受不到中断了，因为即便线程还在休眠，仍然能够响应中断通知，并抛出异常。 3.线程间通信的几种方式 volatile和synchronized关键字 对于同步块的实现使用了monitorenter和monitorexit指令，而同步方法则 是依靠方法修饰符上的ACC_SYNCHRONIZED来完成的。无论采用哪种方式，其本质是对一 个对象的监视器(monitor)进行获取，而这个获取过程是排他的，也就是同一时刻只能有一个 线程获取到由synchronized所保护对象的监视器。 任意一个对象都拥有自己的监视器，当这个对象由同步块或者这个对象的同步方法调用 时，执行方法的线程必须先获取到该对象的监视器才能进入同步块或者同步方法，而没有获 取到监视器(执行该方法)的线程将会被阻塞在同步块和同步方法的入口处，进入BLOCKED 状态。 等待/通知机制（wait / notify） 等待/通知机制，是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B 调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而 执行后续操作。上述两个线程通过对象O来完成交互，而对象上的wait()和notify/notifyAll()的 关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package _2不同的生产者消费者模式;/** * 线程之间的通信问题：两个线程交替执行A B操作同一个变量+1，-1* */public class A { public static void main(String[] args) { Data data = new Data(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.increment(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;A&quot;).start(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.decrement(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;B&quot;).start(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.increment(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;C&quot;).start(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.decrement(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;D&quot;).start(); }}//1.判断是否需要等待//2.执行业务//3.通知其他线程class Data{ //数字，资源类 private int num = 0; //+1 public synchronized void increment() throws InterruptedException { while (num != 0) { //用if会出现虚假唤醒现象 this.wait(); } num++; System.out.println(Thread.currentThread().getName()+&quot;=====&quot;+num); //通知其他线程，+1完毕 this.notifyAll(); } //-1 public synchronized void decrement() throws InterruptedException { while (num == 0) { this.wait(); } num--; System.out.println(Thread.currentThread().getName()+&quot;=====&quot;+num); this.notifyAll(); }}复制代码 Thread.join()方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package server.doc.thread;public class JoinTest implements Runnable { @Override public void run() { System.out.println(&quot;join thread demo&quot;); } public static void main(String[] args) throws InterruptedException { System.out.println(&quot;main thread start...&quot;); JoinTest joinTest = new JoinTest(); Thread thread = new Thread(joinTest); thread.setName(&quot;joinTest thread&quot;); thread.start(); thread.join(); System.out.println(&quot;main thread end&quot;); }}//没有join的时候：main thread start...main thread endjoin thread demo//有join的时候main thread start...join thread demomain thread end也就是说：当main线程去调用t.join()是，会将自己当前线程阻塞，等到t线程执行完成到达完结状态，main线程才可以继续执行复制代码//join 源码public final synchronized void join(long millis) throws InterruptedException { long base = System.currentTimeMillis(); long now = 0; // 首先校验参数是否合法 if (millis &lt; 0) { throw new IllegalArgumentException(&quot;timeout value is negative&quot;); } // 如果join方法没有参数，则相当于直接调用wait方法 if (millis == 0) { while (isAlive()) { wait(0); } } else { while (isAlive()) {//判断当前的线程是否处于活动状态。什么是活动状态呢？活动状态就是线程已经启动且尚未终止 long delay = millis - now; if (delay &lt;= 0) { break; } wait(delay); now = System.currentTimeMillis() - base; } } }复制代码 ThreadLocal（后续讲解）","link":"/2021/05/06/Java%E5%B9%B6%E5%8F%91%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80-%E4%B8%8A/"},{"title":"MySQL（一）语法和数据类型","text":"DDL，英文叫做 Data Definition Language，也就是数据定义语言，它用来定义我们的数据库对象，包括数据库、数据表和列。通过使用 DDL，我们可以创建，删除和修改数据库和表结构。 DML，英文叫做 Data Manipulation Language，数据操作语言，我们用它操作和数据库相关的记录，比如增加、删除、修改数据表中的记录。 DCL，英文叫做 Data Control Language，数据控制语言，我们用它来定义访问权限和安全级别。 DQL，英文叫做 Data Query Language，数据查询语言，我们用它查询想要的记录，它是 SQL 语言的重中之重。 DDL数据定义语言123456789101112131415shengbinbin@192 ~ % mysql -uroot -p //登陆数据库Enter password:Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 8Server version: 8.0.23 MySQL Community Server - GPLCopyright (c) 2000, 2021, Oracle and/or its affiliates.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; 12345678910111213141516171819mysql&gt; CREATE DATABASE test; //创建数据库Query OK, 1 row affected (0.00 sec)mysql&gt; CREATE DATABASE test;ERROR 1007 (HY000): Can't create database 'test'; database existsmysql&gt; show databases; //查看所有数据库+--------------------+| Database |+--------------------+| binshow || information_schema | // 存储了系统中的一些数据库对象信息，比如用户表信息，列信息，权限信息等等| mybatis || mysql | // mysql 存储了系统的用户权限信息| performance_schema || sys || test |+--------------------+7 rows in set (0.02 sec) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253mysql&gt; use test //选择数据库Database changedmysql&gt; show tables; //展示数据库中的表Empty set (0.00 sec)mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+------------------------------------------------------+| Tables_in_mysql |+------------------------------------------------------+| columns_priv || component || db || default_roles || engine_cost || func || general_log || global_grants || gtid_executed || help_category || help_keyword || help_relation || help_topic || innodb_index_stats || innodb_table_stats || password_history || plugin || procs_priv || proxies_priv || replication_asynchronous_connection_failover || replication_asynchronous_connection_failover_managed || role_edges || server_cost || servers || slave_master_info || slave_relay_log_info || slave_worker_info || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+------------------------------------------------------+35 rows in set (0.01 sec)mysql&gt; 1234567891011121314151617mysql&gt; drop database test; //删除数据库Query OK, 0 rows affected (0.01 sec)mysql&gt; show databases;+--------------------+| Database |+--------------------+| binshow || information_schema || mybatis || mysql || performance_schema || sys |+--------------------+6 rows in set (0.01 sec)mysql&gt; 12345678910111213141516mysql&gt; create table emp(ename varchar(10),hiredate date,sal decimal(10,2),deptno int(2)); //创建表Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; desc emp; //查看表的结构+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(10) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+4 rows in set (0.01 sec)mysql&gt; drop table emp; //删除表Query OK, 0 rows affected (0.01 sec) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788mysql&gt; desc emp;+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(10) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+4 rows in set (0.00 sec)mysql&gt; alter table emp modify ename varchar(20); //修改表的结构类型Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc emp;+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(20) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+4 rows in set (0.01 sec)mysql&gt; alter table emp add column age int(3); //增加字段Query OK, 0 rows affected, 1 warning (0.01 sec)Records: 0 Duplicates: 0 Warnings: 1mysql&gt; desc emp;+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(20) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | || age | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+5 rows in set (0.00 sec)mysql&gt; alter table emp drop column age; //删除字段Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc emp;+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(20) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+4 rows in set (0.01 sec)mysql&gt; alter table emp add column age int(3);Query OK, 0 rows affected, 1 warning (0.01 sec)Records: 0 Duplicates: 0 Warnings: 1mysql&gt; alter table emp change age age1 int(4); //字段改名Query OK, 0 rows affected, 1 warning (0.01 sec)Records: 0 Duplicates: 0 Warnings: 1mysql&gt; desc emp;+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(20) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | || age1 | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+5 rows in set (0.00 sec)mysql&gt; alter table emp rename emp1; //修改表名称Query OK, 0 rows affected (0.01 sec)mysql&gt; show tables;+-------------------+| Tables_in_binshow |+-------------------+| emp1 |+-------------------+1 row in set (0.00 sec) DML数据操控语言插入数据1234567891011121314151617181920212223242526272829303132mysql&gt; insert into emp(ename , hiredate , sal ,deptno) values('binshow','2020-02-02','2000',2); //插入语句Query OK, 1 row affected (0.01 sec)mysql&gt; insert into emp(ename,sal) values('wb','1000'); //部分列显示插入数据Query OK, 1 row affected (0.00 sec)mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 2000.00 | 2 | NULL || wb | NULL | 1000.00 | NULL | NULL |+---------+------------+---------+--------+------+2 rows in set (0.00 sec)mysql&gt; insert into emp values('zkd','2020-02-04','3000',3,4); //不加要插入的列名称，但是要一一对应Query OK, 1 row affected (0.00 sec)mysql&gt; insert into emp values('zkd','2020-02-04','3000',3,4),('aaa','2020-01-04','4000',3,4); //直接插入多个数据Query OK, 2 rows affected (0.00 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 2000.00 | 2 | NULL || wb | NULL | 1000.00 | NULL | NULL || zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || aaa | 2020-01-04 | 4000.00 | 3 | 4 |+---------+------------+---------+--------+------+5 rows in set (0.00 sec)mysql&gt; 更新数据1234567891011121314151617181920212223242526272829mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 2000.00 | 2 | NULL || wb | NULL | 1000.00 | NULL | NULL || zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || aaa | 2020-01-04 | 4000.00 | 3 | 4 |+---------+------------+---------+--------+------+5 rows in set (0.00 sec)mysql&gt; update emp set sal = 5000 where ename = 'binshow'; //更新语句Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || wb | NULL | 1000.00 | NULL | NULL || zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || aaa | 2020-01-04 | 4000.00 | 3 | 4 |+---------+------------+---------+--------+------+5 rows in set (0.00 sec)mysql&gt; 123456789101112131415161718192021222324mysql&gt; create table dept(deptno int, deptname varchar(10));Query OK, 0 rows affected (0.01 sec)mysql&gt; desc dept;+----------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| deptno | int | YES | | NULL | || deptname | varchar(10) | YES | | NULL | |+----------+-------------+------+-----+---------+-------+2 rows in set (0.00 sec)mysql&gt; insert into dept values(1,'tech'),(2,'sale'),(5,'fin');Query OK, 3 rows affected (0.01 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select * from dept;+--------+----------+| deptno | deptname |+--------+----------+| 1 | tech || 2 | sale || 5 | fin |+--------+----------+3 rows in set (0.00 sec)mysql&gt; 删除数据123456789101112131415mysql&gt; delete from emp where ename = 'wb';Query OK, 1 row affected (0.00 sec)mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || aaa | 2020-01-04 | 4000.00 | 3 | 4 |+---------+------------+---------+--------+------+4 rows in set (0.00 sec)mysql&gt; 查询数据1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859mysql&gt; select distinct deptno from emp; //查询不重复的数据+--------+ | deptno |+--------+| 2 || 3 |+--------+2 rows in set (0.00 sec)mysql&gt; select * from emp where sal = '5000'; //条件查询+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL |+---------+------------+---------+--------+------+1 row in set (0.00 sec)mysql&gt; select * from emp order by sal; +---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || aaa | 2020-01-04 | 4000.00 | 3 | 4 || binshow | 2020-02-02 | 5000.00 | 2 | NULL |+---------+------------+---------+--------+------+4 rows in set (0.00 sec)mysql&gt; select * from emp order by deptno,sal desc;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || aaa | 2020-01-04 | 4000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 |+---------+------------+---------+--------+------+4 rows in set (0.00 sec)mysql&gt; select * from emp order by deptno,sal desc limit 2;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || aaa | 2020-01-04 | 4000.00 | 3 | 4 |+---------+------------+---------+--------+------+2 rows in set (0.00 sec)mysql&gt; select * from emp order by deptno,sal desc limit 1,2;+-------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+-------+------------+---------+--------+------+| aaa | 2020-01-04 | 4000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 |+-------+------------+---------+--------+------+2 rows in set (0.00 sec)mysql&gt; 聚合操作的顺序问题1select * from table a where id = 1 group by age having xxx; 一条完整的 SELECT 语句内部的执行顺序是这样的： FROM 子句组装数据（包括通过 ON 进行连接）； WHERE 子句进行条件筛选； GROUP BY 分组 ； 使用聚集函数进行计算； HAVING 筛选分组； 计算所有的表达式； SELECT 的字段； ORDER BY 排序； LIMIT 筛选。 having 和 where的区别：having是对聚合后的结果进行条件的过滤，而where是聚合前就对记录过滤 12345678910111213141516171819202122232425262728293031323334mysql&gt; select count(1) from emp;+----------+| count(1) |+----------+| 4 |+----------+1 row in set (0.01 sec)mysql&gt; select deptno,count(1) from emp group by deptno;+--------+----------+| deptno | count(1) |+--------+----------+| 2 | 2 || 3 | 1 || 1 | 1 |+--------+----------+3 rows in set (0.00 sec)mysql&gt; select deptno,count(1) from emp group by deptno having count(1)&gt;1; //统计人数大于1的部门+--------+----------+| deptno | count(1) |+--------+----------+| 2 | 2 |+--------+----------+1 row in set (0.00 sec)mysql&gt; select sum(sal),max(sal),min(sal) from emp; //统计薪水总和，最大薪水，最小薪水+----------+----------+----------+| sum(sal) | max(sal) | min(sal) |+----------+----------+----------+| 16000.00 | 6000.00 | 1000.00 |+----------+----------+----------+1 row in set (0.00 sec)mysql&gt; 表连接 内连接和外连接的区别：内连接仅仅选出两个表中相互匹配的记录。 左连接和右连接的区别： 左连接指包含所有左表中的记录甚至是右边表中没有和她匹配的记录。 12345678910111213141516171819202122232425262728293031323334mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || aaa | 2020-01-04 | 4000.00 | 3 | 4 || sbb | 2018-02-01 | 6000.00 | 1 | 18 || bbb | 2018-04-11 | 1000.00 | 2 | 36 |+---------+------------+---------+--------+------+4 rows in set (0.00 sec)mysql&gt; select * from dept;+--------+----------+| deptno | deptname |+--------+----------+| 1 | tech || 2 | sale || 5 | fin || 3 | hr |+--------+----------+4 rows in set (0.00 sec)mysql&gt; select ename ,deptname from emp , dept where emp.deptno = dept.deptno;+---------+----------+| ename | deptname |+---------+----------+| sbb | tech || bbb | sale || binshow | sale || aaa | hr |+---------+----------+4 rows in set (0.00 sec)mysql&gt; 12345678910111213141516171819202122232425262728mysql&gt; insert into emp values('ccc','2010-02-03','10000',4,45);Query OK, 1 row affected (0.00 sec) //查询emp中所有用户名和所在部门名称mysql&gt; select ename , deptname from emp left join dept on emp.deptno = dept.deptno;+---------+----------+| ename | deptname |+---------+----------+| binshow | sale || aaa | hr || sbb | tech || bbb | sale || ccc | NULL |+---------+----------+5 rows in set (0.01 sec)mysql&gt; select ename , deptname from dept right join emp on emp.deptno = dept.deptno; //和上面相同+---------+----------+| ename | deptname |+---------+----------+| binshow | sale || aaa | hr || sbb | tech || bbb | sale || ccc | NULL |+---------+----------+5 rows in set (0.00 sec)mysql&gt; 子查询123456789101112mysql&gt; select * from emp where deptno in(select deptno from dept);+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || aaa | 2020-01-04 | 4000.00 | 3 | 4 || sbb | 2018-02-01 | 6000.00 | 1 | 18 || bbb | 2018-04-11 | 1000.00 | 2 | 36 |+---------+------------+---------+--------+------+4 rows in set (0.00 sec)mysql&gt; Union联合123456789101112131415161718192021222324252627282930313233mysql&gt; select deptno from emp -&gt; union -&gt; select deptno from dept; //去重了+--------+| deptno |+--------+| 2 || 3 || 1 || 4 || 5 |+--------+5 rows in set (0.00 sec)mysql&gt; select deptno from emp -&gt; union all -&gt; select deptno from dept;+--------+| deptno |+--------+| 2 || 3 || 1 || 2 || 4 || 1 || 2 || 5 || 3 |+--------+9 rows in set (0.00 sec)mysql&gt; DCL数据控制语言暂无 数据类型/运算符/常用函数待补充","link":"/2021/05/11/MySQL%EF%BC%88%E4%B8%80%EF%BC%89%E8%AF%AD%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"title":"MySQL（三）索引","text":"索引是加速数据查找的一种数据结构！ 本文介绍了 索引介绍 从磁盘IO的角度来理解SQL查询 理想的索引 索引介绍什么是索引 索引是mysql为了高效获取数据的一种数据结构 索引本身也很大，不可能全部存储在内存中，一般以索引文件的形式存储在磁盘上 索引的优势和劣势优势： 提高数据检索效率，降低数据库IO成本 降低数据排序的成本，将随机IO变成顺序IO，降低CPU的消耗 劣势： 索引也是一张表，保存了主键和索引字段，并指向实体表的记录，所以也需要占用内存 虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。 因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段， 都会调整因为更新所带来的键值变化后的索引信息 索引的分类功能逻辑分类 普通索引：是基础的索引，没有任何约束，主要用于提高查询效率。 唯一索引：就是在普通索引的基础上增加了数据唯一性的约束，在一张数据表里可以有多个唯一索引。 主键索引：在唯一索引的基础上增加了不为空的约束，也就是 NOT NULL+UNIQUE，一张表里最多只有一个主键索引 全文索引：用的不多，MySQL 自带的全文索引只支持英文 在一张数据表中只能有一个主键索引，这是由主键索引的物理实现方式决定的，因为数据存储在文件中只能按照一种顺序进行存储。但可以有多个普通索引或者多个唯一索引。 InnoDB 表必须要有主键，并且推荐使用整型自增主键，索引与数据是共同存储的，不管是主键索引还是辅助索引，在查找时都是通过先查找到索引节点才能拿到相对应的数据，如果我们在设计表结构时没有显式指定索引列的话，MySQL 会从表中选择数据不重复的列建立索引，如果没有符合的列，则 MySQL 自动为 InnoDB 表生成一个隐含字段作为主键，并且这个字段长度为6个字节，类型为整型。 物理实现分类 聚集索引：按照主键来排序存储数据，页子节点上就是数据行。 非聚集索引（辅助索引）：系统会进行两次查找，第一次先找到索引，第二次找到索引对应的位置取出数据行 每一个表只能有一个聚集索引，因为数据行本身只能按一个顺序存储。 聚集索引与非聚集索引的原理不同，在使用上也有一些区别： 聚集索引的叶子节点存储的就是我们的数据记录，非聚集索引的叶子节点存储的是数据位置。非聚集索引不会影响数据表的物理存储顺序。 一个表只能有一个聚集索引，因为只能有一种排序存储的方式，但可以有多个非聚集索引，也就是多个索引目录提供数据检索。 使用聚集索引的时候，数据的查询效率高，但如果对数据进行插入，删除，更新等操作，效率会比非聚集索引低。 字段个数分类 单一索引：每个索引只包含单个列，一个表可以有多个单列索引 联合索引：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合 数据结构分类 B+树索引 Hash索引 Full-Text全文索引 R-Tree索引 MyISAM 和 InnoDB 存储引擎，都使用 B+Tree的数据结构，它相对与 B-Tree结构，所有的数据都存放在叶子节点上，且把叶子节点通过指针连接到一起，形成了一条数据链表，以加快相邻数据的检索效率。 B树和B+树的介绍B树是专门为了磁盘等外设存储设备设计的一种平衡查找树，B 树的英文是 Balance Tree，也就是平衡的多路搜索树，它的高度远小于平衡二叉树的高度。在文件系统和数据库系统中的索引结构经常采用 B 树来实现。 系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。 InnoDB 存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB 存储引擎中默认每个页的大小为16KB，可通过参数 innodb_page_size 将页的大小设置为 4K、8K、16K，在 MySQL 中可通过如下命令查看页的大小：show variables like 'innodb_page_size'; 而系统一个磁盘块的存储空间往往没有这么大，因此 InnoDB 每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小 16KB。InnoDB 在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘I/O次数，提高查询效率。 B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述 B-Tree，首先定义一条记录为一个二元组[key, data] ，key为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key值互不相同。B-Tree作为平衡的多路搜索树，它的每一个节点最多可以包括 M 个子节点，M 称为 B 树的阶。同时你能看到，每个磁盘块中包括了关键字和子节点的指针。如果一个磁盘块中包括了 x 个关键字，那么指针数就是 x+1。对于一个 100 阶的 B 树来说，如果有 3 层的话最多可以存储约 100 万的索引数据。对于大量的索引数据来说，采用 B 树的结构是非常适合的，因为树的高度要远小于二叉树的高度。 一个 M 阶的 B 树（M&gt;2）有以下的特性： 根节点的儿子数的范围是 [2,M]。 每个中间节点包含 k-1 个关键字和 k 个孩子，孩子的数量 = 关键字的数量 +1，k 的取值范围为 [ceil(M/2), M]。 叶子节点包括 k-1 个关键字（叶子节点没有孩子），k 的取值范围为 [ceil(M/2), M]。 假设中间节点节点的关键字为：Key[1], Key[2], …, Key[k-1]，且关键字按照升序排序，即 Key[i]&lt;Key[i+1]。此时 k-1 个关键字相当于划分了 k 个范围，也就是对应着 k 个指针，即为：P[1], P[2], …, P[k]，其中 P[1] 指向关键字小于 Key[1] 的子树，P[i] 指向关键字属于 (Key[i-1], Key[i]) 的子树，P[k] 指向关键字大于 Key[k-1] 的子树。 所有叶子节点位于同一层。 B-Tree 中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个 3 阶的 B-Tree： 每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。以根节点为例，关键字为17和35，P1指针指向的子树的数据范围为小于17，P2指针指向的子树的数据范围为17~35，P3指针指向的子树的数据范围为大于35。 模拟查找关键字29的过程： 根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】 比较关键字29在区间（17,35），找到磁盘块1的指针P2。 根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】 比较关键字29在区间（26,30），找到磁盘块3的指针P2。 根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】 在磁盘块8中的关键字列表中找到关键字29。 从上一节中的B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。因此出现了改进之后的B+Tree： 在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。 B+Tree相对于B-Tree有几点不同： 有 k 个孩子的节点就有 k 个关键字。也就是孩子数量 = 关键字数，而 B 树中，孩子数量 = 关键字数 +1。 非叶子节点的关键字也会同时存在在子节点中，并且是在子节点中所有关键字的最大（或最小）。 非叶子节点仅用于索引，不保存数据记录，跟记录有关的信息都放在叶子节点中。而 B 树中，非叶子节点既保存索引，也保存数据记录。 所有关键字都在叶子节点出现，叶子节点构成一个有序链表，而且叶子节点本身按照关键字的大小从小到大顺序链接。 为什么Mysql索引要用B+树不是B树？ 首先，B+ 树查询效率更稳定。因为 B+ 树每次只有访问到叶子节点才能找到对应的数据，而在 B 树中，非叶子节点也会存储数据，这样就会造成查询效率不稳定的情况，有时候访问到了非叶子节点就可以找到关键字，而有时需要访问到叶子节点才能找到关键字。 其次，B+ 树的查询效率更高，这是因为通常 B+ 树比 B 树更矮胖（阶数更大，深度更低），查询所需要的磁盘 I/O 也会更少。同样的磁盘页大小，B+ 树可以存储更多的节点关键字。 不仅是对单个关键字的查询上，在查询范围上，B+ 树的效率也比 B 树高。这是因为所有关键字都出现在 B+ 树的叶子节点中，并通过有序链表进行了链接。而在 B 树中则需要通过中序遍历才能完成查询范围的查找，效率要低很多。 从数据页的角度来看B+树在一棵 B+ 树中，每个节点都是一个页，每次新建节点的时候，就会申请一个页空间。同一层上的节点之间，通过页的结构构成一个双向的链表（页文件头中的两个指针字段）。非叶子节点，包括了多个索引行，每个索引行里存储索引键和指向下一层页面的页面指针。最后是叶子节点，它存储了关键字和行记录，在节点内部（也就是页结构的内部）记录之间是一个单向的链表，但是对记录进行查找，则可以通过页目录采用二分查找的方式来进行。 当我们从页结构来理解 B+ 树的结构的时候，可以帮我们理解一些通过索引进行检索的原理： 1.B+ 树是如何进行记录检索的？ 如果通过 B+ 树的索引查询行记录，首先是从 B+ 树的根开始，逐层检索，直到找到叶子节点，也就是找到对应的数据页为止，将数据页加载到内存中，页目录中的槽（slot）采用二分查找的方式先找到一个粗略的记录分组，然后再在分组中通过链表遍历的方式查找记录。 2. 普通索引和唯一索引在查询效率上有什么不同？ 我们创建索引的时候可以是普通索引，也可以是唯一索引，那么这两个索引在查询效率上有什么不同呢？ 唯一索引就是在普通索引上增加了约束性，也就是关键字唯一，找到了关键字就停止检索。而普通索引，可能会存在用户记录中的关键字相同的情况，根据页结构的原理，当我们读取一条记录的时候，不是单独将这条记录从磁盘中读出去，而是将这个记录所在的页加载到内存中进行读取。InnoDB 存储引擎的页大小为 16KB，在一个页中可能存储着上千个记录，因此在普通索引的字段上进行查找也就是在内存中多几次“判断下一条记录”的操作，对于 CPU 来说，这些操作所消耗的时间是可以忽略不计的。所以对一个索引字段进行检索，采用普通索引还是唯一索引在检索效率上基本上没有差别。 回表查询通过某一列建立辅助索引时，通过该列查找数据时，需要经历以下两个阶段： 在辅助索引上检索name，到达其叶子节点获取对应的主键； 使用主键在主索引上再进行对应的检索操作 覆盖索引覆盖索引（Covering Index）,或者叫索引覆盖， 也就是平时所说的不需要回表操作 就是select的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件，换句话说查询列要被所建的索引覆盖。 索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们索引的数据，当能通过读取索引就可以得到想要的数据，那就不需要读取行了。一个索引包含（覆盖）满足查询结果的数据就叫做覆盖索引。 判断标准 使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为using index，MySQL查询优化器在执行查询前会决定是否有索引覆盖查询 哈希索引主要就是通过Hash算法（常见的Hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法），将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。 检索算法：在检索查询时，就再次对待查关键字再次执行相同的Hash算法，得到Hash值，到对应Hash表对应位置取出数据即可，如果发生Hash碰撞，则需要在取值时进行筛选。目前使用Hash索引的数据库并不多，主要有Memory等。 MySQL目前有Memory引擎和NDB引擎支持Hash索引。 索引的使用原则如何通过索引让SQL查询效率最大化？ 哪些情况下需要创建索引 有唯一性约束的字段，比如主键或唯一性字段，可以直接创建主键索引或者唯一性索引。 频繁作为 WHERE 查询条件的字段，尤其在数据表大的情况下 需要经常 GROUP BY 和 ORDER BY 的列 如果同时有GROUP BY 和 ORDER BY 的情况： 1&gt;SELECT user_id, count(*) as num FROM product_comment group by user_id order by comment_time desc limit 100 当我们对 user_id 和 comment_time 分别创建索引,效率反而不高 实际上多个单列索引在多条件查询时只会生效一个索引（MySQL 会选择其中一个限制最严格的作为索引），所以在多条件联合查询的时候最好创建联合索引。在这个例子中，我们创建联合索引 (user_id, comment_time)，再来看下查询的时间，查询时间为 0.775s，效率提升了很多。如果我们创建联合索引的顺序为 (comment_time, user_id) 呢？运行时间为 1.990s，同样比两个单列索引要快，但是会比顺序为 (user_id, comment_time) 的索引要慢一些。这是因为在进行 SELECT 查询的时候，先进行 GROUP BY，再对数据进行 ORDER BY 的操作，所以按照这个联合索引的顺序效率是最高的。 UPDATE、DELETE 的 WHERE 条件列，一般也需要创建索引 DISTINCT 字段需要创建索引 做多表 JOIN 连接操作时，创建索引需要注意以下的原则： 查询中与其他表关联的字段，外键关系建立索引 首先，连接表的数量尽量不要超过 3 张，因为每增加一张表就相当于增加了一次嵌套的循环，数量级增长会非常快，严重影响查询的效率。 其次，对 WHERE 条件创建索引，因为 WHERE 才是对数据条件的过滤。如果在数据量非常大的情况下，没有 WHERE 条件过滤是非常可怕的。 最后，对用于连接的字段创建索引，并且该字段在多张表中的类型必须一致。比如 user_id 在 product_comment 表和 user 表中都为 int(11) 类型，而不能一个为 int 另一个为 varchar 类型。 什么时候不需要创建索引 WHERE 条件（包括 GROUP BY、ORDER BY）里用不到的字段不需要创建索引，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的 如果表记录太少，比如少于 1000 个，那么是不需要创建索引的 字段中如果有大量重复数据，也不用创建索引，比如性别字段 频繁更新的字段不一定要创建索引。因为更新数据的时候，也需要更新索引，如果索引太多，在更新索引的时候也会造成负担，从而影响效率。 索引什么时候会失效 如果索引进行了表达式计算，则会失效 如果对索引使用函数，也会造成失效 在 WHERE 子句中，如果在 OR 前的条件列进行了索引，而在 OR 后的条件列没有进行索引，那么索引会失效。 当我们使用 LIKE 进行模糊查询的时候，前面不能是 % 索引列与 NULL 或者 NOT NULL 进行判断的时候也会失效。 我们在使用联合索引的时候要注意最左原则 从磁盘IO的角度来理解SQL查询数据库存储的基本单位是页，对于一棵 B+ 树的索引来说，是先从根节点找到叶子节点，也就是先查找数据行所在的页，再将页读入到内存中，在内存中对页的记录进行查找，从而得到想要数据。你看，虽然我们想要查找的，只是一行记录，但是对于磁盘 I/O 来说却需要加载一页的信息，因为页是最小的存储单位。 如果我们想要查找多行记录，查询时间是否会成倍地提升呢？其实数据库会采用缓冲池的方式提升页的查找效率。 数据库缓冲池缓冲池管理器会尽量将经常使用的数据保存起来，在数据库进行页面读操作的时候，首先会判断该页面是否在缓冲池中，如果存在就直接读取，如果不存在，就会通过内存或磁盘将页面存放到缓冲池中再进行读取。 123456789mysql&gt; show variables like 'innodb_buffer_pool_size';+-------------------------+-----------+| Variable_name | Value |+-------------------------+-----------+| innodb_buffer_pool_size | 134217728 |+-------------------------+-----------+1 row in set (0.01 sec)mysql&gt; 实际上，当我们对数据库中的记录进行修改的时候，首先会修改缓冲池中页里面的记录信息，然后数据库会以一定的频率刷新到磁盘上。注意并不是每次发生更新操作，都会立刻进行磁盘回写。缓冲池会采用一种叫做 checkpoint 的机制将数据回写到磁盘上，这样做的好处就是提升了数据库的整体性能。 比如，当缓冲池不够用时，需要释放掉一些不常用的页，就可以采用强行采用 checkpoint 的方式，将不常用的脏页回写到磁盘上，然后再从缓冲池中将这些页释放掉。这里脏页（dirty page）指的是缓冲池中被修改过的页，与磁盘上的数据页不一致。 数据页加载的三种方式 内存读取：如果该数据存在于内存中，基本上执行时间在 1ms 左右，效率还是很高的 随机读取：如果数据没有在内存中，就需要在磁盘上对该页进行查找，整体时间预估在 10ms 左右，这 10ms 中有 6ms 是磁盘的实际繁忙时间（包括了寻道和半圈旋转时间），有 3ms 是对可能发生的排队时间的估计值，另外还有 1ms 的传输时间，将页从磁盘服务器缓冲区传输到数据库缓冲区中。这 10ms 看起来很快，但实际上对于数据库来说消耗的时间已经非常长了，因为这还只是一个页的读取时间。 顺序读取其实是一种批量读取的方式，因为我们请求的数据在磁盘上往往都是相邻存储的，顺序读取可以帮我们批量读取页面，这样的话，一次性加载到缓冲池中就不需要再对其他页面单独进行磁盘 I/O 操作了。如果一个磁盘的吞吐量是 40MB/S，那么对于一个 16KB 大小的页来说，一次可以顺序读取 2560（40MB/16KB）个页，相当于一个页的读取时间为 0.4ms。采用批量读取的方式，即使是从磁盘上进行读取，效率也比从内存中只单独读取一个页的效率要高。 通过 last_query_cost 统计 SQL 语句的查询成本我们先前已经讲过，一条 SQL 查询语句在执行前需要确定查询计划，如果存在多种查询计划的话，MySQL 会计算每个查询计划所需要的成本，从中选择成本最小的一个作为最终执行的查询计划。 如果我们想要查看某条 SQL 语句的查询成本，可以在执行完这条 SQL 语句之后，通过查看当前会话中的 last_query_cost 变量值来得到当前查询的成本。这个查询成本对应的是 SQL 语句所需要读取的页的数量 123456789101112131415161718mysql&gt; select * from dept;+--------+----------+| deptno | deptname |+--------+----------+| 1 | tech || 2 | sale || 5 | fin || 3 | hr |+--------+----------+4 rows in set (0.00 sec)mysql&gt; show status like 'last_query_cost';+-----------------+----------+| Variable_name | Value |+-----------------+----------+| Last_query_cost | 0.549000 |+-----------------+----------+1 row in set (0.01 sec) 如果另外一个查询所读取的页的数量是刚才的 20 倍，但是查询的效率并没有明显的变化，实际上这两个 SQL 查询的时间基本上一样，就是因为采用了顺序读取的方式将页面一次性加载到缓冲池中，然后再进行查找。虽然页数量（last_query_cost）增加了不少，但是通过缓冲池的机制，并没有增加多少查询时间 理想的索引是什么样的索引片索引片就是 SQL 查询语句在执行中需要扫描的一个索引片段，我们会根据索引片中包含的匹配列的数量不同，将索引分成窄索引（比如包含索引列数为 1 或 2）和宽索引（包含的索引列数大于 2）。 如果索引片越宽，那么需要顺序扫描的索引页就越多；如果索引片越窄，就会减少索引访问的开销。 过滤因子谓词的选择性也等于满足这个条件列的记录数除以总记录数的比例。 这时如果我们创建一个联合的过滤条件（height, team_id），那么它的过滤能力是怎样的呢？ 联合过滤因子有更高的过滤能力，这里还需要注意一个条件，那就是条件列的关联性应该尽量相互独立，否则如果列与列之间具有相关性，联合过滤因子的能力就会下降很多。比如城市名称和电话区号就有强相关性，这两个列组合到一起不会加强过滤效果。 你能看到过滤因子决定了索引片的大小（注意这里不是窄索引和宽索引），过滤因子的条件过滤能力越强，满足条件的记录数就越少，SQL 查询需要扫描的索引片也就越小。同理，如果我们没有选择好索引片中的过滤因子，就会造成索引片中的记录数过多的情况。 三星索引三星索引具体指的是： 在 WHERE 条件语句中，找到所有等值谓词中的条件列，将它们作为索引片中的开始列； 将 GROUP BY 和 ORDER BY 中的列加入到索引中； 将 SELECT 字段中剩余的列加入到索引片中。 首先，如果我们要通过索引查找符合条件的记录，就需要将 WHERE 子句中的等值谓词列加入到索引片中，这样索引的过滤能力越强，最终扫描的数据行就越少。 另外，如果我们要对数据记录分组或者排序，都需要重新扫描数据记录。为了避免进行 file sort 排序，可以把 GROUP BY 和 ORDER BY 中涉及到的列加入到索引中，因为创建了索引就会按照索引的顺序来存储数据，这样再对这些数据按照某个字段进行分组或者排序的时候，就会提升效率。 有时候我们并不能需要完全遵循三星索引的原则，原因主要有以下两点： 采用三星索引会让索引片变宽，这样每个页能够存储的索引数据就会变少，从而增加了页加载的数量。从另一个角度来看，如果数据量很大，比如有 1000 万行数据，过多索引所需要的磁盘空间可能会成为一个问题，对缓冲池所需空间的压力也会增加。 增加了索引维护的成本。如果我们为所有的查询语句都设计理想的三星索引，就会让数据表中的索引个数过多，这样索引维护的成本也会增加。举个例子，当我们添加一条记录的时候，就需要在每一个索引上都添加相应的行（存储对应的主键值），假设添加一行记录的时间成本是 10ms（磁盘随机读取一个页的时间），那么如果我们创建了 10 个索引，添加一条记录的时间就可能变成 0.1s，如果是添加 10 条记录呢？就会花费近 1s 的时间。从索引维护的成本来看消耗还是很高的。当然对于数据库来说，数据的更新不一定马上回写到磁盘上，但即使不及时将脏页进行回写，也会造成缓冲池中的空间占用过多，脏页过多的情况。 针对一条 SQL 查询来说，三星索引是个理想的方式，但实际运行起来我们要考虑更多维护的成本，在索引效率和索引维护之间进行权衡。 三星索引会让索引变宽，好处就是不需要进行回表查询，减少了磁盘 I/O 的次数，弊端就是会造成频繁的页分裂和页合并，对于数据的插入和更新来说，效率会降低不少。 总结：","link":"/2021/05/12/MySQL%EF%BC%88%E4%B8%89%EF%BC%89%E7%B4%A2%E5%BC%95/"},{"title":"MySQL（二）存储引擎","text":"本篇讲述了MySQL的逻辑分层和存储引擎InnoDB MySQL的逻辑分层插件式的存储引擎架构将查询处理和其它的系统任务以及数据的存储提取相分离。 这种架构可以根据业务的需求和实际需要选择合适的存储引擎。 连接层：最上层是一些客户端和连接服务。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。 服务层：第二层服务层，主要完成大部分的核心服务功能， 包括查询解析、分析、优化、缓存、以及所有的内置函数，所有跨存储引擎的功能也都在这一层实现，包括触发器、存储过程、视图等 引擎层：第三层存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取 存储层：第四层为数据存储层，主要是将数据存储在运行于该设备的文件系统之上，并完成与存储引擎的交互 一条SQL语句的执行流程 客户端请求 连接器（验证用户身份，给予权限） 查询缓存（存在缓存则直接返回，不存在则执行后续操作，mysql8.0之后取消了缓存） 分析器（对SQL进行词法分析和语法分析操作 优化器（主要对执行的sql优化选择最优的执行方案方法） 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口） 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果） InnoDB存储引擎InnoDB 现在是 MySQL 默认的存储引擎，支持事务、行级锁定和外键 InnoDB体系结构InnoDB存储引擎中有很多内存块，可以认为这些内存块组成了一个大的内存池，负责如下工作： 维护所有进程/线程需要访问的多个内部数据结构 缓存磁盘上的数据 重做日志redo log 缓冲 ​ 后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存是最近的数据。此外将已经修改后的数据文件刷新到磁盘中去，同时保证在发生异常情况下可以恢复到正常运行状态。 后台线程的分类Master线程一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性。包括脏页的刷新、合并插入缓存、UNDO页的回收等等 IO线程共有四种IO线程： insert buffer thread log thread read thread ， 4个 write thread，4个 12345678910111213141516171819mysql&gt; show engine innodb status; //可以查看InnoDB状态FILE I/O--------I/O thread 0 state: waiting for i/o request (insert buffer thread)I/O thread 1 state: waiting for i/o request (log thread)I/O thread 2 state: waiting for i/o request (read thread)I/O thread 3 state: waiting for i/o request (read thread)I/O thread 4 state: waiting for i/o request (read thread)I/O thread 5 state: waiting for i/o request (read thread)I/O thread 6 state: waiting for i/o request (write thread)I/O thread 7 state: waiting for i/o request (write thread)I/O thread 8 state: waiting for i/o request (write thread)I/O thread 9 state: waiting for i/o request (write thread)Pending normal aio reads: [0, 0, 0, 0] , aio writes: [0, 0, 0, 0] , ibuf aio reads:, log i/o's:, sync i/o's:Pending flushes (fsync) log: 0; buffer pool: 0900 OS file reads, 1594 OS file writes, 930 OS fsyncs0.00 reads/s, 0 avg bytes/read, 0.00 writes/s, 0.00 fsyncs/s Purge Thread事务被提交之后，其使用的undolog可能不再需要了，因此purge thread会回收已经使用并分配的undo页。 Page Cleaner Thread将脏页中的刷新操作放入到单独的线程中来完成，减轻Master Thread的工作对用户查询线程的阻塞。 内存缓冲池缓冲池简单来说就是一块内存区域，通过内存的速度来弥补CPU和磁盘之间速度的差异。 在数据库中读取页的操作，首先将从磁盘读到的页存放在缓冲池中，下次再读相同的页时，首先判断该页是否在缓冲池中，如果在则命中，否则从磁盘中进行读取。 在数据库中修改页的操作，首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上（通过一种checkpoint到机制触发）。 1234567891011121314mysql&gt; select version();+-----------+| version() |+-----------+| 8.0.23 |+-----------+1 row in set (0.00 sec)mysql&gt; show variables like 'innodb_buffer_pool_size';+-------------------------+-----------+| Variable_name | Value |+-------------------------+-----------+| innodb_buffer_pool_size | 134217728 |+-------------------------+-----------+1 row in set (0.01 sec) 缓冲池中存放着各种类型的页： LRU列表、Free列表、Flush列表这么多页使用优化之后的LRU算法来进行管理的。 123456789101112131415161718192021mysql&gt; show engine innodb status;----------------------BUFFER POOL AND MEMORY----------------------Total large memory allocated 136970240Dictionary memory allocated 500792Buffer pool size 8191 //8191个页，每个页16KB = 128GFree buffers 7079 // free列表中的页数Database pages 1107 // LRU列表中的页数Old database pages 423Modified db pages 0 //Flush 脏页列表的页数，FLUSH列表即为脏页列表。Pending reads 0Pending writes: LRU 0, flush list 0, single page 0Pages made young 1, not young 0 //Pages made young 表示LRU列表中页移动到前端的次数0.00 youngs/s, 0.00 non-youngs/s //表示每秒上面两个操作的次数Pages read 899, created 208, written 9350.00 reads/s, 0.00 creates/s, 0.00 writes/sNo buffer pool page gets since the last printoutPages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/sLRU len: 1107, unzip_LRU len: 0 //可以压缩页，unzip_LRU列表管理着非16KB的页I/O sum[0]:cur[0], unzip sum[0]:cur[0] LRU列表中的页被修改之后，称该页为脏页（缓冲池中的页和磁盘上的页出现了数据不一致）。 重做日志缓冲从图2-2可以看到，InnoDB 存储引擎的内存区域除了有缓冲池外，还有重做日志缓冲(redo log buffer)。InnoDB 存储引擎首先将重做日志信息先放入到这个缓冲区，然后按一定频率将其刷新到重做日志文件。重做日志缓冲一般不需要设置得很大，因为- -般情况下每一秒钟会将重做日志缓冲刷新到日志文件，因此用户只需要保证每秒产生的事务量在这个缓冲大小之内即可。该值可由配置参数innodb_ log_ buffer_ size控制，默认为8MB: 123456789mysql&gt; show variables like 'innodb_log_buffer_size';+------------------------+----------+| Variable_name | Value |+------------------------+----------+| innodb_log_buffer_size | 16777216 |+------------------------+----------+1 row in set (0.00 sec)mysql&gt; 重做日志在下列三种情况下会将重做日志缓冲中的内容刷新到外部磁盘的重做日志文件中: MasterThread每一秒将重做日志缓冲刷新到重做日志文件; 每个事务提交时会将重做日志缓冲刷新到重做日志文件; 当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲刷新到重做日志文件。 Checkpoint技术Checkpoint技术就是将缓存池中脏页在某个时间点刷回到磁盘的操作 一个DML语句，进行数据update或delete 操作时，此时改变了缓冲池页中的记录，此时因为缓冲池页的数据比磁盘的新，此时的页就叫做脏页。 不管怎样，总会后的内存页数据需要刷回到磁盘里，这里就涉及几个问题： 若每次一个页发生变化，就将新页的版本刷新到磁盘，那么这个开销是非常大的 若热点数据集中在某几个页中，那么数据库的性能将变得非常差 如果在从缓冲池将页的新版本刷新到磁盘时发生了宕机，那么数据就不能恢复了 — Write Ahead Log Write Ahead Log（预写式日志）WAL策略解决了刷新页数据到磁盘时发生宕机而导致数据丢失的问题，它是关系数据库系统中用于提供原子性和持久性（ACID 属性中的两个）的一系列技术。 WAL策略核心点就是redo log，每当有事务提交时，先写入 redo log（重做日志），在修改缓冲池数据页，这样当发生掉电之类的情况时系统可以在重启后继续操作。 按理说有了WAL策略，我们就可以高枕无忧了。但其问题点又出现在redo log上面： redo log 不可能是无限大的，不能没完没了的存储我们的数据等待一起刷新到磁盘 在数据库怠机恢复时，如果redo log 太大的话恢复的代价也是非常大的 所以为了解决脏页的刷新性能，脏页应该在什么时间、什么情况下进行脏页的刷新就用到了Checkpoint技术。 Checkpoint 的目的1、缩短数据库的恢复时间 当数据库怠机恢复时，不需要重做所有的日志信息。因为Checkpoint前的数据页已经刷回到磁盘了。只需要Checkpoint后的redo log进行恢复就好了。 2、缓冲池不够用时，将脏页刷新到磁盘 当缓冲池空间不足时，根据LRU算法会溢出最近最少使用的页，若此页为脏页，那么需要强制执行Checkpoint，将脏页也就是页的新版本刷回磁盘。 3、redo log不可用时，刷新脏页 如图redo log 的不可用是因为当前数据库对其设计都是循环使用的，所以其空间并不是无限大。 当redo log被写满, 因为此时系统不能接受更新, 所有更新语句都会被堵住。 此时必须强制产生Checkpoint需要将 write pos 向前推进，推进范围内的脏页都需要刷新到磁盘 Checkpoint 的种类Checkpoint发生的时间、条件及脏页的选择等都非常复杂。 Checkpoint 每次刷新多少脏页到磁盘？ Checkpoint每次从哪里取脏页？ Checkpoint 什么时间被触发？ 面对上面的问题，InnoDB存储引擎内部为我们提供了两种Checkpoint： Sharp Checkpoint：发生在数据库关闭时将所有的脏页都刷新回磁盘，这是默认的工作方式，参数innodb_fast_shutdown=1 Fuzzy Checkpoint：InnoDB存储引擎内部使用这种模式,只刷新一部分脏页，而不是刷新所有的脏页回磁盘 FuzzyCheckpoint发生的情况 Master Thread Checkpoint 差不多以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘。 这个过程是异步的，即此时InnoDB存储引擎可以进行其他的操作，用户查询线程不会阻塞 FLUSH_LRU_LIST Checkpoint 因为LRU列表要保证一定数量的空闲页可被使用，所以如果不够会从尾部移除页，如果移除的页有脏页，就会进行此Checkpoint。 5.6版本后，这个Checkpoint放在了一个单独的Page Cleaner线程中进行，并且用户可以通过参数innodb_lru_scan_depth控制LRU列表中可用页的数量，该值默认为1024 Async/Sync Flush Checkpoint 指的是redo log文件不可用的情况，这时需要强制将一些页刷新回磁盘，而此时脏页是从脏页列表中选取的 5.6版本后不会阻塞用户查询 Dirty Page too much Checkpoint 即脏页的数量太多，导致InnoDB存储引擎强制进行Checkpoint。 其目的总的来说还是为了保证缓冲池中有足够可用的页。 其可由参数innodb_max_dirty_pages_pct控制,比如该值为75，表示当缓冲池中脏页占据75%时，强制进行CheckPoint 因为CPU和磁盘间的鸿沟的问题，从而出现缓冲池数据页来加快数据库DML操作 因为缓冲池数据页与磁盘数据一致性的问题，从而出现WAL策略（核心就是redo log） 因为缓冲池脏页的刷新性能问题，从而出现Checkpoint技术 InnoDB 为了提高执行效率，并不会每次DML操作都和磁盘交互进行持久化。而是通过Write Ahead Log 先策略写入redo log保证事物的持久化。 对于事物中修改的缓冲池脏页，会通过异步的方式刷盘，而内存空闲页和redo log的可用是通过Checkpoint技术来保证的。 不同存储引擎文件存储结构每个数据表都有一个对应的.frm文件，保存每个数据表的元数据信息，包括表结构的定义信息。 MyISAM 物理文件结构为： .frm文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等 .MYD (MYData) 文件：MyISAM 存储引擎专用，用于存储MyISAM 表的数据 .MYI (MYIndex)文件：MyISAM 存储引擎专用，用于存储MyISAM 表的索引相关信息 InnoDB 物理文件结构为： .frm 文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等 .ibd 文件或 .ibdata 文件： 这两种文件都是存放 InnoDB 数据的文件，之所以有两种文件形式存放 InnoDB 的数据，是因为 InnoDB 的数据存储方式能够通过配置来决定是使用共享表空间存放存储数据，还是用独享表空间存放存储数据。 独享表空间存储方式使用.ibd文件，并且每个表一个.ibd文件 共享表空间存储方式使用.ibdata文件，所有表共同使用一个.ibdata文件（或多个，可自己配置） InnoDB和MyISAM的区别（5点） InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败； InnoDB 是聚簇索引，MyISAM 是非聚簇索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 InnoDB 不保存表的具体行数，执行select count(*) from table 时需要全表扫描。而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快； InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； 一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15 ? 如果表的类型是MyISAM，那么是18。因为MyISAM表会把自增主键的最大ID 记录到数据文件中，重启MySQL自增主键的最大ID也不会丢失； 如果表的类型是InnoDB，那么是15。因为InnoDB 表只是把自增主键的最大ID记录到内存中，所以重启数据库或对表进行OPTION操作，都会导致最大ID丢失 InnoDB的逻辑存储结构记录是按照行来存储的，但是数据库的读取并不以行为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，效率会非常低。因此在数据库中，不论读一行，还是读多行，都是将这些行所在的页进行加载。也就是说，数据库管理存储空间的基本单位是页（Page）。 一个页中可以存储多个行记录（Row），同时在数据库中，还存在着区（Extent）、段（Segment）和表空间（Tablespace）。行、页、区、段、表空间的关系如下图所示： 从图中你能看到一个表空间包括了一个或多个段，一个段包括了一个或多个区，一个区包括了多个页，而一个页中可以有多行记录，这些概念我简单给你讲解下。 表空间表空间（Tablespace）是一个逻辑容器，表空间存储的对象是段，在一个表空间中可以有一个或多个段，但是一个段只能属于一个表空间。数据库由一个或多个表空间组成，表空间从管理上可以划分为系统表空间、用户表空间、撤销表空间、临时表空间等。 在 InnoDB 中存在两种表空间的类型：共享表空间和独立表空间。如果是共享表空间就意味着多张表共用一个表空间。如果是独立表空间，就意味着每张表有一个独立的表空间，也就是数据和索引信息都会保存在自己的表空间中。独立的表空间可以在不同的数据库之间进行迁移。 12345678910mysql&gt; show variables like 'innodb_file_per_table';+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| innodb_file_per_table | ON | //每张表都会单独保存为一个.ibd 文件。+-----------------------+-------+1 row in set (0.00 sec)mysql&gt; 段段（Segment）由一个或多个区组成，区在文件系统是一个连续分配的空间（在 InnoDB 中是连续的 64 个页），不过在段中不要求区与区之间是相邻的。段是数据库中的分配单位，不同类型的数据库对象以不同的段形式存在。当我们创建数据表、索引的时候，就会相应创建对应的段，比如创建一张表时会创建一个表段，创建一个索引时会创建一个索引段。 区区（Extent）是比页大一级的存储结构，在 InnoDB 存储引擎中，一个区会分配 64 个连续的页。因为 InnoDB 中的页大小默认是 16KB，所以一个区的大小是 64*16KB=1MB。 页内结构页（Page）如果按类型划分的话，常见的有数据页（保存 B+ 树节点）、系统页、Undo 页和事务数据页等。数据页是我们最常使用的页。在 MySQL 的 InnoDB 存储引擎中，默认页的大小是 16KB，我们可以通过下面的命令来进行查看： 123456789mysql&gt; show variables like '%innodb_page_size%';+------------------+-------+| Variable_name | Value |+------------------+-------+| innodb_page_size | 16384 |+------------------+-------+1 row in set (0.00 sec)mysql&gt; 数据库 I/O 操作的最小单位是页，与数据库相关的内容都会存储在页结构里。数据页包括七个部分，分别是文件头（File Header）、页头（Page Header）、最大最小记录（Infimum+supremum）、用户记录（User Records）、空闲空间（Free Space）、页目录（Page Directory）和文件尾（File Tailer）。 可以分为一下三个部分： 首先是文件通用部分，也就是文件头和文件尾。它们类似集装箱，将页的内容进行封装，通过文件头和文件尾校验的方式来确保页的传输是完整的。在文件头中有两个字段，分别是 FIL_PAGE_PREV 和 FIL_PAGE_NEXT，它们的作用相当于指针，分别指向上一个数据页和下一个数据页。连接起来的页相当于一个双向的链表 第二个部分是记录部分，页的主要作用是存储记录，所以“最小和最大记录”和“用户记录”部分占了页结构的主要空间。另外空闲空间是个灵活的部分，当有新的记录插入时，会从空闲空间中进行分配用于存储新记录， 第三部分是索引部分，这部分重点指的是页目录，它起到了记录的索引作用，因为在页中，记录是以单向链表的形式进行存储的。单向链表的特点就是插入、删除非常方便，但是检索效率不高，最差的情况下需要遍历链表上的所有节点才能完成检索，因此在页目录中提供了二分查找的方式，用来提高记录的检索效率。这个过程就好比是给记录创建了一个目录： 将所有的记录分成几个组，这些记录包括最小记录和最大记录，但不包括标记为“已删除”的记录。 第 1 组，也就是最小记录所在的分组只有 1 个记录；最后一组，就是最大记录所在的分组，会有 1-8 条记录；其余的组记录数量在 4-8 条之间。这样做的好处是，除了第 1 组（最小记录所在组）以外，其余组的记录数会尽量平分。 在每个组中最后一条记录的头信息中会存储该组一共有多少条记录，作为 n_owned 字段。 页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），每个槽相当于指针指向了不同组的最后一个记录。如下图所示： 页目录存储的是槽，槽相当于分组记录的索引。我们通过槽查找记录，实际上就是在做二分查找。这里我以上面的图示进行举例，5 个槽的编号分别为 0，1，2，3，4，我想查找主键为 9 的用户记录，我们初始化查找的槽的下限编号，设置为 low=0，然后设置查找的槽的上限编号 high=4，然后采用二分查找法进行查找。 首先找到槽的中间位置 p=(low+high)/2=(0+4)/2=2，这时我们取编号为 2 的槽对应的分组记录中最大的记录，取出关键字为 8。因为 9 大于 8，所以应该会在槽编号为 (p,high] 的范围进行查找 接着重新计算中间位置 p’=(p+high)/2=(2+4)/2=3，我们查找编号为 3 的槽对应的分组记录中最大的记录，取出关键字为 12。因为 9 小于 12，所以应该在槽 3 中进行查找。 遍历槽 3 中的所有记录，找到关键字为 9 的记录，取出该条记录的信息即为我们想要查找的内容。 从数据页的角度看 B+ 树是如何进行查询的MySQL 的 InnoDB 存储引擎采用 B+ 树作为索引，而索引又可以分成聚集索引和非聚集索引（二级索引），这些索引都相当于一棵 B+ 树，如图所示。一棵 B+ 树按照节点类型可以分成两部分： 叶子节点，B+ 树最底层的节点，节点的高度为 0，存储行记录。 非叶子节点，节点的高度大于 0，存储索引键和页面指针，并不存储行记录本身。 在一棵 B+ 树中，每个节点都是一个页，每次新建节点的时候，就会申请一个页空间。同一层上的节点之间，通过页的结构构成一个双向的链表（页文件头中的两个指针字段）。非叶子节点，包括了多个索引行，每个索引行里存储索引键和指向下一层页面的页面指针。最后是叶子节点，它存储了关键字和行记录，在节点内部（也就是页结构的内部）记录之间是一个单向的链表，但是对记录进行查找，则可以通过页目录采用二分查找的方式来进行。 当我们从页结构来理解 B+ 树的结构的时候，可以帮我们理解一些通过索引进行检索的原理： 1.B+ 树是如何进行记录检索的？ 如果通过 B+ 树的索引查询行记录，首先是从 B+ 树的根开始，逐层检索，直到找到叶子节点，也就是找到对应的数据页为止，将数据页加载到内存中，页目录中的槽（slot）采用二分查找的方式先找到一个粗略的记录分组，然后再在分组中通过链表遍历的方式查找记录。 2. 普通索引和唯一索引在查询效率上有什么不同？ 我们创建索引的时候可以是普通索引，也可以是唯一索引，那么这两个索引在查询效率上有什么不同呢？ 唯一索引就是在普通索引上增加了约束性，也就是关键字唯一，找到了关键字就停止检索。而普通索引，可能会存在用户记录中的关键字相同的情况，根据页结构的原理，当我们读取一条记录的时候，不是单独将这条记录从磁盘中读出去，而是将这个记录所在的页加载到内存中进行读取。InnoDB 存储引擎的页大小为 16KB，在一个页中可能存储着上千个记录，因此在普通索引的字段上进行查找也就是在内存中多几次“判断下一条记录”的操作，对于 CPU 来说，这些操作所消耗的时间是可以忽略不计的。所以对一个索引字段进行检索，采用普通索引还是唯一索引在检索效率上基本上没有差别。 总结今天我们学习了数据库中的基本存储单位，也就是页（Page），磁盘 I/O 都是基于页来进行读取的，在页之上还有区、段和表空间，它们都是更大的存储单位。我们在分配空间的时候会按照页为单位来进行分配，同一棵树上同一层的页与页之间采用双向链表，而在页里面，记录之间采用的单向链表的方式。 链表这种数据结构的特点是增加、删除比较方便，所以在对记录进行删除的时候，有时候并不是真的删除了记录，而只是逻辑上的删除，也就是在标记为上标记为“已删除”。但链表还有个问题就是查找效率低，因此在页结构中还专门设计了页目录这个模块，专门给记录做一个目录，通过二分查找法的方式进行检索提升效率。","link":"/2021/05/11/MySQL%EF%BC%88%E4%BA%8C%EF%BC%89%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"title":"MySQL（六）高可用集群","text":"","link":"/2021/05/12/MySQL%EF%BC%88%E5%85%AD%EF%BC%89%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/"},{"title":"MySQL（四）事务和锁","text":"事务是由一组SQL语句组成的逻辑处理单元，而锁可以保证事务的隔离性。 MySQL中的事务事务的四个基本属性事务是由一组SQL语句组成的逻辑处理单元，具有4个属性，通常简称为事务的ACID属性。 A (Atomicity) 原子性：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样 C (Consistency) 一致性：一致性指的就是数据库在进行事务操作后，会由原来的一致状态，变成另一种一致的状态。也就是说当事务提交后，或者当事务发生回滚后，数据库的完整性约束不能被破坏。 I (Isolation)隔离性：一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰 D (Durability) 持久性：在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚 并发事务会带来的问题更新丢失（Lost Update)： 事务A和事务B选择同一行，然后基于最初选定的值更新该行时，由于两个事务都不知道彼此的存在，就会发生丢失更新问题 **脏读(Dirty Reads)**：读到了其他事务还没有提交的数据。 **不可重复读（Non-Repeatable Reads)**：事务 A 多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。 幻读（Phantom Reads)：幻读与不可重复读类似。它发生在一个事务A读取了几行数据，接着另一个并发事务B插入了一些数据时。在随后的查询中，事务A就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 幻读和不可重复读的区别： 不可重复读的重点是修改：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改） 幻读的重点在于新增或者删除：在同一事务中，同样的条件,，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除） 如何解决这些问题“更新丢失”通常是应该完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。 “脏读” 、 “不可重复读”和“幻读” ，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决： 一种是加锁：在读取数据前，对其加锁，阻止其他事务对数据进行修改。 另一种是数据多版本并发控制（MultiVersion Concurrency Control，简称 MVCC 或 MCC），也称为多版本数据库：不用加任何锁， 通过一定机制生成一个数据请求时间点的一致性数据快照 （Snapshot)， 并用这个快照来提供一定级别 （语句级或事务级） 的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本。 事务的四种隔离级别READ-UNCOMMITTED(读未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读 InnoDB 存储引擎在 REPEATABLE-READ（可重读）事务隔离级别下使用的是Next-Key Lock 算法，因此可以避免幻读的产生. 介绍一下MVCCMultiversion Concurrency Control，中文翻译过来就是多版本并发控制技术，MVCC 的实现是通过保存数据在某个时间点的快照来实现的。也就是说不管需要执行多长时间，每个事务看到的数据都是一致的。 MVCC在innodb中的实现InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现： db_row_id：隐藏的行 ID，用来生成默认聚集索引。如果我们创建数据表的时候没有指定聚集索引，这时 InnoDB 就会用这个隐藏 ID 来创建聚集索引。采用聚集索引的方式可以提升数据的查找效率。 db_trx_id：操作这个数据的事务 ID，也就是最后一个对该数据进行插入或更新的事务 ID。 db_roll_ptr：回滚指针，也就是指向这个记录的 Undo Log 信息。 InnoDB 将行记录快照保存在了 Undo Log 里，我们可以在回滚段中找到它们： 从图中你能看到回滚指针将数据行的所有快照记录都通过链表的结构串联了起来，每个快照的记录都保存了当时的 db_trx_id，也是那个时间点操作这个数据的事务 ID。这样如果我们想要找历史快照，就可以通过遍历回滚指针的方式进行查找 如果一个事务想要查询这个行记录，需要读取哪个版本的行记录呢？这时就需要用到 Read View 了，它帮我们解决了行的可见性问题。Read View 保存了当前事务开启时所有活跃（还没有提交）的事务列表 在 Read VIew 中有几个重要的属性： trx_ids，系统当前正在活跃的事务 ID 集合。 low_limit_id，活跃的事务中最大的事务 ID。 up_limit_id，活跃的事务中最小的事务 ID。 creator_trx_id，创建这个 Read View 的事务 ID。 假设当前有事务 creator_trx_id 想要读取某个行记录，这个行记录的事务 ID 为 trx_id，那么会出现以下几种情况： 如果 trx_id &lt; 活跃的最小事务 ID（up_limit_id），也就是说这个行记录在这些活跃的事务创建之前就已经提交了，那么这个行记录对该事务是可见的。 如果 trx_id &gt; 活跃的最大事务 ID（low_limit_id），这说明该行记录在这些活跃的事务创建之后才创建，那么这个行记录对当前事务不可见。 如果 up_limit_id &lt; trx_id &lt; low_limit_id，说明该行记录所在的事务 trx_id 在目前 creator_trx_id 这个事务创建的时候，可能还处于活跃的状态，因此我们需要在 trx_ids 集合中进行遍历，如果 trx_id 存在于 trx_ids 集合中，证明这个事务 trx_id 还处于活跃状态，不可见。否则，如果 trx_id 不存在于 trx_ids 集合中，证明事务 trx_id 已经提交了，该行记录可见 总而言之，当我们查询一条记录的时候，系统如何通过多版本并发控制技术找到它： 首先获取事务自己的版本号，也就是事务 ID； 获取 Read View； 查询得到的数据，然后与 Read View 中的事务版本号进行比较； 如果不符合 ReadView 规则，就需要从 Undo Log 中获取历史快照； 最后返回符合规则的数据。 InnoDB 中，MVCC 是通过 Undo Log + Read View 进行数据读取，Undo Log 保存了历史快照，而 Read View 规则帮我们判断当前版本的数据是否可见。 在隔离级别为读已提交（Read Commit）时，一个事务中的每一次 SELECT 查询都会获取一次 Read View 当隔离级别为可重复读的时候，就避免了不可重复读，这是因为一个事务只在第一次 SELECT 的时候会获取一次 Read View，而后面所有的 SELECT 都会复用这个 Read View innodb如何解决幻读的问题在可重复读的情况下，InnoDB 可以通过 Next-Key 锁 +MVCC 来解决幻读问题。 事务日志InnoDB 使用日志来减少提交事务时的开销。因为日志中已经记录了事务，就无须在每个事务提交时把缓冲池的脏块刷新(flush)到磁盘中。 事务修改的数据和索引通常会映射到表空间的随机位置，所以刷新这些变更到磁盘需要很多随机 IO。 InnoDB 假设使用常规磁盘，随机IO比顺序IO昂贵得多，因为一个IO请求需要时间把磁头移到正确的位置，然后等待磁盘上读出需要的部分，再转到开始位置。 InnoDB 用日志把随机IO变成顺序IO。一旦日志安全写到磁盘，事务就持久化了，即使断电了，InnoDB可以重放日志并且恢复已经提交的事务。 InnoDB 使用一个后台线程智能地刷新这些变更到数据文件。这个线程可以批量组合写入，使得数据写入更顺序，以提高效率。 事务日志可以帮助提高事务效率： 使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。 事务日志采用的是追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得多。 事务日志持久以后，内存中被修改的数据在后台可以慢慢刷回到磁盘。 如果数据的修改已经记录到事务日志并持久化，但数据本身没有写回到磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这一部分修改的数据。 目前来说，大多数存储引擎都是这样实现的，我们通常称之为预写式日志（Write-Ahead Logging），修改数据需要写两次磁盘。 事务的ACID是如何保证实现的事务的隔离性是通过锁实现，而事务的原子性、一致性和持久性则是通过事务日志实现 。 事务日志包括：重做日志redo和回滚日志undo redo log（重做日志） 实现持久化和原子性 在innoDB的存储引擎中，事务日志通过重做(redo)日志和innoDB存储引擎的日志缓冲(InnoDB Log Buffer)实现。事务开启时，事务中的操作，都会先写入存储引擎的日志缓冲中，在事务提交之前，这些缓冲的日志都需要提前刷新到磁盘上持久化，这就是DBA们口中常说的“日志先行”(Write-Ahead Logging)。当事务提交之后，在Buffer Pool中映射的数据文件才会慢慢刷新到磁盘。此时如果数据库崩溃或者宕机，那么当系统重启进行恢复时，就可以根据redo log中记录的日志，把数据库恢复到崩溃前的一个状态。未完成的事务，可以继续提交，也可以选择回滚，这基于恢复的策略而定。 在系统启动的时候，就已经为redo log分配了一块连续的存储空间，以顺序追加的方式记录Redo Log，通过顺序IO来改善性能。所有的事务共享redo log的存储空间，它们的Redo Log按语句的执行顺序，依次交替的记录在一起。 undo log（回滚日志） 实现一致性 undo log 主要为事务的回滚服务。在事务执行的过程中，除了记录redo log，还会记录一定量的undo log。undo log记录了数据在每个操作前的状态，如果事务执行过程中需要回滚，就可以根据undo log进行回滚操作。单个事务的回滚，只会回滚当前事务做的操作，并不会影响到其他的事务做的操作。 Undo记录的是已部分完成并且写入硬盘的未完成的事务，默认情况下回滚日志是记录下表空间中的（共享表空间或者独享表空间） 二种日志均可以视为一种恢复操作，redo_log是恢复提交事务修改的页操作，而undo_log是回滚行记录到特定版本。二者记录的内容也不同，redo_log是物理日志，记录页的物理修改操作，而undo_log是逻辑日志，根据每行记录进行记录。 又引出个问题：你知道MySQL 有多少种日志吗？ 错误日志：记录出错信息，也记录一些警告信息或者正确的信息。 查询日志：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。 慢查询日志：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。 二进制日志：记录对数据库执行更改的所有操作。 中继日志：中继日志也是二进制日志，用来给slave 库恢复 事务日志：重做日志redo和回滚日志undo MySQL对分布式事务的支持分布式事务的实现方式有很多，既可以采用 InnoDB 提供的原生的事务支持，也可以采用消息队列来实现分布式事务的最终一致性。这里我们主要聊一下 InnoDB 对分布式事务的支持。 MySQL 从 5.0.3 InnoDB 存储引擎开始支持XA协议的分布式事务。一个分布式事务会涉及多个行动，这些行动本身是事务性的。所有行动都必须一起成功完成，或者一起被回滚。 在MySQL中，使用分布式事务涉及一个或多个资源管理器和一个事务管理器。 如图，MySQL 的分布式事务模型。模型中分三块：应用程序（AP）、资源管理器（RM）、事务管理器（TM）: 应用程序：定义了事务的边界，指定需要做哪些事务； 资源管理器：提供了访问事务的方法，通常一个数据库就是一个资源管理器； 事务管理器：协调参与了全局事务中的各个事务。 分布式事务采用两段式提交（two-phase commit）的方式： 第一阶段所有的事务节点开始准备，告诉事务管理器ready。 第二阶段事务管理器告诉每个节点是commit还是rollback。如果有一个节点失败，就需要全局的节点全部rollback，以此保障事务的原子性。 MySQL中的锁锁的分类从对数据操作的粒度分类：为了尽可能提高数据库的并发度，每次锁定的数据范围越小越好，理论上每次只锁定当前操作的数据的方案会得到最大的并发度，但是管理锁是很耗资源的事情（涉及获取，检查，释放锁等动作），因此数据库系统需要在高并发响应和系统性能两方面进行平衡，这样就产生了“锁粒度（Lock granularity）”的概念。 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低（MyISAM 和 MEMORY 存储引擎采用的是表级锁）； 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高（InnoDB 存储引擎既支持行级锁也支持表级锁，但默认情况下是采用行级锁）； 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 适用：从锁的角度来说，表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。 从对数据操作的类型分类： 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行，不会互相影响 写锁（排他锁）：当前写操作没有完成前，它会阻断其他写锁和读锁 1234567891011121314151617181920mysql&gt; lock table dept read; //加上读锁Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from dept;+--------+----------+| deptno | deptname |+--------+----------+| 1 | tech || 2 | sale || 5 | fin || 3 | hr |+--------+----------+4 rows in set (0.00 sec)mysql&gt; update dept set deptno = 6 where deptname = 'tech'; //不能修改了ERROR 1099 (HY000): Table 'dept' was locked with a READ lock and can't be updatedmysql&gt; unlock table; //解锁Query OK, 0 rows affected (0.00 sec) MyISAM 的表锁有两种模式： 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求； 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作； MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后， 只有持有锁的线程可以对表进行更新操作。 其他线程的读、 写操作都会等待，直到锁被释放为止。 默认情况下，写锁比读锁具有更高的优先级：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。 InnoDB 实现了以下两种类型的行锁： 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。 为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁： 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。 索引失效会导致行锁变表锁。比如 vchar 查询不写单引号的情况。 解释一下悲观锁和乐观锁乐观锁与悲观锁是两种并发控制的思想，可用于解决丢失更新问题 乐观锁会“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务。用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式 乐观锁的版本号机制在表中设计一个版本字段 version，第一次读的时候，会获取 version 字段的取值。然后对数据进行更新或删除操作时，会执行UPDATE ... SET version=version+1 WHERE version=version。此时如果已经有事务对这条数据进行了更改，修改就不会成功。 这种方式类似我们熟悉的 SVN、CVS 版本管理系统，当我们修改了代码进行提交时，首先会检查当前版本号与服务器上的版本号是否一致，如果一致就可以直接提交，如果不一致就需要更新服务器上的最新代码，然后再进行提交。 悲观锁会“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。 从这两种锁的设计思想中，你能看出乐观锁和悲观锁的适用场景： 乐观锁适合读操作多的场景，相对来说写的操作比较少。它的优点在于程序实现，不存在死锁问题，不过适用场景也会相对乐观，因为它阻止不了除了程序以外的数据库操作。 悲观锁适合写操作多的场景，因为写的操作具有排它性。采用悲观锁的方式，可以在数据库层面阻止其他事务对该数据的操作权限，防止读 - 写和写 - 写的冲突。 InnoDB锁的模式 InnoDB 三种行锁的方式 **记录锁(Record Locks)**： 单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项； 1SELECT * FROM table WHERE id = 1 FOR UPDATE; 它会在 id=1 的记录上加上记录锁，以阻止其他事务插入，更新，删除 id=1 这一行 在通过 主键索引 与 唯一索引 对数据行进行 UPDATE 操作时，也会对该行数据加记录锁： 1UPDATE SET age = 50 WHERE id = 1; 间隙锁（Gap Locks）： 当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”。 InnoDB 也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。 对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。 间隙锁基于非唯一索引，它锁定一段范围内的索引记录。间隙锁基于下面将会提到的Next-Key Locking 算法，请务必牢记：使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。 1SELECT * FROM table WHERE id BETWEN 1 AND 10 FOR UPDATE; 即所有在（1，10）区间内的记录行都会被锁住，所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。 GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况 临键锁(Next-key Locks)： 临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。(临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。) Next-Key 可以理解为一种特殊的间隙锁，也可以理解为一种特殊的算法。通过临建锁可以解决幻读的问题。 每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。需要强调的一点是，InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。 对于行的查询，都是采用该方法，主要目的是解决幻读的问题 死锁该如何解决死锁产生： 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环 当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁 锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：真正的数据冲突；存储引擎的实现方式。 检测死锁：数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。 死锁恢复：死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。 外部锁的死锁检测：发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决 死锁影响性能：死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖innodb_lock_wait_timeout设置进行事务回滚。 MyISAM避免死锁： 在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。 InnoDB避免死锁： 为了在单个InnoDB表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个元祖（行）使用SELECT ... FOR UPDATE语句来获取必要的锁，即使这些行的更改语句是在之后才执行的。 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁、更新时再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁 如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会 通过SELECT ... LOCK IN SHARE MODE获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。 改变事务隔离级别 如果出现死锁，可以用 show engine innodb status;命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。 我们都不希望出现死锁的情况，可以采取一些方法避免死锁的发生： 如果事务涉及多个表，操作比较复杂，那么可以尽量一次锁定所有的资源，而不是逐步来获取，这样可以减少死锁发生的概率； 如果事务需要更新数据表中的大部分数据，数据表又比较大，这时可以采用锁升级的方式，比如将行级锁升级为表级锁，从而减少死锁产生的概率； 不同事务并发读写多张数据表，可以约定访问表的顺序，采用相同的顺序降低死锁发生的概率。 总结","link":"/2021/05/12/MySQL%EF%BC%88%E5%9B%9B%EF%BC%89%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/"},{"title":"Netty（一）前世今生","text":"传统的HTTP服务器原理 创建一个ServerSocket，监听并绑定一个端口 一系列客户端来请求这个端口 服务器使用Accept，获得一个来自客户端的Socket连接对象 启动一个新线程处理连接 4.1 读Socket，得到字节流 4.2. 解码协议，得到Http请求对象 4.3 处理Http请求，得到一个结果，封装成一个HttpResponse对象 4.4 编码协议，将结果序列化字节流 写Socket，将字节流发给客户端 继续循环步骤3 HTTP服务器之所以称为HTTP服务器，是因为编码解码协议是HTTP协议，如果协议是Redis协议，那它就成了Redis服务器，如果协议是WebSocket，那它就成了WebSocket服务器，等等。 使用Netty你就可以定制编解码协议，实现自己的特定协议的服务器。 NIO上面是一个传统处理http的服务器，但是在高并发的环境下，线程数量会比较多，System load也会比较高，于是就有了NIO。 他并不是Java独有的概念，NIO代表的一个词汇叫着IO多路复用。它是由操作系统提供的系统调用，早期这个操作系统调用的名字是select，但是性能低下，后来渐渐演化成了Linux下的epoll和Mac里的kqueue。我们一般就说是epoll，因为没有人拿苹果电脑作为服务器使用对外提供服务。而Netty就是基于Java NIO技术封装的一套框架。为什么要封装，因为原生的Java NIO使用起来没那么方便，而且还有臭名昭著的bug，Netty把它封装之后，提供了一个易于操作的使用模式和接口，用户使用起来也就便捷多了。 说NIO之前先说一下BIO（Blocking IO）,如何理解这个Blocking呢？ 客户端监听（Listen）时，Accept是阻塞的，只有新连接来了，Accept才会返回，主线程才能继 读写socket时，Read是阻塞的，只有请求消息来了，Read才能返回，子线程才能继续处理 读写socket时，Write是阻塞的，只有客户端把消息收了，Write才能返回，子线程才能继续读取下一个请求","link":"/2021/05/24/Netty%EF%BC%88%E4%B8%80%EF%BC%89%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"},{"title":"MySQL（五）调优性能和分区","text":"MySQL的调优介绍： 查询优化器的执行 MySQL调优的不同维度 分区/分表/分库的操作 查询优化器SQL的执行过程 一条 SQL 查询语句首先会经过分析器，进行语法分析和语义检查。 语法分析是检查 SQL 拼写和语法是否正确，语义检查是检查 SQL 中的访问对象是否存在。比如我们在写 SELECT 语句的时候，列名写错了，系统就会提示错误。语法检查和语义检查可以保证 SQL 语句没有错误，最终得到一棵语法分析树 查询优化器的目标是找到执行 SQL 查询的最佳执行计划，执行计划就是查询树，它由一系列物理操作符组成，这些操作符按照一定的运算关系组成查询的执行计划。在查询优化器中，可以分为逻辑查询优化阶段和物理查询优化阶段。 逻辑查询优化就是通过改变 SQL 语句的内容来使得 SQL 查询更高效，同时为物理查询优化提供更多的候选执行计划。通常采用的方式是对 SQL 语句进行等价变换，对查询进行重写，而查询重写的数学基础就是关系代数。对条件表达式进行等价谓词重写、条件简化，对视图进行重写，对子查询进行优化，对连接语义进行了外连接消除、嵌套连接消除等。 逻辑查询优化是基于关系代数进行的查询重写，而关系代数的每一步都对应着物理计算，这些物理计算往往存在多种算法，因此需要计算各种物理路径的代价，从中选择代价最小的作为执行计划。在这个阶段里，对于单表和多表连接的操作，需要高效地使用索引，提升查询效率。 两种优化器模式我们需要通过优化器来制定数据表的扫描方式、连接方式以及连接顺序，从而得到最佳的 SQL 执行计划 第一种是基于规则的优化器（RBO，Rule-Based Optimizer），规则就是人们以往的经验，或者是采用已经被证明是有效的方式。通过在优化器里面嵌入规则，来判断 SQL 查询符合哪种规则，就按照相应的规则来制定执行计划，同时采用启发式规则去掉明显不好的存取路径。 第二种是基于代价的优化器（CBO，Cost-Based Optimizer），这里会根据代价评估模型，计算每条可能的执行计划的代价，也就是 COST，从中选择代价最小的作为执行计划。相比于 RBO 来说，CBO 对数据更敏感，因为它会利用数据表中的统计信息来做判断，针对不同的数据表，查询得到的执行计划可能是不同的，因此制定出来的执行计划也更符合数据表的实际情况。 RBO 的方式更像是一个出租车老司机，凭借自己的经验来选择从 A 到 B 的路径。而 CBO 更像是手机导航，通过数据驱动，来选择最佳的执行路径。 CBO如何计算代价1234567891011121314mysql&gt; select * from mysql.server_cost;+------------------------------+------------+---------------------+---------+---------------+| cost_name | cost_value | last_update | comment | default_value |+------------------------------+------------+---------------------+---------+---------------+| disk_temptable_create_cost | NULL | 2021-05-01 14:58:35 | NULL | 20 | | disk_temptable_row_cost | NULL | 2021-05-01 14:58:35 | NULL | 0.5 || key_compare_cost | NULL | 2021-05-01 14:58:35 | NULL | 0.05 || memory_temptable_create_cost | NULL | 2021-05-01 14:58:35 | NULL | 1 || memory_temptable_row_cost | NULL | 2021-05-01 14:58:35 | NULL | 0.1 || row_evaluate_cost | NULL | 2021-05-01 14:58:35 | NULL | 0.1 |+------------------------------+------------+---------------------+---------+---------------+6 rows in set (0.00 sec)mysql&gt; disk_temptable_create_cost，表示临时表文件（MyISAM 或 InnoDB）的创建代价，默认值为 20 disk_temptable_row_cost，表示临时表文件（MyISAM 或 InnoDB）的行代价，默认值 0.5 key_compare_cost，表示键比较的代价。键比较的次数越多，这项的代价就越大，这是一个重要的指标，默认值 0.05。 memory_temptable_create_cost，表示内存中临时表的创建代价，默认值 1。 memory_temptable_row_cost，表示内存中临时表的行代价，默认值 0.1。 row_evaluate_cost，统计符合条件的行代价，如果符合条件的行数越多，那么这一项的代价就越大，因此这是个重要的指标，默认值 0.1。 12345678910mysql&gt; select * from mysql.engine_cost; //页加载的代价+-------------+-------------+------------------------+------------+---------------------+---------+---------------+| engine_name | device_type | cost_name | cost_value | last_update | comment | default_value |+-------------+-------------+------------------------+------------+---------------------+---------+---------------+| default | 0 | io_block_read_cost | NULL | 2021-05-01 14:58:35 | NULL | 1 || default | 0 | memory_block_read_cost | NULL | 2021-05-01 14:58:35 | NULL | 0.25 |+-------------+-------------+------------------------+------------+---------------------+---------+---------------+2 rows in set (0.00 sec)mysql&gt; io_block_read_cost，从磁盘中读取一页数据的代价，默认是 1。 memory_block_read_cost，从内存中读取一页数据的代价，默认是 0.25。 总代价 = I/O 代价 + CPU 代价 + 内存代价 + 远程代价 MySQL调优调优的目标数据库调优的目的就是要让数据库运行得更快，也就是说响应的时间更快，吞吐量更大。 不过随着用户量的不断增加，以及应用程序复杂度的提升，我们很难用“更快”去定义数据库调优的目标，因为用户在不同时间段访问服务器遇到的瓶颈不同，比如双十一促销的时候会带来大规模的并发访问；还有用户在进行不同业务操作的时候，数据库的事务处理和SQL 查询都会有所不同。因此我们还需要更加精细的定位，去确定调优的目标。 可以从哪些维度进行调优 选择适合的 DBMS 优化表设计 表结构要尽量遵循第三范式的原则（关于第三范式，我在后面章节会讲）。这样可以让数据结构更加清晰规范，减少冗余字段，同时也减少了在更新，插入和删除数据时等异常情况的发生。 如果分析查询应用比较多，尤其是需要进行多表联查的时候，可以采用反范式进行优化。反范式采用空间换时间的方式，通过增加冗余字段提高查询的效率。 表字段的数据类型选择，关系到了查询效率的高低以及存储空间的大小。一般来说，如果字段可以采用数值类型就不要采用字符类型；字符长度要尽可能设计得短一些。针对字符类型来说，当确定字符长度固定时，就可以采用 CHAR 类型；当长度不固定时，通常采用 VARCHAR 类型。 优化逻辑查询:是通过改变 SQL语句的内容让 SQL 执行效率更高效，采用的方式是对 SQL 语句进行等价变换，比如我们在讲解 EXISTS 子查询和 IN 子查询的时候，会根据小表驱动大表的原则选择适合的子查询。在 WHERE 子句中会尽量避免对字段进行函数运算，它们会让字段的索引失效。 优化物理查询:它的核心是高效地建立索引，并通过这些索引来做各种优化。 如果数据重复度高，就不需要创建索引。通常在重复度超过 10% 的情况下，可以不创建这个字段的索引。比如性别这个字段（取值为男和女）。 要注意索引列的位置对索引使用的影响。比如我们在 WHERE 子句中对索引字段进行了表达式的计算，会造成这个字段的索引失效。 要注意联合索引对索引使用的影响。我们在创建联合索引的时候会对多个字段创建索引，这时索引的顺序就很重要了。比如我们对字段 x, y, z 创建了索引，那么顺序是(x,y,z) 还是 (z,y,x)，在执行的时候就会存在差别。 要注意多个索引对索引使用的影响。索引不是越多越好，因为每个索引都需要存储空间，索引多也就意味着需要更多的存储空间。此外，过多的索引也会导致优化器在进行评估的时候增加了筛选出索引的计算时间，影响评估的效率。 查询优化器在对 SQL 语句进行等价变换之后，还需要根据数据表的索引情况和数据情况确定访问路径，这就决定了执行 SQL 时所需要消耗的资源。SQL 查询时需要对不同的数据表进行查询，因此在物理查询优化阶段也需要确定这些查询所采用的路径，具体的情况包括： \\1. 单表扫描：对于单表扫描来说，我们可以全表扫描所有的数据，也可以局部扫描。 \\2. 两张表的连接：常用的连接方式包括了嵌套循环连接、HASH 连接和合并连接。 \\3. 多张表的连接：多张数据表进行连接的时候，顺序很重要，因为不同的连接路径查询的 效率不同，搜索空间也会不同。我们在进行多表连接的时候，搜索空间可能会达到很高的数据量级，巨大的搜索空间显然会占用更多的资源，因此我们需要通过调整连接顺 序，将搜索空间调整在一个可接收的范围内。 物理查询优化是在确定了逻辑查询优化之后，采用物理优化技术（比如索引等），通过计算 代价模型对各种可能的访问路径进行估算，从而找到执行方式中代价最小的作为执行计划。 在这个部分中，我们需要掌握的重点是对索引的创建和使用。 使用 Redis 或 Memcached 作为缓存,如果我们将常用的数据直接放到内存中，就会大幅提升查询的效率。 库级优化:读写分离,对数据库分库分表。当数据量级达到亿级以上时，有时候我们需要把一个数据库切成多份，放到不同的数据库服务器上 什么情况下做垂直切分，什么情况下做水平切分呢？ 如果数据库中的数据表过多，可以采用垂直分库的方式，将关联的数据表部署在一个数据库上。 如果数据表中的列过多，可以采用垂直分表的方式，将数据表分拆成多张，把经常一起使用的列放到同一张表里。 如果数据表中的数据达到了亿级以上，可以考虑水平切分，将大的数据表分拆成不同的子表，每张表保持相同的表结构,采用水平拆分的方式，就是将单张数据量大的表按照某个属性维度分成不同的小表,比如说按照年份拆分 表设计的三范式范式的定义会使用到主键和候选键（因为主键和候选键可以唯一标识元组），数据库中的键（Key）由一个或者多个属性组成。我总结了下数据表中常用的几种键和属性的定义： 超键：能唯一标识元组的属性集叫做超键。 候选键：如果超键不包括多余的属性，那么这个超键就是候选键。 主键：用户可以从候选键中选择一个作为主键。 外键：如果数据表 R1 中的某属性集不是 R1 的主键，而是另一个数据表 R2 的主键，那么这个属性集就是数据表 R1 的外键。 主属性：包含在任一候选键中的属性称为主属性。 非主属性：与主属性相对，指的是不包含在任何一个候选键中的属性。 1NF 指的是数据库表中的任何属性都是原子性的，不可再分。 2NF 指的数据表里的非主属性都要和这个数据表的候选键有完全依赖关系 3NF 在满足 2NF 的同时，对任何非主属性都不传递依赖于候选键 什么是反范式SQL执行慢如何定位呢 观察服务器的状态是否存在周期性的波动。如果存在周期性波动，有可能是周期性节点的原因，比如双十一、促销活动等。这样的话，我们可以通过 A1 这一步骤解决，也就是加缓存，或者更改缓存失效策略。 如果缓存策略没有解决，或者不是周期性波动的原因，我们就需要进一步分析查询延迟和卡顿的原因。接下来进入 S2 这一步，我们需要开启慢查询。慢查询可以帮我们定位执行慢的 SQL 语句。我们可以通过设置 long_query_time 参数定义“慢”的阈值，如果 SQL 执行时间超过了 long_query_time，则会认为是慢查询。当收集上来这些慢查询之后，我们就可以通过分析工具对慢查询日志进行分析。 在 S3 这一步骤中，我们就知道了执行慢的 SQL，这样就可以针对性地用 EXPLAIN 查看对应 SQL 语句的执行计划，或者使用 show profile 查看 SQL 中每一个步骤的时间成本。这样我们就可以了解 SQL 查询慢是因为执行时间长，还是等待时间长。 如果是 SQL 等待时间长，我们进入 A2 步骤。在这一步骤中，我们可以调优服务器的参数，比如适当增加数据库缓冲池等。 如果是 SQL 执行时间长，就进入 A3 步骤，这一步中我们需要考虑是索引设计的问题？还是查询关联的数据表过多？还是因为数据表的字段设计问题导致了这一现象。然后在这些维度上进行对应的调整。 数据库自身的 SQL 查询性能是否已经达到了瓶颈（CPU饱和/磁盘IO/硬件瓶颈，查看系统状态） 如果已经达到了性能瓶颈，进入 A4 阶段，需要考虑增加服务器，采用读写分离的架构，或者考虑对数据库进行分库分表，比如垂直分库、垂直分表和水平分表等。 使用慢查询定位执行慢的 SQL1234mysql &gt; show variables like '%slow_query_log';mysql &gt; set global slow_query_log='ON'; //打开慢查询日志mysql &gt; show variables like '%long_query_time%';//看下慢查询的时间阈值设置mysql &gt; set global long_query_time = 3; 使用 EXPLAIN 查看执行计划使用 Explain 关键字可以模拟优化器执行SQL查询语句，从而知道 MySQL 是如何处理你的 SQL 语句的。分析你的查询语句或是表结构的性能瓶颈 能干吗： 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 哪些索引被实际使用 表之间的引用 每张表有多少行被优化器查询 怎么玩： Explain + SQL语句 执行计划包含的信息（如果有分区表的话还会有partitions） 各字段解释 id（select 查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序） id相同，执行顺序从上往下 id全不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 id部分相同，执行顺序是先按照数字大的先执行，然后数字相同的按照从上往下的顺序执行 select_type（查询类型，用于区别普通查询、联合查询、子查询等复杂查询） SIMPLE ：简单的select查询，查询中不包含子查询或UNION PRIMARY：查询中若包含任何复杂的子部分，最外层查询被标记为PRIMARY SUBQUERY：在select或where列表中包含了子查询 DERIVED：在from列表中包含的子查询被标记为DERIVED，MySQL会递归执行这些子查询，把结果放在临时表里 UNION：若第二个select出现在UNION之后，则被标记为UNION，若UNION包含在from子句的子查询中，外层select将被标记为DERIVED UNION RESULT：从UNION表获取结果的select table（显示这一行的数据是关于哪张表的） type（显示查询使用了那种类型，从最好到最差依次排列 system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL ） 在这些情况里，all 是最坏的情况，因为采用了全表扫描的方式。index 和 all 差不多，只不过 index 对索引表进行全扫描，这样做的好处是不再需要对数据进行排序，但是开销依然很大。 如果我们在 extra 列中看到 Using index，说明采用了索引覆盖，也就是索引可以覆盖所需的 SELECT 字段，就不需要进行回表，这样就减少了数据查找的开销。 system：表只有一行记录（等于系统表），是 const 类型的特例，平时不会出现 const：表示通过索引一次就找到了，const 用于比较 primary key 或 unique 索引，因为只要匹配一行数据，所以很快，如将主键置于 where 列表中，mysql 就能将该查询转换为一个常量 eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配，常见于主键或唯一索引扫描 ref：非唯一性索引扫描，范围匹配某个单独值得所有行。本质上也是一种索引访问，他返回所有匹配某个单独值的行，然而，它可能也会找到多个符合条件的行，多以他应该属于查找和扫描的混合体 range：只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引，一般就是在你的where语句中出现了between、&lt;、&gt;、in等的查询，这种范围扫描索引比全表扫描要好，因为它只需开始于索引的某一点，而结束于另一点，不用扫描全部索引 index：Full Index Scan，index于ALL区别为index类型只遍历索引树。通常比ALL快，因为索引文件通常比数据文件小。（也就是说虽然all和index都是读全表，但index是从索引中读取的，而all是从硬盘中读的） ALL：Full Table Scan，将遍历全表找到匹配的行 tip: 一般来说，得保证查询至少达到range级别，最好到达ref possible_keys（显示可能应用在这张表中的索引，一个或多个，查询涉及到的字段若存在索引，则该索引将被列出，但不一定被查询实际使用） key 实际使用的索引，如果为NULL，则没有使用索引 查询中若使用了覆盖索引，则该索引和查询的 select 字段重叠，仅出现在key列表中 key_len 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好 key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的 ref （显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引列上的值） rows （根据表统计信息及索引选用情况，大致估算找到所需的记录所需要读取的行数） Extra（包含不适合在其他列中显示但十分重要的额外信息） using filesort: 说明mysql会对数据使用一个外部的索引排序，不是按照表内的索引顺序进行读取。mysql中无法利用索引完成的排序操作称为“文件排序”。常见于order by和group by语句中 Using temporary：使用了临时表保存中间结果，mysql在对查询结果排序时使用临时表。常见于排序order by和分组查询group by。 using index：表示相应的select操作中使用了覆盖索引，避免访问了表的数据行，效率不错，如果同时出现using where，表明索引被用来执行索引键值的查找；否则索引被用来读取数据而非执行查找操作 using where：使用了where过滤 using join buffer：使用了连接缓存 impossible where：where子句的值总是false，不能用来获取任何元祖 select tables optimized away：在没有group by子句的情况下，基于索引优化操作或对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化 distinct：优化distinct操作，在找到第一匹配的元祖后即停止找同样值的动作 case: 第一行（执行顺序4）：id列为1，表示是union里的第一个select，select_type列的primary表示该查询为外层查询，table列被标记为，表示查询结果来自一个衍生表，其中derived3中3代表该查询衍生自第三个select查询，即id为3的select。【select d1.name……】 第二行（执行顺序2）：id为3，是整个查询中第三个select的一部分。因查询包含在from中，所以为derived。【select id,name from t1 where other_column=’’】 第三行（执行顺序3）：select列表中的子查询select_type为subquery，为整个查询中的第二个select。【select id from t3】 第四行（执行顺序1）：select_type为union，说明第四个select是union里的第二个select，最先执行【select name,id from t2】 第五行（执行顺序5）：代表从union的临时表中读取行的阶段，table列的&lt;union1,4&gt;表示用第一个和第四个select的结果进行union操作。【两个结果union操作】 Show Profile 分析查询通过慢日志查询可以知道哪些 SQL 语句执行效率低下，通过 explain 我们可以得知 SQL 语句的具体执行情况，索引使用等，还可以结合Show Profile命令查看执行状态。 Show Profile 是 MySQL 提供可以用来分析当前会话中语句执行的资源消耗情况。可以用于SQL的调优的测量 默认情况下，参数处于关闭状态，并保存最近15次的运行结果 分析步骤 是否支持，看看当前的mysql版本是否支持 1mysql&gt;Show variables like 'profiling'; --默认是关闭，使用前需要开启 开启功能，默认是关闭，使用前需要开启 1mysql&gt;set profiling=1; 运行SQL 查看结果 诊断SQL，show profile cpu,block io for query id(上一步前面的问题SQL数字号码) 日常开发需要注意的结论 converting HEAP to MyISAM 查询结果太大，内存都不够用了往磁盘上搬了。 create tmp table 创建临时表，这个要注意 Copying to tmp table on disk 把内存临时表复制到磁盘 locked 性能优化索引优化 全值匹配我最爱 最佳左前缀法则，比如建立了一个联合索引(a,b,c)，那么其实我们可利用的索引就有(a), (a,b), (a,b,c) 不在索引列上做任何操作（计算、函数、(自动or手动)类型转换），会导致索引失效而转向全表扫描 存储引擎不能使用索引中范围条件右边的列 尽量使用覆盖索引(只访问索引的查询(索引列和查询列一致))，减少select is null ,is not null 也无法使用索引 like “xxxx%” 是可以用到索引的，like “%xxxx” 则不行(like “%xxx%” 同理)。like以通配符开头(‘%abc…’)索引失效会变成全表扫描的操作， 字符串不加单引号索引失效 少用or，用它来连接时会索引失效 &lt;，&lt;=，=，&gt;，&gt;=，BETWEEN，IN 可用到索引，&lt;&gt;，not in ，!= 则不行，会导致全表扫描 一般性建议 对于单键索引，尽量选择针对当前query过滤性更好的索引 在选择组合索引的时候，当前Query中过滤性最好的字段在索引字段顺序中，位置越靠前越好。 在选择组合索引的时候，尽量选择可以能够包含当前query中的where字句中更多字段的索引 尽可能通过分析统计信息和调整query的写法来达到选择合适索引的目的 少用Hint强制索引 查询优化永远小标驱动大表（小的数据集驱动大的数据集） 12345slect * from A where id in (select id from B)`等价于#等价于select id from Bselect * from A where A.id=B.id复制代码 当 B 表的数据集必须小于 A 表的数据集时，用 in 优于 exists 12345select * from A where exists (select 1 from B where B.id=A.id)#等价于select * from Aselect * from B where B.id = A.id`复制代码 当 A 表的数据集小于B表的数据集时，用 exists优于用 in 注意：A表与B表的ID字段应建立索引。 order by关键字优化 order by子句，尽量使用 Index 方式排序，避免使用 FileSort 方式排序 MySQL 支持两种方式的排序，FileSort 和 Index，Index效率高，它指 MySQL 扫描索引本身完成排序，FileSort 效率较低； ORDER BY 满足两种情况，会使用Index方式排序；①ORDER BY语句使用索引最左前列 ②使用where子句与ORDER BY子句条件列组合满足索引最左前列 尽可能在索引列上完成排序操作，遵照索引建的最佳最前缀 如果不在索引列上，filesort 有两种算法，mysql就要启动双路排序和单路排序 双路排序：MySQL 4.1之前是使用双路排序,字面意思就是两次扫描磁盘，最终得到数据 单路排序：从磁盘读取查询需要的所有列，按照order by 列在 buffer对它们进行排序，然后扫描排序后的列表进行输出，效率高于双路排序 优化策略 增大sort_buffer_size参数的设置 增大max_lencth_for_sort_data参数的设置 GROUP BY关键字优化 group by实质是先排序后进行分组，遵照索引建的最佳左前缀 当无法使用索引列，增大 max_length_for_sort_data 参数的设置，增大sort_buffer_size参数的设置 where高于having，能写在where限定的条件就不要去having限定了 数据类型优化MySQL 支持的数据类型非常多，选择正确的数据类型对于获取高性能至关重要。不管存储哪种类型的数据，下面几个简单的原则都有助于做出更好的选择。 更小的通常更好：一般情况下，应该尽量使用可以正确存储数据的最小数据类型。 简单就好：简单的数据类型通常需要更少的CPU周期。例如，整数比字符操作代价更低，因为字符集和校对规则（排序规则）使字符比较比整型比较复杂。 尽量避免NULL：通常情况下最好指定列为NOT NULL 分区、分表、分库MySQL分区一般情况下我们创建的表对应一组存储文件，使用MyISAM存储引擎时是一个.MYI和.MYD文件，使用Innodb存储引擎时是一个.ibd和.frm（表结构）文件。 当数据量较大时（一般千万条记录级别以上），MySQL的性能就会开始下降，这时我们就需要将数据分散到多组存储文件，保证其单个文件的执行效率 能干嘛 逻辑数据分割 提高单一的写和读应用速度 提高分区范围读查询的速度 分割数据能够有多个不同的物理文件路径 高效的保存历史数据 怎么玩 首先查看当前数据库是否支持分区 MySQL5.6以及之前版本： 1SHOW VARIABLES LIKE '%partition%'; MySQL5.6： 1show plugins; 分区类型及操作 RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区。mysql将会根据指定的拆分策略，,把数据放在不同的表文件上。相当于在文件上,被拆成了小块.但是,对外给客户的感觉还是一张表，透明的。 按照 range 来分，就是每个库一段连续的数据，这个一般是按比如时间范围来的，比如交易表啊，销售表啊等，可以根据年月来存放数据。可能会产生热点问题，大量的流量都打在最新的数据上了。 range 来分，好处在于说，扩容的时候很简单。 LIST分区：类似于按RANGE分区，每个分区必须明确定义。它们的主要区别在于，LIST分区中每个分区的定义和选择是基于某列的值从属于一个值列表集中的一个值，而RANGE分区是从属于一个连续区间值的集合。 HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL 中有效的、产生非负整数值的任何表达式。 hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表 KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值。 看上去分区表很帅气，为什么大部分互联网还是更多的选择自己分库分表来水平扩展咧？ 分区表，分区键设计不太灵活，如果不走分区键，很容易出现全表锁 一旦数据并发量上来，如果在分区表实施关联，就是一个灾难 自己分库分表，自己掌控业务场景与访问模式，可控。分区表，研发写了一个sql，都不确定mysql是怎么玩的，不太可控 随着业务的发展，业务越来越复杂，应用的模块越来越多，总的数据量很大，高并发读写操作均超过单个数据库服务器的处理能力怎么办？ 这个时候就出现了数据分片，数据分片指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中。数据分片的有效手段就是对关系型数据库进行分库和分表。 区别于分区的是，分区一般都是放在单机里的，用的比较多的是时间范围分区，方便归档。只不过分库分表需要代码实现，分区则是mysql内部实现。分库分表和分区并不冲突，可以结合使用。 说说分库与分表的设计 MySQL分表分表有两种分割方式，一种垂直拆分，另一种水平拆分。 垂直拆分 垂直分表，通常是按照业务功能的使用频次，把主要的、热门的字段放在一起做为主要表。然后把不常用的，按照各自的业务属性进行聚集，拆分到不同的次要表中；主要表和次要表的关系一般都是一对一的。 水平拆分(数据分片) 单表的容量不超过500W，否则建议水平拆分。是把一个表复制成同样表结构的不同表，然后把数据按照一定的规则划分，分别存储到这些表中，从而保证单表的容量不会太大，提升性能；当然这些结构一样的表，可以放在一个或多个数据库中。 水平分割的几种方法： 使用MD5哈希，做法是对UID进行md5加密，然后取前几位（我们这里取前两位），然后就可以将不同的UID哈希到不同的用户表（user_xx）中了。 还可根据时间放入不同的表，比如：article_201601，article_201602。 按热度拆分，高点击率的词条生成各自的一张表，低热度的词条都放在一张大表里，待低热度的词条达到一定的贴数后，再把低热度的表单独拆分成一张表。 根据ID的值放入对应的表，第一个表user_0000，第二个100万的用户数据放在第二 个表user_0001中，随用户增加，直接添加用户表就行了。 什么情况下做垂直切分，什么情况下做水平切分呢？ 如果数据库中的数据表过多，可以采用垂直分库的方式，将关联的数据表部署在一个数据库上。 如果数据表中的列过多，可以采用垂直分表的方式，将数据表分拆成多张，把经常一起使用的列放到同一张表里。 如果数据表中的数据达到了亿级以上，可以考虑水平切分，将大的数据表分拆成不同的子表，每张表保持相同的表结构。比如你可以按照年份来划分，把不同年份的数据放到不同的数据表中。2017 年、2018 年和 2019 年的数据就可以分别放到三张数据表中。 采用垂直分表的形式，就是将一张数据表分拆成多张表，采用水平拆分的方式，就是将单张数据量大的表按照某个属性维度分成不同的小表。 MySQL分库 为什么要分库? 数据库集群环境后都是多台 slave，基本满足了读取操作; 但是写入或者说大数据、频繁的写入操作对master性能影响就比较大，这个时候，单库并不能解决大规模并发写入的问题，所以就会考虑分库。 分库是什么？ 一个库里表太多了，导致了海量数据，系统性能下降，把原本存储于一个库的表拆分存储到多个库上， 通常是将表按照功能模块、关系密切程度划分出来，部署到不同库上。 优点： 减少增量数据写入时的锁对查询的影响 由于单表数量下降，常见的查询操作由于减少了需要扫描的记录，使得单表单次查询所需的检索行数变少，减少了磁盘IO，时延变短 但是它无法解决单表数据量太大的问题 分库分表后的难题 分布式事务的问题，数据的完整性和一致性问题。 数据操作维度问题：用户、交易、订单各个不同的维度，用户查询维度、产品数据分析维度的不同对比分析角度。 跨库联合查询的问题，可能需要两次查询 跨节点的count、order by、group by以及聚合函数问题，可能需要分别在各个节点上得到结果后在应用程序端进行合并 额外的数据管理负担，如：访问数据表的导航定位 额外的数据运算压力，如：需要在多个节点执行，然后再合并计算程序编码开发难度提升，没有太好的框架解决，更多依赖业务看如何分，如何合，是个难题。 总结","link":"/2021/05/12/MySQL%EF%BC%88%E4%BA%94%EF%BC%89%E8%B0%83%E4%BC%98%E6%80%A7%E8%83%BD%E5%92%8C%E5%88%86%E5%8C%BA/"},{"title":"Netty（二）Reactor模型","text":"本篇主要讲述了三种Reactor模型： Reactor单线程模型 Reactor多线程模型 Reactor主从模型 三种Reactor模型生活场景的类比生活场景：饭店规模的扩大 一个人包揽所有活：迎宾、点菜、做饭、上菜、送客等。 多找几个伙计：大家一起做上面的事。 进一步分工：搞一个或多个人专门做迎宾。 类比： 饭店伙计：线程 迎宾：接入连接 点菜：请求 做菜：业务处理 上菜：响应 送客：断连 Reactor单线程模型最简单的单Reactor单线程模型。Reactor线程是个多面手，负责多路分离套接字，Accept新连接，并分派请求到处理器链中。该模型适用于处理器链中业务处理组件能快速完成的场景。不过,这种单线程模型不能充分利用多核资源，所以实际使用的不多。、 Reactor多线程模型该模型在处理器链部分采用了多线程（线程池）。 Reactor主从模型是将Reactor分成两部分，mainReactor负责监听server socket, accept新连接，并将建立的socket分派给subReactor。subReactor负责 多路分离已连接的socket,读写网络数据，对业务处理功能，其扔给worker线程池完成。 通常，subReactor个数 上可与CPU个数等同。 主从Reactor源码分析简单说就是两种SocketChannel绑定到两种Reactor模型中去完成主从模型的支持。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class EchoServer { private int port; public EchoServer(int port) { this.port = port; } public static void main(String[] args) throws Exception { new EchoServer(8833).start(); } public void start() throws Exception { //1.Reactor模型的主、从多线程 EventLoopGroup mainGroup = new NioEventLoopGroup(); EventLoopGroup childGroup = new NioEventLoopGroup(); try { //2.构造引导器实例ServerBootstrap ServerBootstrap b = new ServerBootstrap(); b.group(mainGroup, childGroup) .channel(NioServerSocketChannel.class) //2.1 设置NIO的channel .localAddress(new InetSocketAddress(port)) //2.2 配置本地监听端口 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { //2.3 初始化channel的时候，配置Handler @Override protected void initChannel(final SocketChannel socketChannel) { socketChannel.pipeline() .addLast(&quot;codec&quot;, new HttpServerCodec()) .addLast(&quot;compressor&quot;, new HttpContentCompressor()) .addLast(&quot;aggregator&quot;, new HttpObjectAggregator(65536)) .addLast(&quot;handler&quot;, new EchoServerHandler()); //2.4 加入自定义业务逻辑ChannelHandler } }); ChannelFuture f = b.bind().sync(); //3.启动监听 System.out.println(&quot;Http Server started， Listening on &quot; + port); f.channel().closeFuture().sync(); } finally { mainGroup.shutdownGracefully().sync(); childGroup.shutdownGracefully().sync(); } }}public class EchoServerHandler extends SimpleChannelInboundHandler&lt;FullHttpRequest&gt; { @Override protected void channelRead0(ChannelHandlerContext channelHandlerContext, FullHttpRequest fullHttpRequest) throws Exception { String content = String.format(&quot;Receive http request, url: %s , method: %s , content: %s%n&quot; ,fullHttpRequest.uri() ,fullHttpRequest.method() ,fullHttpRequest.content().toString().getBytes(StandardCharsets.UTF_8)); DefaultFullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK, Unpooled.wrappedBuffer(content.getBytes())); channelHandlerContext.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE); }}shengbinbin@chengbinbindeMacBook-Pro netty_example % curl http://localhost:8833/abcReceive http request, url: /abc , method: GET , content: [B@3e40b233 只需要创建两个EventLoopGroup，然后绑定到引导器ServerBootstrap上就好了. mainGroup 是主 Reactor，childGroup 是从 Reactor。它们分别使用不同的 NioEventLoopGroup，主 Reactor 负责处理 Accept，然后把 Channel 注册到从 Reactor 上，从 Reactor 主要负责 Channel 生命周期内的所有 I/O 事件。 1）什么是Channel Channel 的字面意思是“通道”，它是网络通信的载体，提供了基本的 API 用于网络 I/O 操作，如 register、bind、connect、read、write、flush 等。 Netty 实现的 Channel 是以 JDK NIO Channel 为基础的，提供了更高层次的抽象，屏蔽了底层 Socket。 2）什么是ChannleHandler和ChannelPipeline ChannelHandler实现对客户端发送过来的数据进行处理，可能包括编解码、自定义业务逻辑处理等等。 ChannelPipeline 负责组装各种 ChannelHandler，当 I/O 读写事件触发时，ChannelPipeline 会依次调用 ChannelHandler 列表对 Channel 的数据进行拦截和处理。 3）什么是EventLoopGroup？ EventLoopGroup 本质是一个线程池， 是 Netty Reactor 线程模型的具体实现方式，主要负责接收 I/O 请求，并分配线程执行处理请求。我们在demo中使用了它的实现类 NioEventLoopGroup，也是 Netty 中最被推荐使用的线程模型。 我们还通过构建main EventLoopGroup 和 child EventLoopGroup 实现了 “主从Reactor模式”。 4）EventLoopGroup、EventLoop、Channel有什么关系？ 一个 EventLoopGroup 往往包含一个或者多个 EventLoop。 EventLoop 用于处理 Channel 生命周期内的所有 I/O 事件，如 accept、connect、read、write 等 I/O 事件。 EventLoop 同一时间会与一个线程绑定，每个 EventLoop 负责处理多个 Channel。 1234567891011// Configure the server. //主从模型 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); //自定义业务逻辑 ChannelHandler final EchoServerHandler serverHandler = new EchoServerHandler(); try { //构造引导器实例ServerBootstrap ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) //加入主从group .channel(NioServerSocketChannel.class) //设置NIO的channel 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) { super.group(parentGroup); //加入主reactor模型 ObjectUtil.checkNotNull(childGroup, &quot;childGroup&quot;); if (this.childGroup != null) { throw new IllegalStateException(&quot;childGroup set already&quot;); } this.childGroup = childGroup; //加入从reactor模型 return this; }//====super.group(parentGroup)====public B group(EventLoopGroup group) { ObjectUtil.checkNotNull(group, &quot;group&quot;); if (this.group != null) { throw new IllegalStateException(&quot;group set already&quot;); } this.group = group; return self(); }//this.group = group;public abstract class AbstractBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; implements Cloneable { volatile EventLoopGroup group; //这个成员变量 final ChannelFuture initAndRegister() { Channel channel = null; try { channel = channelFactory.newChannel(); init(channel); } catch (Throwable t) { if (channel != null) { // channel can be null if newChannel crashed (eg SocketException(&quot;too many open files&quot;)) channel.unsafe().closeForcibly(); // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); } // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE).setFailure(t); } //开始register，将这个channel 注册到主Reactor模型中去，完成绑定关系，在这是ServerSocketChannel ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } // If we are here and the promise is not failed, it's one of the following cases: // 1) If we attempted registration from the event loop, the registration has been completed at this point. // i.e. It's safe to attempt bind() or connect() now because the channel has been registered. // 2) If we attempted registration from the other thread, the registration request has been successfully // added to the event loop's task queue for later execution. // i.e. It's safe to attempt bind() or connect() now: // because bind() or connect() will be executed *after* the scheduled registration task is executed // because register(), bind(), and connect() are all bound to the same thread. return regFuture; } 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) { super.group(parentGroup); ObjectUtil.checkNotNull(childGroup, &quot;childGroup&quot;); if (this.childGroup != null) { throw new IllegalStateException(&quot;childGroup set already&quot;); } this.childGroup = childGroup; return this; }private volatile EventLoopGroup childGroup; //从reactor模型就是这个成员变量@Override void init(Channel channel) { setChannelOptions(channel, options0().entrySet().toArray(newOptionArray(0)), logger); setAttributes(channel, attrs0().entrySet().toArray(newAttrArray(0))); ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; //childGroup就是currentChildGroup final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0)); final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0)); //ChannelInitializer一次性、初始化handler: //负责添加一个ServerBootstrapAcceptor handler，添加完后，自己就移除了: //ServerBootstrapAcceptor handler： 负责接收客户端连接创建连接后，对连接的初始化工作。 p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( //currentChildGroup传入进去 ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } }); }public void channelRead(ChannelHandlerContext ctx, Object msg) { final Channel child = (Channel) msg; //SocketChannel child.pipeline().addLast(childHandler); setChannelOptions(child, childOptions, logger); setAttributes(child, childAttrs); try { //这里的SocketChannel 绑定到从Reactor模型中去 childGroup.register(child).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { forceClose(child, future.cause()); } } }); } catch (Throwable t) { forceClose(child, t); } } 逻辑架构 服务端利用ServerBootstrap进行启动引导，绑定监听端口 启动初始化时有 main EventLoopGroup 和 child EventLoopGroup 两个组件，其中 main EventLoopGroup负责监听网络连接事件。当有新的网络连接时，就将 Channel 注册到 child EventLoopGroup。 child EventLoopGroup 会被分配一个 EventLoop 负责处理该 Channel 的读写事件。 当客户端发起 I/O 读写事件时，服务端 EventLoop 会进行数据的读取，然后通过 ChannelPipeline 依次有序触发各种ChannelHandler进行数据处理。 客户端数据会被依次传递到 ChannelPipeline 的 ChannelInboundHandler 中，在一个handler中处理完后就会传入下一个handler。 当数据写回客户端时，会将处理结果依次传递到 ChannelPipeline 的 ChannelOutboundHandler 中，在一个handler中处理完后就会传入下一个handler，最后返回客户端。","link":"/2021/05/24/Netty%EF%BC%88%E4%BA%8C%EF%BC%89Reactor%E6%A8%A1%E5%9E%8B/"},{"title":"Netty（三）TCP粘包和半包","text":"本篇讲述了什么是TCP的粘包和半包以及Netty是如何解决的 什么是粘包和半包代码演示123456789101112131415161718192021222324252627282930313233343536373839//服务端代码public class TimeServer { public void bind(int port) throws Exception { //初始化两个 loopGroup EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //服务端初始化的 bootstrap ServerBootstrap s = new ServerBootstrap(); //加载两个 loopGroup s.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024)//设置 NioServerSocketChannel 的 TCP 参数，设置 backlog 为 1024 .childHandler(new ChildChannelHandler()); //绑定 IO 事件处理类 ChildChannelHandler。 //异步监听端口，同步等待关闭 ChannelFuture f = s.bind(port).sync(); f.channel().closeFuture().sync(); }finally { //关闭两个 loopGroup bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; new TimeServer().bind(8080); }}public class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; { @Override protected void initChannel(SocketChannel ch) throws Exception { //获取 channel 的 pipeline，这里仅仅加进尾端 ch.pipeline().addLast(new TimeServerHandler()); }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//客户端代码public class TimeClient { public void connect(int port, String host) { // 创建客户端处理 IO 读写的 NioEventLoopGroup 线程组 EventLoopGroup group = new NioEventLoopGroup(); try { // 创建客户端辅助启动类 Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new FirstClientHandler()); } }); //调用connect发起异步请求，调用同步方法等待成功 ChannelFuture f = b.connect(host, port).sync(); f.channel().closeFuture().sync(); }catch (Exception e ) { }finally { group.shutdownGracefully(); } } public static void main(String[] args) { int port = 8080; new TimeClient().connect(port, &quot;127.0.0.1&quot;); }}public class FirstClientHandler extends ChannelInboundHandlerAdapter { @Override public void channelActive(ChannelHandlerContext ctx) { for (int i = 0; i &lt; 1000; i++) { ByteBuf buffer = getByteBuf(ctx); ctx.channel().writeAndFlush(buffer); } } private ByteBuf getByteBuf(ChannelHandlerContext ctx) { byte[] bytes = &quot;你好，我的名字是binshow!&quot;.getBytes(Charset.forName(&quot;utf-8&quot;)); ByteBuf buffer = ctx.alloc().buffer(); buffer.writeBytes(bytes); return buffer; } } 从服务端的控制台输出可以看出，存在三种类型的输出 一种是正常的字符串输出。 一种是多个字符串“粘”在了一起，我们定义这种 ByteBuf 为粘包。 一种是一个字符串被“拆”开，形成一个破碎的包，我们定义这种 ByteBuf 为半包。 原因分析 由图可以看出：发送端的字节流都会先传入缓冲区，再通过网络传入到接收端的缓冲区中，最终由接收端获取。 对于操作系统来说，只认TCP协议，尽管我们的应用层是按照 ByteBuf 为 单位来发送数据，server按照Bytebuf读取，但是到了底层操作系统仍然是按照字节流发送数据，因此，数据到了服务端，也是按照字节流的方式读入，然后到了 Netty 应用层面，重新拼装成ByteBuf，而这里的 ByteBuf 与客户端按顺序发送的 ByteBuf 可能是不对等的。因此，我们需要在客户端根据自定义协议来组装我们应用层的数据包，然后在服务端根据我们的应用层的协议来组装数据包，这个过程通常在服务端称为拆包，而在客户端称为粘包。 粘包的主要原因： 发送方每次写入数据 &lt; 套接字缓冲区大小 接收方读取套接字缓冲区数据不够及时 半包的主要原因： 发送方写入数据 &gt; 套接字缓冲区大小 发送的数据大于协议的MTU（最大传输单元），必须拆包 根本原因：TCP是流式协议，消息是无边界的。而UDP虽然一次运输多个包裹，但是每个包裹是有边界的，所以没有粘包等现象。 Netty对三种常用封帧方式的支持在没有 Netty 的情况下，用户如果自己需要拆包，基本原理就是不断从 TCP 缓冲区中读取数据，每次读取完都需要判断是否是一个完整的数据包 如果当前读取的数据不足以拼接成一个完整的业务数据包，那就保留该数据，继续从 TCP 缓冲区中读取，直到得到一个完整的数据包。 如果当前读到的数据加上已经读取的数据足够拼接成一个数据包，那就将已经读取的数据拼接上本次读取的数据，构成一个完整的业务数据包传递到业务逻辑，多余的数据仍然保留，以便和下次读到的数据尝试拼接。 而在Netty中，已经造好了许多类型的拆包器，我们直接用就好： FixedLengthFrameDecoder固定长度的拆包器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class TimeClient { public void connect(int port, String host) { // 创建客户端处理 IO 读写的 NioEventLoopGroup 线程组 EventLoopGroup group = new NioEventLoopGroup(); try { // 创建客户端辅助启动类 Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new FirstClientHandler()); ch.pipeline().addLast(new FixedLengthFrameDecoder(32)); // } }); //调用connect发起异步请求，调用同步方法等待成功 ChannelFuture f = b.connect(host, port).sync(); f.channel().closeFuture().sync(); }catch (Exception e ) { }finally { group.shutdownGracefully(); } } public static void main(String[] args) { int port = 8080; new TimeClient().connect(port, &quot;127.0.0.1&quot;); }}public class TimeServer { public void bind(int port) throws Exception { //初始化两个 loopGroup EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //服务端初始化的 bookstrap ServerBootstrap s = new ServerBootstrap(); //加载两个 loopGroup s.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024)//设置 NioServerSocketChannel 的 TCP 参数，设置 backlog 为 1024 //.childHandler(new ChildChannelHandler()); //绑定 IO 事件处理类 ChildChannelHandler。 .childHandler(new ChannelInitializer() { @Override protected void initChannel(Channel channel) throws Exception { ChannelPipeline pipeline = channel.pipeline(); pipeline.addLast(new FixedLengthFrameDecoder(32)); pipeline.addLast(new ChildChannelHandler()); } }); //异步监听端口，同步等待关闭 ChannelFuture f = s.bind(port).sync(); f.channel().closeFuture().sync(); }finally { //关闭两个 loopGroup bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; new TimeServer().bind(8080); }} LineBasedFrameDecoder每个数据包之间以换行符作为分隔符。 1234567891011121314151617181920212223242526272829303132public class TimeServer { public void bind(int port) throws Exception { //初始化两个 loopGroup EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //服务端初始化的 bootstrap ServerBootstrap s = new ServerBootstrap(); //加载两个 loopGroup s.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) .childHandler(new ChildChannelHandler()); //异步监听端口，同步等待关闭 ChannelFuture f = s.bind(port).sync(); f.channel().closeFuture().sync(); }finally { //关闭两个 loopGroup bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; new TimeServer().bind(8080); }} 12345678910111213public class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; { @Override protected void initChannel(SocketChannel ch) throws Exception { // 以行为编解码基础的 LineBasedFrameDecoder，并设置最大行字节为 1024 ch.pipeline().addLast(new LineBasedFrameDecoder(1024)); //2使用 StringDecoder 将链条中的前结点编解码结果解码为字符串 ch.pipeline().addLast(new StringDecoder()); //3.根据链条中的前结点的编解码结果进行业务逻辑处理 ch.pipeline().addLast(new TimeServerHandler()); }} 12345678910111213141516171819202122232425262728293031323334public class TimeClient { public void connect(int port, String host) { // 创建客户端处理 IO 读写的 NioEventLoopGroup 线程组 EventLoopGroup group = new NioEventLoopGroup(); try { // 创建客户端辅助启动类 Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new LineBasedFrameDecoder(1024)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new TimeClientHandler()); } }); //调用connect发起异步请求，调用同步方法等待成功 ChannelFuture f = b.connect(host, port).sync(); f.channel().closeFuture().sync(); }catch (Exception e ) { }finally { group.shutdownGracefully(); } } public static void main(String[] args) { int port = 8080; new TimeClient().connect(port, &quot;127.0.0.1&quot;); }} 123456789101112131415161718192021222324252627282930313233343536373839public class TimeClientHandler extends ChannelInboundHandlerAdapter { //日志记录 private static final Logger logger = Logger.getLogger(TimeClientHandler.class.getName()); private int counter; private byte[] req; public TimeClientHandler() { req = (&quot;QUERY TIME ORDER&quot; + System.getProperty(&quot;line.separator&quot;)).getBytes(); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ByteBuf message = null; for (int i=0;i&lt;100;i++) { message= Unpooled.buffer(req.length); message.writeBytes(req); ctx.writeAndFlush(message); } } //当客户端和服务端tcp链路建立成功之后，netty的nio线程会调用channelActive方法 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { String body = (String) msg; System.out.println(&quot;now is : &quot; + body + &quot; ; the counter is : &quot; + ++counter); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { logger.warning(&quot;unexpected exception from downstream: &quot; + cause.getMessage()); ctx.close(); }} DelimiterBasedFrameDecoder1234567891011121314151617181920212223242526272829303132333435363738394041public class EchoServer { public void bind(int port) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap s = new ServerBootstrap(); s.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) //添加日志 .handler(new LoggingHandler()) //处理 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { protected void initChannel(SocketChannel ch) throws Exception { //根据 &quot;$_&quot; 作为分隔符，然后进行分割 ByteBuf delimitoer = Unpooled.copiedBuffer(&quot;$_&quot;.getBytes()); //根据指定分隔符来切割信息流的开始和结束 ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, delimitoer)); //字符串解码 ch.pipeline().addLast(new StringDecoder()); //将字符传递给服务端处理器 ch.pipeline().addLast(new EchoServerHandler()); } }); ChannelFuture f = s.bind(port).sync(); f.channel().closeFuture().sync(); }catch (Exception e) { }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { new EchoServer().bind(8080); }} 12345678910111213141516171819public class EchoServerHandler extends ChannelInboundHandlerAdapter { int count = 0; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { String body = (String) msg; System.out.println(&quot;this is &quot;+ ++count + &quot; times receive client:[&quot; + body + &quot;]&quot; ); body += &quot;$_&quot;; ByteBuf echo = Unpooled.copiedBuffer(body.getBytes()); ctx.writeAndFlush(echo); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 123456789101112131415161718192021222324252627282930313233public class EchoClient { public void connect(int port, String host) { // 创建客户端处理 IO 读写的 NioEventLoopGroup 线程组 EventLoopGroup group = new NioEventLoopGroup(); try { // 创建客户端辅助启动类 Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { protected void initChannel(SocketChannel ch) throws Exception { ByteBuf delimitoer = Unpooled.copiedBuffer(&quot;$_&quot;.getBytes()); ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, delimitoer)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new EchoClientHandler()); } }); //调用connect发起异步请求，调用同步方法等待成功 ChannelFuture f = b.connect(host, port).sync(); f.channel().closeFuture().sync(); }catch (Exception e ) { }finally { group.shutdownGracefully(); } } public static void main(String[] args) { new EchoClient().connect(8080, &quot;127.0.0.1&quot;); }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class EchoClient { public void connect(int port, String host) { // 创建客户端处理 IO 读写的 NioEventLoopGroup 线程组 EventLoopGroup group = new NioEventLoopGroup(); try { // 创建客户端辅助启动类 Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { protected void initChannel(SocketChannel ch) throws Exception { ByteBuf delimitoer = Unpooled.copiedBuffer(&quot;$_&quot;.getBytes()); ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, delimitoer)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new EchoClientHandler()); } }); //调用connect发起异步请求，调用同步方法等待成功 ChannelFuture f = b.connect(host, port).sync(); f.channel().closeFuture().sync(); }catch (Exception e ) { }finally { group.shutdownGracefully(); } } public static void main(String[] args) { new EchoClient().connect(8080, &quot;127.0.0.1&quot;); }}//而客户端处理器需要输出结果，查看是不是有分隔符没分割成功的问题public class EchoClientHandler extends ChannelInboundHandlerAdapter { private int counter; static final String ECHO_REQ = &quot;Hi, Lilinfeng. welcome to Netty.$_&quot;; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { for (int i=0;i &lt; 100;i++) { ctx.writeAndFlush(Unpooled.copiedBuffer(ECHO_REQ.getBytes())); } } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(&quot;this is &quot;+ ++counter + &quot; times receive server :[&quot; + msg + &quot;]&quot;); } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 源码解读","link":"/2021/05/24/Netty%EF%BC%88%E4%B8%89%EF%BC%89TCP%E7%B2%98%E5%8C%85%E5%92%8C%E5%8D%8A%E5%8C%85/"},{"title":"Netty（五）锁和内存使用","text":"本篇讲述了Netty中对锁的正确使用和对内存的分配原则 Netty中如何正确的使用锁锁的对象和范围–减少粒度1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950=======ServerBootstrap=======@Override void init(Channel channel) throws Exception { final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0();//无线程安全问题 synchronized (options) { //针对这两种属性来锁 setChannelOptions(channel, options, logger); } final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) { for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) { @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); } } ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; synchronized (childOptions) { currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0)); } synchronized (childAttrs) { currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0)); } p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } }); } 锁的对象本身大小–减少空间占用12345678910111213141516171819=====ChannelOutboundBuffer===== private static final AtomicLongFieldUpdater&lt;ChannelOutboundBuffer&gt; TOTAL_PENDING_SIZE_UPDATER = AtomicLongFieldUpdater.newUpdater(ChannelOutboundBuffer.class, &quot;totalPendingSize&quot;); private volatile long totalPendingSize; //统计待发送的字节数 private static final AtomicIntegerFieldUpdater&lt;ChannelOutboundBuffer&gt; UNWRITABLE_UPDATER = AtomicIntegerFieldUpdater.newUpdater(ChannelOutboundBuffer.class, &quot;unwritable&quot;); private void incrementPendingOutboundBytes(long size, boolean invokeLater) { if (size == 0) { return; } long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size); if (newWriteBufferSize &gt; channel.config().getWriteBufferHighWaterMark()) { setUnwritable(invokeLater); } } Atomic long VS long： 前者是一个对象，包含对象头（object header）以用来保存 hashcode、lock 等信息，32 位系统占用8字节；64 位系统占 16 字节，所以在 64 位系统情况下： volatile long = 8 bytes AtomicLong = 8 bytes （volatile long）+ 16bytes （对象头）+ 8 bytes (引用) = 32 bytes至少节约 24 字节! 结论：Atomic* objects -&gt; Volatile primary type + Static Atomic*FieldUpdater 锁的速度–提高并发性记录内存分配字节数等功能用到的 LongCounter（io.netty.util.internal.PlatformDependent#newLongCounter() ） 123456789101112131415161718=====PlatformDependent=====public static LongCounter newLongCounter() { if (javaVersion() &gt;= 8) { //判断JDK的版本 return new LongAdderCounter(); } else { return new AtomicLongCounter(); } }//继承JDK中的 LongAdder，在高并发下比较优秀final class LongAdderCounter extends LongAdder implements LongCounter { @Override public long value() { return longValue(); }} 不同场景选择不同的并发包例1：关闭和等待关闭事件执行器（Event Executor）： Object.wait/notify -&gt; CountDownLatch 1234567=====SingleThreadEventExecutor=====private volatile ThreadProperties threadProperties; private final Executor executor; private volatile boolean interrupted; private final CountDownLatch threadLock = new CountDownLatch(1); private final Set&lt;Runnable&gt; shutdownHooks = new LinkedHashSet&lt;Runnable&gt;(); 例2：Nio Event loop中负责存储task的Queue Jdk’s LinkedBlockingQueue (MPMC) -&gt; jctools’ MPSC 123456789io.netty.util.internal.PlatformDependent.Mpsc#newMpscQueue(int)：static &lt;T&gt; Queue&lt;T&gt; newMpscQueue(final int maxCapacity) { // Calculate the max capacity which can not be bigger then MAX_ALLOWED_MPSC_CAPACITY. // This is forced by the MpscChunkedArrayQueue implementation as will try to round it // up to the next power of two and so will overflow otherwise. final int capacity = max(min(maxCapacity, MAX_ALLOWED_MPSC_CAPACITY), MIN_MAX_MPSC_CAPACITY); return USE_MPSC_CHUNKED_ARRAY_QUEUE ? new MpscChunkedArrayQueue&lt;T&gt;(MPSC_CHUNK_SIZE, capacity) : new MpscGrowableAtomicArrayQueue&lt;T&gt;(MPSC_CHUNK_SIZE, capacity); } 避免用锁 Netty 应用场景下：局部串行 + 整体并行 &gt; 一个队列 + 多个线程模式: 降低用户开发难度、逻辑简单、提升处理性能 避免锁带来的上下文切换和并发保护等额外开销 避免用锁：用 ThreadLocal 来避免资源争用，例如 Netty 轻量级的线程池实现 Netty如何使用内存减少对像本身大小 用基本类型就不要用包装类 应该定义成类变量的不要定义为实例变量 对分配内存进行预估 对于已经可以预知固定 size 的 HashMap避免扩容 1234567891011121314=====com.google.common.collect.Maps#newHashMapWithExpectedSize===== public static &lt;K, V&gt; HashMap&lt;K, V&gt; newHashMapWithExpectedSize(int expectedSize) { return new HashMap(capacity(expectedSize)); } static int capacity(int expectedSize) { if (expectedSize &lt; 3) { CollectPreconditions.checkNonnegative(expectedSize, &quot;expectedSize&quot;); return expectedSize + 1; } else { return expectedSize &lt; 1073741824 ? (int)((float)expectedSize / 0.75F + 1.0F) : 2147483647; } } Netty 根据接受到的数据动态调整（guess）下个要分配的 Buffer 的大小 123456789101112131415161718192021222324252627======io.netty.channel.AdaptiveRecvByteBufAllocator====== /** * 接受数据buffer的容量会尽可能的足够大以接受数据 * 也尽可能的小以不会浪费它的空间 * @param actualReadBytes */ private void record(int actualReadBytes) { //尝试是否可以减小分配的空间仍然能满足需求： //尝试方法：当前实际读取的size是否小于或等于打算缩小的尺寸 if (actualReadBytes &lt;= SIZE_TABLE[max(0, index - INDEX_DECREMENT - 1)]) { //decreaseNow: 连续2次尝试减小都可以 if (decreaseNow) { //减小 index = max(index - INDEX_DECREMENT, minIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; } else { decreaseNow = true; } //判断是否实际读取的数据大于等于预估的，如果是，尝试扩容 } else if (actualReadBytes &gt;= nextReceiveBufferSize) { index = min(index + INDEX_INCREMENT, maxIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; } } Zero-Copy零拷贝 使用逻辑组合，代替实际复制。 12345678910111213141516171819202122232425262728293031323334=====io.netty.handler.codec.ByteToMessageDecoder======public static final Cumulator COMPOSITE_CUMULATOR = new Cumulator() { @Override public ByteBuf cumulate(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf in) { ByteBuf buffer; try { if (cumulation.refCnt() &gt; 1) { buffer = expandCumulation(alloc, cumulation, in.readableBytes()); buffer.writeBytes(in); } else { CompositeByteBuf composite; //创建composite bytebuf，如果已经创建过，就不用了 if (cumulation instanceof CompositeByteBuf) { composite = (CompositeByteBuf) cumulation; } else { composite = alloc.compositeBuffer(Integer.MAX_VALUE); composite.addComponent(true, cumulation); } //避免内存复制 composite.addComponent(true, in); in = null; buffer = composite; } return buffer; } finally { if (in != null) { // We must release if the ownership was not transferred as otherwise it may produce a leak if // writeBytes(...) throw for whatever release (for example because of OutOfMemoryError). in.release(); } } } }; 使用包装，代替实际复制。 12byte[] bytes = data.getBytes(); ByteBuf byteBuf = Unpooled.wrappedBuffer(bytes); 调用 JDK 的 Zero-Copy 接口。 Netty 中也通过在 DefaultFileRegion 中包装了 NIO 的 FileChannel.transferTo() 方法实现了零拷贝：io.netty.channel.DefaultFileRegion#transferTo 1234567891011121314151617181920212223242526272829@Override public long transferTo(WritableByteChannel target, long position) throws IOException { long count = this.count - position; if (count &lt; 0 || position &lt; 0) { throw new IllegalArgumentException( &quot;position out of range: &quot; + position + &quot; (expected: 0 - &quot; + (this.count - 1) + ')'); } if (count == 0) { return 0L; } if (refCnt() == 0) { throw new IllegalReferenceCountException(0); } // Call open to make sure fc is initialized. This is a no-oop if we called it before. open(); long written = file.transferTo(this.position + position, count, target);//这里调用了 if (written &gt; 0) { transferred += written; } else if (written == 0) { // If the amount of written data is 0 we need to check if the requested count is bigger then the // actual file itself as it may have been truncated on disk. // // See https://github.com/netty/netty/issues/8868 validate(this, position); } return written; } 堆外内存 优点： 更广阔的“空间 ”，缓解店铺内压力 -&gt; 破除堆空间限制，减轻 GC 压力 减少“冗余”细节（假设烧烤过程为了气氛在室外进行：烤好直接上桌：vs 烤好还要进店内）-&gt; 避免复制 缺点： 需要搬桌子 -&gt; 创建速度稍慢 受城管管、风险大 -&gt; 堆外内存受操作系统管理 内存池为什么引入对象池： 创建对象开销大 对象高频率创建且可复用 支持并发又能保护系统 维护、共享有限的资源 如何实现对象池？ 开源实现：Apache Commons Pool Netty 轻量级对象池实现 io.netty.util.Recycler 源码解读12345678910111213141516171819202122232425262728293031323334353637383940//主从模型 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); //自定义业务逻辑 ChannelHandler final EchoServerHandler serverHandler = new EchoServerHandler(); try { //构造引导器实例ServerBootstrap ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) //设置NIO的channel .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) //两种设置keepalive风格 .childOption(ChannelOption.SO_KEEPALIVE, true) .childOption(NioChannelOption.SO_KEEPALIVE, true) //切换到unpooled的方式之一,切换内存池参数之一 .childOption(ChannelOption.ALLOCATOR, UnpooledByteBufAllocator.DEFAULT) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline p = ch.pipeline(); if (sslCtx != null) { p.addLast(sslCtx.newHandler(ch.alloc())); } p.addLast(new LoggingHandler(LogLevel.INFO)); p.addLast(serverHandler); } }); // Start the server. ChannelFuture f = b.bind(PORT).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); } finally { // Shut down all event loops to terminate all threads. bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } 12345678910111213141516171819202122232425262728293031323334353637383940414243=====DefaultChannelConfig====== //默认bytebuf分配器 private volatile ByteBufAllocator allocator = ByteBufAllocator.DEFAULT;======ByteBufUtil====== private static final byte WRITE_UTF_UNKNOWN = (byte) '?'; private static final int MAX_CHAR_BUFFER_SIZE; private static final int THREAD_LOCAL_BUFFER_SIZE; private static final int MAX_BYTES_PER_CHAR_UTF8 = (int) CharsetUtil.encoder(CharsetUtil.UTF_8).maxBytesPerChar(); static final int WRITE_CHUNK_SIZE = 8192; static final ByteBufAllocator DEFAULT_ALLOCATOR; static { //以io.netty.allocator.type为准，没有的话，安卓平台用非池化实现，其他用池化实现 //读取io.netty.allocator.typ，如果没有的话就看是不是安卓平台 String allocType = SystemPropertyUtil.get( &quot;io.netty.allocator.type&quot;, PlatformDependent.isAndroid() ? &quot;unpooled&quot; : &quot;pooled&quot;); allocType = allocType.toLowerCase(Locale.US).trim(); ByteBufAllocator alloc; if (&quot;unpooled&quot;.equals(allocType)) { alloc = UnpooledByteBufAllocator.DEFAULT; logger.debug(&quot;-Dio.netty.allocator.type: {}&quot;, allocType); } else if (&quot;pooled&quot;.equals(allocType)) { alloc = PooledByteBufAllocator.DEFAULT; logger.debug(&quot;-Dio.netty.allocator.type: {}&quot;, allocType); } else { //io.netty.allocator.type设置的不是&quot;unpooled&quot;或者&quot;pooled&quot;，就用池化实现。 alloc = PooledByteBufAllocator.DEFAULT; logger.debug(&quot;-Dio.netty.allocator.type: pooled (unknown: {})&quot;, allocType); } DEFAULT_ALLOCATOR = alloc; //默认使用了池化的技术 THREAD_LOCAL_BUFFER_SIZE = SystemPropertyUtil.getInt(&quot;io.netty.threadLocalDirectBufferSize&quot;, 0); logger.debug(&quot;-Dio.netty.threadLocalDirectBufferSize: {}&quot;, THREAD_LOCAL_BUFFER_SIZE); MAX_CHAR_BUFFER_SIZE = SystemPropertyUtil.getInt(&quot;io.netty.maxThreadLocalCharBufferSize&quot;, 16 * 1024); logger.debug(&quot;-Dio.netty.maxThreadLocalCharBufferSize: {}&quot;, MAX_CHAR_BUFFER_SIZE); } 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061===== PooledDirectByteBuf ===== final class PooledDirectByteBuf extends PooledByteBuf&lt;ByteBuffer&gt; { private static final Recycler&lt;PooledDirectByteBuf&gt; RECYCLER = new Recycler&lt;PooledDirectByteBuf&gt;() { @Override protected PooledDirectByteBuf newObject(Handle&lt;PooledDirectByteBuf&gt; handle) { return new PooledDirectByteBuf(handle, 0); } }; //从“池”里借一个用 static PooledDirectByteBuf newInstance(int maxCapacity) { PooledDirectByteBuf buf = RECYCLER.get(); buf.reuse(maxCapacity); return buf; } ===== RECYCLER ===== public final T get() { if (maxCapacityPerThread == 0) { //表明没有开启池化 return newObject((Handle&lt;T&gt;) NOOP_HANDLE); } Stack&lt;T&gt; stack = threadLocal.get(); DefaultHandle&lt;T&gt; handle = stack.pop(); //试图从“池”中取出一个，没有就新建一个 if (handle == null) { handle = stack.newHandle(); handle.value = newObject(handle); } return (T) handle.value; } static final class DefaultHandle&lt;T&gt; implements Handle&lt;T&gt; { private int lastRecycledId; private int recycleId; boolean hasBeenRecycled; private Stack&lt;?&gt; stack; private Object value; DefaultHandle(Stack&lt;?&gt; stack) { this.stack = stack; } @Override public void recycle(Object object) { if (object != value) { throw new IllegalArgumentException(&quot;object does not belong to handle&quot;); } Stack&lt;?&gt; stack = this.stack; if (lastRecycledId != recycleId || stack == null) { throw new IllegalStateException(&quot;recycled already&quot;); } //释放用完的对象到池里面去 stack.push(this); } } 如何切换堆内内存和堆外内存方法 1：参数设置 io.netty.noPreferDirect = true; 方法 2：传入构造参数false ServerBootstrap serverBootStrap = new ServerBootstrap(); UnpooledByteBufAllocator unpooledByteBufAllocator = new UnpooledByteBufAllocator(false); serverBootStrap.childOption(ChannelOption.ALLOCATOR, unpooledByteBufAllocator) 123456789101112public static final UnpooledByteBufAllocator DEFAULT = new UnpooledByteBufAllocator(PlatformDependent.directBufferPreferred());====== PlatformDependent ======// We should always prefer direct buffers by default if we can use a Cleaner to release direct buffers. //使用堆外内存两个条件：1 有cleaner方法去释放堆外内存； 2 io.netty.noPreferDirect 不能设置为true DIRECT_BUFFER_PREFERRED = CLEANER != NOOP &amp;&amp; !SystemPropertyUtil.getBoolean(&quot;io.netty.noPreferDirect&quot;, false);//参数指定 if (logger.isDebugEnabled()) { logger.debug(&quot;-Dio.netty.noPreferDirect: {}&quot;, !DIRECT_BUFFER_PREFERRED); } 堆外内存的分配？ ByteBuffer.allocateDirect(initialCapacity)","link":"/2021/05/25/Netty%EF%BC%88%E4%BA%94%EF%BC%89%E9%94%81%E5%92%8C%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8/"},{"title":"Netty（七）案例编写和调优参数","text":"","link":"/2021/05/27/Netty%EF%BC%88%E4%B8%83%EF%BC%89%E6%A1%88%E4%BE%8B%E7%BC%96%E5%86%99%E5%92%8C%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0/"},{"title":"Netty（四）编解码技术","text":"本篇主要讲述了 二次编码 keepalive和idle检测 为什么需要二次编码我们把解决半包和粘包问题的常用三种解码器叫做一次解码器，这层解码的结果是字节。 我们在项目中使用的是对象，需要和字节进行相互转换，所以二次解码器就是将字节转换成对象。相对应的编码器就是将Java对象转换成字节流方便存储或传输。 一次解码器：ByteToMessageDecoder io.netty.buffer.ByteBuf(原始数据流,可能出现粘包或半包) –&gt; io.netty.buffer.ByteBuf(用户数据的字节数组) 二次解码器：MessageToMessageDecoder io.netty.buffer.ByteBuf(用户数据的字节数组) –&gt; java Object 常用的二次编解码方式 Java序列号 XML JSON ProtoBuf Marshaling 选择编解码方式的特点 压缩后的空间大小 编解码的时间速度 可读性 多语言的支持 Protobuf的简介和使用源码解读12345678public class ByteArrayDecoder extends MessageToMessageDecoder&lt;ByteBuf&gt; { @Override protected void decode(ChannelHandlerContext ctx, ByteBuf msg, List&lt;Object&gt; out) throws Exception { // copy the ByteBuf content to a byte array //将netty的ByteBuf 转换成JDK中的字节数组 out.add(ByteBufUtil.getBytes(msg)); }} Keepalive和Idle检测为什么需要keepalive生活场景类比： 订餐电话场景 服务器应用 电话线路 数据连接（TCP 连接） 交谈的话语 数据 通话双方 数据发送和接收方 对比\\场景 订餐电话场景 服务器应用 需要 keepalive 的场景 对方临时着急走开 对端异常“崩溃” 对方在，但是很忙，不知道什么时候忙完 对端在，但是处理不过来 电话线路故障 对端在，但是不可达 不做 keepalive 的后果 线路占用，耽误其他人订餐 连接已坏，但是还浪费资源维持，下次直接用会直接报错 如何设计keepalive？以TCP中为例TCP keepalive 核心参数： # sysctl -a|grep tcp_keepalive net.ipv4.tcp_keepalive_time = 7200 net.ipv4.tcp_keepalive_intvl = 75 net.ipv4.tcp_keepalive_probes = 9 当启用（默认关闭）keepalive 时，TCP 在连接没有数据通过的7200秒后发送 keepalive 消息，当探测没有确认时，按75秒的重试频率重发，一直发 9 个探测包都没有确认，就认定连接失效。 所以总耗时一般为：2 小时 11 分钟 (7200 秒 + 75 秒* 9 次) 为什么应用层还需要keepalive ? 协议分层，各层关注点不同：传输层关注是否“通”，应用层关注是否可服务？ 类比前面的电话订餐例子，电话能通，不代表有人接；服务器连接在，但是不定可以服务（例如服务不过来等）。 TCP 层的 keepalive 默认关闭，且经过路由等中转设备 keepalive 包可能会被丢弃。 TCP 层的 keepalive 时间太长：默认 &gt; 2 小时，虽然可改，但属于系统参数，改动影响所有应用。 HTTP 属于应用层协议，但是常常听到名词“ HTTP Keep-Alive ”指的是对长连接和短连接的选择： • Connection : Keep-Alive 长连接（HTTP/1.1 默认长连接，不需要带这个 header） • Connection : Close 短连接 idle检测是什么 Idle 监测，只是负责诊断，诊断后，做出不同的行为，决定 Idle 监测的最终用途： 发送 keepalive :一般用来配合 keepalive ，减少 keepalive 消息。 Keepalive 设计演进：V1 定时 keepalive 消息 -&gt; V2 空闲监测 + 判定为 Idle 时才发keepalive。 V1：keepalive 消息与服务器正常消息交换完全不关联，定时就发送； V2：有其他数据传输的时候，不发送 keepalive ，无数据传输超过一定时间，判定为 Idle，再发 keepalive 。 如何开启keepalive和idle1234567891011在server端： //构造引导器实例ServerBootstrap ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) //设置NIO的channel .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) //两种设置keepalive风格 .childOption(ChannelOption.SO_KEEPALIVE, true) .childOption(NioChannelOption.SO_KEEPALIVE, true)","link":"/2021/05/25/Netty%EF%BC%88%E5%9B%9B%EF%BC%89%E7%BC%96%E8%A7%A3%E7%A0%81%E6%8A%80%E6%9C%AF/"},{"title":"Java并发理论基础-下","text":"Java并发理论基础下章主要描述了以下内容 Lock接口实现的锁 常见的并发容器 常见的并发工具类 线程池 Lock接口synchronized在1.6之后做了很多的优化，效率提高了很多，但是还有很多问题是synchronized无法解决的，因此Lock接口及其实现方法就出现了： 能够响应中断。synchronized 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程。但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有机会释放曾经持有的锁 A。这样就破坏了不可抢占条件了。 支持超时。如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。 非阻塞地获取锁。如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。 API接口方法123456void lock(); //获取锁，调用该方法的线程会获得锁，获得锁之后从该方法返回void lockInterruptibly() throws InterruptedException; //可中断的获得锁boolean tryLock(); //尝试非阻塞的获取锁，调用该方法后立即返回，如果能获取返回true，否则返回falseboolean tryLock(long time, TimeUnit unit) throws InterruptedException; //超时的获取锁void unlock(); //释放锁Condition newCondition(); //获取等待通知组件，该组件和当前锁绑定，当前线程获得了锁之后才能调用组件的wait方法释放锁 Lock的一般使用实例1234567Lock lock = new ReentrantLock(); lock.lock(); try { //业务逻辑 }finally { lock.unlock();//在finally块中释放锁，目的是保证在获取到锁之后，最终能够被释放。 } synchronized和ReentrantLock的区别 synchronized是JVM内建的同步机制，是一个关键字，ReentrantLock是一个类。 ReentrantLock可以实现公平锁，可以自定义条件，可以定义超时时间，需要显式的释放锁，而synchronized只能是非公平锁。 每一个lock操作，为了保证锁的释放，最好在finally中显式的unlock lock只适用于代码块，而synchronized可以用来修饰方法，代码块 在Java6之前，synchronized完全依靠操作系统的互斥锁来实现，需要进行用户态和内核态的切换，所以开销较大，但随着一系列的锁优化，synchronized的性能也越来越好了 队列同步器AQSAQS的全称是AbstractQueuedSynchronizer，它的定位是为Java中几乎所有的锁和同步器提供一个基础框架。 AQS是基于FIFO的队列实现的，并且内部维护了一个volatile修饰的状态变量state，通过原子更新这个状态变量state即可以实现加锁解锁操作。 AQS的源码解析 主要内部类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647static final class Node { //初始化两个节点引用 static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; static final int CANCELLED = 1; // 标识线程已取消 static final int SIGNAL = -1; // 标识后继节点需要唤醒 static final int CONDITION = -2; // 标识线程等待在一个条件上 static final int PROPAGATE = -3; // 标识后面的共享锁需要无条件的传播（共享锁需要连续唤醒读的线程） volatile int waitStatus; //// 当前节点保存的线程对应的等待状态 volatile Node prev; volatile Node next; volatile Thread thread; // 当前节点保存的线程 Node nextWaiter; final boolean isShared() { return nextWaiter == SHARED; } final Node predecessor() throws NullPointerException { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } Node() { // Used to establish initial head or SHARED marker } Node(Thread thread, Node mode) { // Used by addWaiter this.nextWaiter = mode; this.thread = thread; } Node(Thread thread, int waitStatus) { // Used by Condition this.waitStatus = waitStatus; this.thread = thread; } } 主要属性 123456789101112131415161718 private transient volatile Node head; //维护一个头节点和尾节点的引用 private transient volatile Node tail; private volatile int state; //同步状态，用volatile修饰 //获取当前同步状态 protected final intgetState() { return state; } //设置新的同步状态 protected final void setState(int newState) { state = newState;} //通过unsafe类的CAS修改同步状态 protected final boolean compareAndSetState(int expect, int update) { // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } 子类需要实现的方法–模版方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495//提供给子类重写，独占式的获取同步状态，实现该方法需要查询当前状态并判断是否符合预期，然后用CAS来设置同步状态 protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } //提供给子类重写，独占式的释放同步状态，等待的线程将有机会获取同步状态 protected boolean tryRelease(int arg) { throw new UnsupportedOperationException(); } //共享式的获取同步状态，返回值大于0表示成功 protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException(); } //共享式的释放同步状态 protected boolean tryReleaseShared(int arg) { throw new UnsupportedOperationException(); } //当前同步器是否在独占模式下被线程占用 protected boolean isHeldExclusively() { throw new UnsupportedOperationException(); } //独占式获取同步状态，获取成功则返回，否则进入同步队列等待 public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } //和上面这个方法相同，但是响应中断 public final void acquireInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); } //在上面的方法中增加了时间限制 public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout); } //独占式释放同步状态，释放后唤醒同步队列中的第一个节点 public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } //共享式的获取同步状态，主要区别是同一时间可以有多个线程获取到同步状态 public final void acquireShared(int arg) { if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); } //和上面相同，响应中断 public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); } public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); return tryAcquireShared(arg) &gt;= 0 || doAcquireSharedNanos(arg, nanosTimeout); } //共享式的释放同步状态 public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; } 节点加入等待队列流程同步器将节点加入到同步队列的过程：加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法:**compareAndSetTail(Node expect,Node update)**，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式 与之前的尾节点建立关联。 1234private final boolean compareAndSetTail(Node expect, Node update) { return unsafe.compareAndSwapObject(this, tailOffset, expect, update);} 设置首节点的过程设置首节点的过程：同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。 设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节 点设置成为原首节点的后继节点并断开原首节点的next引用即可。 acquire流程分析123456AQS ----&gt; acquire()public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 123456789101112131415161718192021222324252627282930313233343536373839404142tryAcquire 方法针对公平锁和非公平锁有着不同的实现，总的来说是保证线程安全的获取同步状态 //Fair version of tryAcquire. Don't grant access unless recursive call or no waiters or is first. protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; //hasQueuedPredecessors 是公平锁和非公平锁的区别 compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //可重入锁的实现 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } 如果tryAcquire不能获取锁： 123456789101112131415161718192021222324252627282930313233343536373839404142434445//构造新的尾节点，通过CAS来放入队列尾部//Creates and enqueues node for current thread and given mode.Params://mode – Node.EXCLUSIVE for exclusive, Node.SHARED for sharedReturns://the new nodeprivate Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); ////如果多个线程获取同步状态失败，并发的添加到list，也许会顺序混乱，通过CAS变 得“串行化”了 return node; }/*Inserts node into queue, initializing if necessary. See picture above.Params:node – the node to insertReturns:node's predecessor*/private Node enq(final Node node) { for (;;) { ////通过“死循环”来保证节点的正确添加 Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; //只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线 程不断地尝试设置 if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 12345678910111213141516171819202122//acquireQueued --- 节点进入同步队列之后，就进入了一个自旋的过程，每个节点(或者说每个线程)都在自 省地观察，当条件满足，获取到了同步状态，就可以从这个自旋过程中退出，否则依旧留在这 个自旋过程中(并会阻塞节点的线程):final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { //死循环自旋的过程 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } acquire方法调用流程： 前驱节点为头节点且能够获取同步状态的判断条件和线程进入等待状态是获 取同步状态的自旋过程。当同步状态获取成功之后，当前线程从acquire(int arg)方法返回，如果 对于锁这种并发组件而言，代表着当前线程获取了锁。 当前线程获取同步状态并执行了相应逻辑之后，就需要释放同步状态，使得后续节点能 够继续获取同步状态。通过调用同步器的release(int arg)方法可以释放同步状态，该方法在释 放了同步状态之后，会唤醒其后继节点(进而使后继节点重新尝试获取同步状态)。 12345678910@ReservedStackAccess public final boolean release(int arg) { if (tryRelease(arg)) { //tryRelease针对公平锁和非公平锁也有不同的实现 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } 重入锁重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞，该特性的实现需要解决以下两个问题。 线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。 锁的最终释放。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。 12345678910111213141516171819protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { //如果当前线程就是拥有锁的线程 int nextc = c + acquires; //则共享变量++ if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } 读写锁读写锁，并不是 Java 语言特有的，而是一个广为使用的通用技术，所有的读写锁都遵守以下三条基本原则： 允许多个线程同时读共享变量； 只允许一个线程写共享变量； 如果一个写线程正在执行写操作，此时禁止读线程读共享变量。 读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升。 LockSupport类LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread) 方法来唤醒一个被阻塞的线程： 1234567891011public static void park(Object blocker) { //阻塞当前线程 Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null); }public static void unpark(Thread thread) { //唤醒当前线程 if (thread != null) UNSAFE.unpark(thread); } Condition接口等待通知模式：任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、 wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式 Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式 新版生产者和消费者一般都会将Condition对象作为成员变量。当调用await()方法后，当前线程会释放锁并在此等待，而其他线程调用Condition对象的signal()方法，通知当前线程后，当前线程才从await()方法返回，并且在返回前已经获取了锁 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class SharedDate{ //共享资源类 private int num = 0; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void increment(){ lock.lock(); try { while (num != 0) condition.await(); //1. 判断释放满足条件，注意用while num++; //2. 业务逻辑 System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); condition.signal(); //3. 唤醒其他线程 } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } public void decrement(){ lock.lock(); try { while (num == 0) condition.await(); num--; System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); condition.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }}/** 需求：两个线程操作一个初始值为0的变量，一个线程操作变量+1，另一个线程操作变量-1。操作10次后变量依旧为0 * */public class ConditionDemo { public static void main(String[] args) { // 线程操作资源类 SharedDate sharedDate = new SharedDate(); Thread a = new Thread(()-&gt;{ for (int i = 0; i &lt; 5; i++) { sharedDate.increment(); } },&quot;A&quot;); Thread b = new Thread(()-&gt;{ for (int i = 0; i &lt; 5; i++) { sharedDate.decrement(); } },&quot;B&quot;); a.start(); b.start(); } } 精确通知不同的等待者12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485class SharedDate{ //共享资源类 private int num = 1; //1 A ，2 B ， 3 C private Lock lock = new ReentrantLock(); private Condition c1 = lock.newCondition(); //多个条件实现精确通知 private Condition c2 = lock.newCondition(); private Condition c3 = lock.newCondition(); public void print2(int a){ lock.lock(); try { while (num != 1) c1.await(); for (int i = 0; i &lt; a; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); } num = 2; //要修改状态位，以此来唤醒不同的线程 c2.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } public void print4(int a){ lock.lock(); try { while (num != 2) c2.await(); for (int i = 0; i &lt; a; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); } num = 3;//要修改状态位，以此来唤醒不同的线程 c3.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } public void print8(int a){ lock.lock(); try { while (num != 3) c3.await(); for (int i = 0; i &lt; a; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); } num = 1;//要修改状态位，以此来唤醒不同的线程 c1.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }}/** 需求：三个线程依次打印1，2，3。其中A线程打印2次，B线程打印4次，C线程打印6次** */public class ConditionDemo { public static void main(String[] args) { // 线程操作资源类 SharedDate sharedDate = new SharedDate(); Thread a = new Thread(()-&gt;{ sharedDate.print2(2); },&quot;A&quot;); Thread b = new Thread(()-&gt;{ sharedDate.print4(4); },&quot;B&quot;); Thread c = new Thread(()-&gt;{ sharedDate.print8(8); },&quot;C&quot;); a.start(); b.start(); c.start(); }} Java并发容器CopyOnWriteArrayListCopyOnWrite，顾名思义就是写的时候会将共享变量新复制一份出来，这样做的好处是读操作完全无锁 CopyOnWriteArrayList 内部维护了一个数组，成员变量 array 就指向这个内部数组，所有的读操作都是基于 array 进行的。 如果在遍历 array 的同时，还有一个写操作，例如增加元素，CopyOnWriteArrayList 是如何处理的呢？CopyOnWriteArrayList 会将 array 复制一份，然后在新复制处理的数组上执行增加元素的操作，执行完之后再将 array 指向这个新的数组。通过下图你可以看到，读写是可以并行的，遍历操作一直都是基于原 array 执行，而写操作则是基于新 array 进行。 ConcurrentHashMap1.1 为什么要使用ConcurrentHashMap hashMap线程不安全，hashtable效率低下 ConcurrentHashMap的锁分段技术可有效提升并发访问率，首先将数据分成一段一段地存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问 1.2 结构![image-20210502103840847](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210502103840847.png) ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁（ReentrantLock），在ConcurrentHashMap里扮演锁的角色；HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似，是一种数组和链表结构。一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得与它对应的Segment锁 1.3 初始化1.4 定位segment1.5 常用的方法操作2. ConcurrentLinkedQueue3. Java中的阻塞队列3.1 什么是阻塞队列阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。 1）支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。 2）支持阻塞的移除方法：意思是在队列为空时，获取元素的线程会等待队列变为非空。 阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器 3.2 常见的阻塞队列种类JDK 7提供了7个阻塞队列，如下。 ·ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。 ·LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。 ·PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。 ·DelayQueue：一个使用优先级队列实现的无界阻塞队列。 ·SynchronousQueue：一个不存储元素的阻塞队列。 ·LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 ·LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。 3.3 阻塞队列的实现原理ArrayBlockingQueue使用了Condition来实现 1234567891011121314151617181920212223242526272829303132333435363738394041/** Condition for waiting takes */private fnal Condition notEmpty;/** Condition for waiting puts */private fnal Condition notFull;public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); }//put方法public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == items.length) notFull.await(); enqueue(e); } finally { lock.unlock(); } }//take public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) notEmpty.await(); return dequeue(); } finally { lock.unlock(); } } 第七部分、13个原子操作类1. 原子更新基本类型3个·AtomicBoolean：原子更新布尔类型。 ·AtomicInteger：原子更新整型。 ·AtomicLong：原子更新长整型。 1.1 实现原理基于CAS（compare-and-swap）技术来实现的，所谓CAS，表征的是一些列操作的集合，获取当前数值，进行一些运算，利用CAS指令试图进行更新。如果当前数值未变，代表没有其他线程进行并发修改，则成功更新。否则，可能出现不同的选择，要么进行重试，要么就返回一个成功或者失败的结果。 1234567891011121314151617181920public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); //使用了unsafe类 private static final long valueOffset; private volatile int value; //volatile修饰的变量 static { try { valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } public AtomicInteger(int initialValue) { value = initialValue; } public AtomicInteger() { } 12345678910111213141516public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1); //调用的是unsafe类中的方法实现原子自增的 }public final int getAndAddInt(Object o, long offset, int delta) { int v; do { v = getIntVolatile(o, offset); } while (!compareAndSwapInt(o, offset, v, v + delta)); return v; }//cas底层是unsafe类中的本地方法，依赖于CPU提供的特定指令public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); 1.2 CAS的问题 CAS也并不是没有副作用，试想，其常用的失败重试机制，隐含着一个假设，即竞争情况是短暂的。大多数应用场景中，确实大部分重试只会发生一次就获得了成功，但是总是有意外情况，所以在有需要的时候，还是要考虑限制自旋的次数，以免过度消耗CPU。 另外一个就是著名的ABA问题，这是通常只在lock-free算法下暴露的问题。我前面说过CAS是在更新时比较前值，如果对方只是恰好相同，例如期间发生了 A -&gt; B -&gt; A的更新，仅仅判断数值是A，可能导致不合理的修改操作。针对这种情况，Java提供了AtomicStampedReference工具类，通过为引用建立类似版本号（stamp）的方式，来保证CAS的正确性 2. 原子更新数组·AtomicIntegerArray：原子更新整型数组里的元素。 ·AtomicLongArray：原子更新长整型数组里的元素。 ·AtomicReferenceArray：原子更新引用类型数组里的元素。 ·AtomicIntegerArray类主要是提供原子的方式更新数组里的整型，其常用方法如下。 3.原子更新引用类型4. 原子更新字段类第八部分、并发工具类1.倒计时器CountDownLatchCountDownLatch允许一个或多个线程等待其他线程完成操作。 运动员进行跑步比赛时，假设有 6 个运动员参与比赛，裁判员在终点会为这 6 个运动员分别计时，可以想象没当一个运动员到达终点的时候，对于裁判员来说就少了一个计时任务。直到所有运动员都到达终点了，裁判员的任务也才完成。这 6 个运动员可以类比成 6 个线程，当线程调用 CountDownLatch.countDown 方法时就会对计数器的值减一，直到计数器的值为 0 的时候，裁判员（调用 await 方法的线程）才能继续往下执行。 1.1 方法解析12345//整型数 N，之后调用 CountDownLatch 的countDown方法会对 N 减一，知道 N 减到 0 的时候，当前调用await方法的线程继续执行。public CountDownLatch(int count) { if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync = new Sync(count); } public void await() throws InterruptedException：调用await()方法的线程会被挂起，等待直到count值为0再继续执行。 public boolean await(long timeout, TimeUnit unit) throws InterruptedException：同await()，若等待timeout时长后，count值还是没有变为0，不再等待，继续执行。时间单位如下常用的毫秒、天、小时、微秒、分钟、纳秒、秒。 public void countDown()： count值递减1. public long getCount()：获取当前count值。 public String toString()：重写了toString()方法，多打印了count值，具体参考源码。 1.2 使用实例 创建CountDownLatch并设置计数器值。 启动多线程并且调用CountDownLatch实例的countDown()方法。 主线程调用 await() 方法，这样主线程的操作就会在这个方法上阻塞，直到其他线程完成各自的任务，count值为0，停止阻塞，主线程继续执行。 123456789101112131415161718192021222324252627282930313233343536373839404142public class CountDownLatchDemo { //线程数 private static int N = 10; // 单位：min private static int countDownLatchTimeout = 5; public static void main(String[] args) { //创建CountDownLatch并设置计数值，该count值可以根据线程数的需要设置 CountDownLatch countDownLatch = new CountDownLatch(N); //创建线程池 ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; N; i++) { cachedThreadPool.execute(() -&gt; { try { System.out.println(Thread.currentThread().getName() + &quot; do something!&quot;); } catch (Exception e) { System.out.println(&quot;Exception: do something exception&quot;); } finally { //该线程执行完毕-1 countDownLatch.countDown(); } }); } System.out.println(&quot;main thread do something-1&quot;); try { countDownLatch.await(countDownLatchTimeout, TimeUnit.MINUTES); } catch (InterruptedException e) { System.out.println(&quot;Exception: await interrupted exception&quot;); } finally { System.out.println(&quot;countDownLatch: &quot; + countDownLatch.toString()); } System.out.println(&quot;main thread do something-2&quot;); //若需要停止线程池可关闭;// cachedThreadPool.shutdown(); }} 2.循环栅栏：CyclicBarrier 开运动会时，会有跑步这一项运动，我们来模拟下运动员入场时的情况，假设有 6 条跑道，在比赛开始时，就需要 6 个运动员在比赛开始的时候都站在起点了，裁判员吹哨后才能开始跑步。跑道起点就相当于“barrier”，是临界点，而这 6 个运动员就类比成线程的话，就是这 6 个线程都必须到达指定点了，意味着凑齐了一波，然后才能继续执行，否则每个线程都得阻塞等待，直至凑齐一波即可。cyclic 是循环的意思，也就是说 CyclicBarrier 当多个线程凑齐了一波之后，仍然有效，可以继续凑齐下一波 2.1 常用方法12345678910//等到所有的线程都到达指定的临界点await() throws InterruptedException, BrokenBarrierException//与上面的await方法功能基本一致，只不过这里有超时限制，阻塞等待直至到达超时时间为止await(long timeout, TimeUnit unit) throws InterruptedException,BrokenBarrierException, TimeoutException//获取当前有多少个线程阻塞等待在临界点上int getNumberWaiting()//用于查询阻塞等待的线程是否被中断boolean isBroken() 2.2 使用实例123456789101112131415161718192021222324public class CyclicBarrierDemo { //指定必须有6个运动员到达才行 private static CyclicBarrier barrier = new CyclicBarrier(6, () -&gt; { System.out.println(&quot;所有运动员入场，裁判员一声令下！！！！！&quot;); }); public static void main(String[] args) { System.out.println(&quot;运动员准备进场，全场欢呼............&quot;); ExecutorService service = Executors.newFixedThreadPool(6); for (int i = 0; i &amp;lt; 6; i++) { service.execute(() -&amp;gt; { try { System.out.println(Thread.currentThread().getName() + &quot; 运动员，进场&quot;); barrier.await(); System.out.println(Thread.currentThread().getName() + &quot; 运动员出发&quot;); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }); }}} 2.3 CyclicBarrier 和CountDownLatch 的区别 CountDownLatch是不可以重置的，所以无法重用；而CyclicBarrier则没有这种限制，可以重用。 CountDownLatch的基本操作组合是countDown/await。调用await的线程阻塞等待countDown足够的次数，不管你是在一个线程还是多个线程里countDown，只要次数足够即可。所以就像Brain Goetz说过的，CountDownLatch操作的是事件。 CyclicBarrier的基本操作组合，则就是await，当所有的伙伴（parties）都调用了await，才会继续进行任务，并自动进行重置。注意，正常情况下，CyclicBarrier的重置都是自动发生的，如果我们调用reset方法，但还有线程在等待，就会导致等待线程被打扰，抛出BrokenBarrierException异常。CyclicBarrier侧重点是线程，而不是调用事件，它的典型应用场景是用来等待并发线程结束。 3.控制并发线程数的SemaphoreSemaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源 第九部分、线程池1. 为什么要使用线程池第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 第三：提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。但是，要做到合理利用线程池，必须对其实现原理了如指掌。 2. 线程池的实现原理2.1五种不同的标准线程池Executors目前提供了5种不同的线程池创建配置： newCachedThreadPool()，它是一种用来处理大量短时间工作任务的线程池，具有几个鲜明特点：它会试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置的时间超过60秒，则被终止并移出缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用SynchronousQueue作为工作队列。 newFixedThreadPool(int nThreads)，重用指定数目（nThreads）的线程，其背后使用的是无界的工作队列，任何时候最多有nThreads个工作线程是活动的。这意味着，如果任务数量超过了活动队列数目，将在工作队列中等待空闲线程出现；如果有工作线程退出，将会有新的工作线程被创建，以补足指定的数目nThreads。 newSingleThreadExecutor()，它的特点在于工作线程数目被限制为1，操作一个无界的工作队列，所以它保证了所有任务的都是被顺序执行，最多会有一个任务处于活动状态，并且不允许使用者改动线程池实例，因此可以避免其改变线程数目。 newSingleThreadScheduledExecutor()和newScheduledThreadPool(int corePoolSize)，创建的是个ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程。 newWorkStealingPool(int parallelism)，这是一个经常被人忽略的线程池，Java 8才加入这个创建方法，其内部会构建ForkJoinPool，利用Work-Stealing算法，并行地处理任务，不保证处理顺序。 2.2 创建七大参数 corePoolSize：核心线程数 maximumPoolSize：最大线程数 keepAliveTime：线程存活时间 TimeUnit：存活时间的单位 workQueue：工作队列，必须是阻塞队列 ThreadFactory ：创建线程的工厂 RejectedExecutionHandler：拒绝执行的策略 2.3 四大拒绝策略·AbortPolicy：直接抛出异常。 ·CallerRunsPolicy：只用调用者所在线程来运行任务。 ·DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。 ·DiscardPolicy：不处理，丢弃掉。 Ps：可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。如记录日志或持久化存储不能处理的任务。 2.4 任务处理流程![image-20210502114404422](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210502114404422.png) 2.5 提交任务submit和execute execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。 execute()方法输入的任务是一个Runnable类的实例。 submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。 2.6 线程池的大小选择策略 如果是计算型任务，说明CPU是一种稀缺的资源，线程太多会导致上下文切换，所以线程数一般为按照CPU核的数目N或者N+1； 如果是IO密集型任务，线程数 = CPU核数 × （1 + 平均等待时间/平均工作时间） 第十部分、Executor框架1. Executor框架简介1.1Executor框架的两级调度模型 在HotSpot VM的线程模型中，Java线程（java.lang.Thread）被一对一映射为本地操作系统线 程。Java线程启动时会创建一个本地操作系统线程；当该Java线程终止时，这个操作系统线程也会被回收。操作系统会调度所有线程并将它们分配给可用的CPU。 在上层，Java多线程程序通常把应用分解为若干个任务，然后使用用户级的调度器（Executor框架）将这些任务映射为固定数量的线程；在底层，操作系统内核将这些线程映射到硬件处理器上: ![image-20210503091113831](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210503091113831.png) 1.2 三大组成部分 任务。包括被执行任务需要实现的接口：Runnable接口或Callable接口。 任务的执行。包括任务执行机制的核心接口Executor，以及继承自Executor的 ExecutorService接口。Executor框架有两个关键类实现了ExecutorService接口 （ThreadPoolExecutor和ScheduledThreadPoolExecutor）。 异步计算的结果。包括接口Future和实现Future接口的FutureTask类。 ![image-20210503091241378](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210503091241378.png) 2. ThreadPoolExecutor详解Executor框架最核心的类是ThreadPoolExecutor，它是线程池的实现类，主要由下列4个组件构成。 ·corePool：核心线程池的大小。 ·maximumPool：最大线程池的大小。 ·BlockingQueue：用来暂时保存任务的工作队列。 ·RejectedExecutionHandler：当ThreadPoolExecutor已经关闭或ThreadPoolExecutor已经饱和 时（达到了最大线程池大小且工作队列已满），execute()方法将要调用的Handler。 2.1 FixedThreadPoolFixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads。 123456public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory); } keepAliveTime设置为0L，意味着多余的空闲线程会被立即终止 FixedThreadPool使用无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为 Integer.MAX_VALUE）。使用无界队列作为工作队列会对线程池带来如下影响: 1）当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中 的线程数不会超过corePoolSize。 2）由于1，使用无界队列时maximumPoolSize将是一个无效参数。 3）由于1和2，使用无界队列时keepAliveTime将是一个无效参数。 4）由于使用无界队列，运行中的FixedThreadPool（未执行方法shutdown()或 shutdownNow()）不会拒绝任务（不会调用RejectedExecutionHandler.rejectedExecution方法）。 2.2 SingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); } SingleThreadExecutor的corePoolSize和maximumPoolSize被设置为1。其他参数与 FixedThreadPool相同。SingleThreadExecutor使用无界队列LinkedBlockingQueue作为线程池的工 作队列（队列的容量为Integer.MAX_VALUE）。SingleThreadExecutor使用无界队列作为工作队列 对线程池带来的影响与FixedThreadPool相同. 2.3 CachedThreadPool12345public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); } CachedThreadPool的corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置为 Integer.MAX_VALUE，即maximumPool是无界的。这里把keepAliveTime设置为60L，意味着 CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被 终止。 如果主线程提交任务的速度高于 maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下， CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。","link":"/2021/05/07/Java%E5%B9%B6%E5%8F%91%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80-%E4%B8%8B/"},{"title":"Redis（三）过期键删除和持久化","text":"Redis过期键的删除和持久化策略 过期键删除键过期的本质是什么可能存在的删除策略Redis如何删除过期键的持久化 Redis 用做缓存时，直接从内存中读取数据，响应速度会非常快。但是一旦服务器宕机，内存中的数据将全部丢失。 从后端数据库恢复这些数据，但这种方式存在两个问题： 一是，需要频繁访问数据库，会给数据库带来巨大的压力； 二是，这些数据是从慢速数据库中读取出来的，性能肯定比不上从 Redis 中读取，导致使用这些数据的应用程序响应变慢。 所以，对 Redis 来说，实现数据的持久化，避免从后端数据库中进行恢复，是至关重要的。 AOF（Append Only File）为什么是写后日志之前学习MySQL的时候接触的都是数据库的写前日志（Write Ahead Log, WAL），也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。 但是在Redis中却恰恰相反， Redis 是先执行命令，把数据写入内存，然后才记录日志。 那么为什么要这样设置呢？ 传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。 “*3”表示当前命令有三个部分，每部分都是由“$+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“$3set”表示这部分有 3 个字节，也就是“set”命令。 为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。 有两个缺陷： 如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。 AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。 三种写回策略在AOF的配置文件中，AOF 机制给我们提供了三个选择，也就是 AOF 配置项appendfsync 的三个可选值。 Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘； Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘； No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。 “同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能；虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了；“每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。 想要获得高性能，就选择 No 策略；如果想要得到高可靠性保证，就选择Always 策略；如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择Everysec 策略。 AOF文件重写AOF 文件过大会带来一系列性能问题，主要在于以下三个方面： 文件系统本身对文件大小有限制，无法保存过大的文件； 如果文件太大，之后再往里面追加命令记录的话，效率也会变低； 如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。 AOF 重写机制就是在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。比如说，当读取了键值对“testkey”:“testvalue”之后，重写机制会记录 settestkey testvalue 这条命令。 我们知道，AOF 文件是以追加的方式，逐一记录接收到的写命令的。当一个键值对被多条写命令反复修改时，AOF 文件会记录相应的多条命令。但是，在重写的时候，是根据这个键值对当前的最新状态，为它生成对应的写入命令。这样一来，一个键值对在重写日志中只用一条命令就行了，而且，在日志恢复时，只用执行这条命令，就可以直接完成这个键值对的写入了。 AOF重写会阻塞主线程吗AOF 日志重写的时候，是由 bgrewriteaof 子进程来完成的，不用主线程参与，这也是为了避免阻塞主线程，导致数据库性能下降。 每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，子进程这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。 所谓fork子进程指的是，子进程是会拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。子进程复制了父进程页表，也能共享访问父进程的内存数据了，此时，类似于有了父进程的所有内存数据。 因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。 RDB（Redis DataBase ）内存快照 给哪些内存数据做快照？Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是全量快照，也就是说，把内存中的所有数据都记录到磁盘中 Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave save：在主线程中执行，会导致阻塞； bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是Redis RDB 文件生成的默认配置。 避免阻塞和正常处理写操作并不是一回事！！！。此时，主线程的确没有阻塞，可以正常接收请求，但是，为了保证快照完整性，它只能处理读操作，因为不能修改正在执行快照的数据。为了快照而暂停写操作，肯定是不能接受的。所以这个时候，Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。 简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。 快照频率如何确定如果频繁地执行全量快照，也会带来两方面的开销。 一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。 另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。 我们可以做增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。 它需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。 虽然跟 AOF 相比，快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销，那么，还有什么方法既能利用 RDB 的快速恢复，又能以较小的开销做到尽量少丢数据呢？ AOF 日志和内存快照混合Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。 这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。 关于 AOF 和 RDB 的选择问题，我想再给你提三点建议： 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择； 如果允许分钟级别的数据丢失，可以只使用 RDB； 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。","link":"/2021/05/13/Redis%EF%BC%88%E4%B8%89%EF%BC%89%E8%BF%87%E6%9C%9F%E9%94%AE%E5%88%A0%E9%99%A4%E5%92%8C%E6%8C%81%E4%B9%85%E5%8C%96/"},{"title":"Netty（六）流程源码解析","text":"本篇讲述了Netty启动过程中的源码分析： 启动服务 构建连接 接受数据 业务处理 发送数据 断开连接 关闭服务 实例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344public class EchoServer { private int port; public EchoServer(int port) { this.port = port; } public static void main(String[] args) throws Exception { new EchoServer(8833).start(); } public void start() throws Exception { //1.Reactor模型的主、从多线程 EventLoopGroup mainGroup = new NioEventLoopGroup(); EventLoopGroup childGroup = new NioEventLoopGroup(); try { //2.构造引导器实例ServerBootstrap ServerBootstrap b = new ServerBootstrap(); b.group(mainGroup, childGroup) .channel(NioServerSocketChannel.class) //2.1 设置NIO的channel .option(ChannelOption.SO_BACKLOG, 1024) .localAddress(new InetSocketAddress(port)) //2.2 配置本地监听端口 .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { //2.3 初始化channel的时候，配置Handler @Override protected void initChannel(final SocketChannel socketChannel) { socketChannel.pipeline() .addLast(&quot;codec&quot;, new HttpServerCodec()) .addLast(&quot;compressor&quot;, new HttpContentCompressor()) .addLast(&quot;aggregator&quot;, new HttpObjectAggregator(65536)) .addLast(&quot;handler&quot;, new EchoServerHandler()); //2.4 加入自定义业务逻辑ChannelHandler } }); ChannelFuture f = b.bind().sync(); //3.启动监听 System.out.println(&quot;Http Server started， Listening on &quot; + port); f.channel().closeFuture().sync(); } finally { mainGroup.shutdownGracefully().sync(); childGroup.shutdownGracefully().sync(); } }} 启动服务 创建NioEventLoopGroup12EventLoopGroup bossGroup = new NioEventLoopGroup(); //bossGroup 负责的是接受请求EventLoopGroup workerGroup = new NioEventLoopGroup();//workerGroup 负责的是处理请求 EventLoopGroup 就是一个死循环，不停地检测IO事件，处理IO事件，执行任务。 创建selector1Selector selector = sun.nio.ch.SelectorProviderImpl.openSelector() ServerBootstrap 参数配置group()方法传入Reactor模型通过 ServerBootstrap 的方法 group() 传入之后，会设置成为 ServerBootstrap 的 parentGroup 和 childGroup 12 ServerBootstrap b = new ServerBootstrap();b.group(mainGroup, childGroup) 123456789101112131415161718192021=====ServerBootstrap=====public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) { super.group(parentGroup);//切换到 AbstractBootstrap ObjectUtil.checkNotNull(childGroup, &quot;childGroup&quot;); if (this.childGroup != null) { throw new IllegalStateException(&quot;childGroup set already&quot;); } this.childGroup = childGroup; return this; }//AbstractBootstrap 需要使用 parentGroup 来注册监听外部请求（OP_ACCEPT 事件）的 Channel=====AbstractBootstrap=====public B group(EventLoopGroup group) { ObjectUtil.checkNotNull(group, &quot;group&quot;); if (this.group != null) { throw new IllegalStateException(&quot;group set already&quot;); } this.group = group; return self(); } 设置服务端Channel1.channel(NioServerSocketChannel.class) 12345678910111213141516171819这个 channel 实际上是 AbstractBootstrap 抽象类的方法，因为这个是可以共用的。然后 AbstractBootstrap 会交给其成员函数 channelFactory()，通过实例化参数来控制怎么根据 class 来生成 channel。=====AbstractBootstrap=====public B channel(Class&lt;? extends C&gt; channelClass) { return channelFactory(new ReflectiveChannelFactory&lt;C&gt;( ObjectUtil.checkNotNull(channelClass, &quot;channelClass&quot;) )); }=====ReflectiveChannelFactory=====public ReflectiveChannelFactory(Class&lt;? extends T&gt; clazz) { ObjectUtil.checkNotNull(clazz, &quot;clazz&quot;); try { this.constructor = clazz.getConstructor(); //通过反射获取构造器，再创建channel实例 } catch (NoSuchMethodException e) { throw new IllegalArgumentException(&quot;Class &quot; + StringUtil.simpleClassName(clazz) + &quot; does not have a public non-arg constructor&quot;, e); } } 对于服务端来说，创建的一般是public io.netty.channel.socket.nio.NioServerSocketChannel() option方法设置TCP参数1.option(ChannelOption.SO_BACKLOG, 1024)//主要是设置 TCP 的 backlog 参数，这个设置之后主要是调用底层 C 对应的接口 为什么要设置这个参数呢？这个参数实际上指定内核为此套接口排队的最大连接个数。对于给定的套接字接口，内核要维护两个对列：未连接队列和已连接队列。那是因为在 TCP 的三次握手过程中三个分节来分隔这两个队列。下面是整个过程的一个讲解： 如果服务器处于 listen 时，收到客户端的 syn 分节（connect）时在未完成队列中创建一个新的条目，然后用三路握手的第二个分节即服务器的 syn 响应客户端。 新条目会直到第三个分节到达前（客户端对服务器 syn 的 ack）都会一直保留在未完成连接队列中，如果三路握手完成，该条目将从未完成队列搬到已完成队列的尾部。 当进程调用 accept 时，从已完成队列的头部取一条目给进程，当已完成队列为空的时候进程就睡眠，直到有条目在已完成连接队列中才唤醒。 现在说到了重点，backlog 其实是两个队列的总和的最大值，大多数实现默认值为 5。但是高并发的情况之下，并不够用。因为可能客户端 syn 的到达以及等待三路握手第三个分节的到达延时而增大。 所以我们需要根据实际场景和网络状况进行灵活配置 设置服务端的 Handler123456789101112//父类中的 Handler 是客户端新接入的连接 SocketChannel 对应的 ChannelPipeline 的 Handler.handler(new LoggingHandler(LogLevel.INFO)) //子类中的 Handler 是 NioServerSocketChannel 对应的 ChannelPipeline 的 Handler .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { //2.3 初始化channel的时候，配置Handler @Override protected void initChannel(final SocketChannel socketChannel) { socketChannel.pipeline() .addLast(&quot;codec&quot;, new HttpServerCodec()) .addLast(&quot;compressor&quot;, new HttpContentCompressor()) .addLast(&quot;aggregator&quot;, new HttpObjectAggregator(65536)) .addLast(&quot;handler&quot;, new EchoServerHandler()); //2.4 加入自定义业务逻辑ChannelHandler } 上面代码有两个 handler 方法，区别在于 handler() 方法是 NioServerSocketChannel 使用的，所有连接该监听端口的客户端都会执行它；父类 AbstractBootstrap 中的 Handler 是个工厂类，它为每个接入的客户端都创建一个新的 Handler。 绑定本地端口然后启动服务1ChannelFuture f = b.bind().sync(); //3.启动监听 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151=====AbstractBootstrap=====public ChannelFuture bind() { validate();//验证服务启动需要的必要参数 SocketAddress localAddress = this.localAddress; if (localAddress == null) { throw new IllegalStateException(&quot;localAddress not set&quot;); } return doBind(localAddress); } private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); //初始化一个 channel， final Channel channel = regFuture.channel(); //获取 channel if (regFuture.cause() != null) { return regFuture; } if (regFuture.isDone()) {//如果这个 channel 的注册事件完成了 // At this point we know that the registration was complete and successful. //再产生一个异步任务，进行端口监听 ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; } else { // Registration future is almost always fulfilled already, but just in case it's not. //设置一个进度条的任务，等待注册事件完成后，就开始端口的监听 final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); } else { // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); } } }); return promise; } }final ChannelFuture initAndRegister() { Channel channel = null; try { channel = channelFactory.newChannel();//通过 channel 工厂生成一个 channel init(channel); } catch (Throwable t) { if (channel != null) { // channel can be null if newChannel crashed (eg SocketException(&quot;too many open files&quot;)) channel.unsafe().closeForcibly(); // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); } // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE).setFailure(t); } ChannelFuture regFuture = config().group().register(channel);//将这个 channel 注册进 parentEventLoop if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } return regFuture; }===== ServerBootstrap ===== void init(Channel channel) throws Exception { final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) { setChannelOptions(channel, options, logger);//设置 channel 的 option } final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) { for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) { @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); ////设置属性 } } ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; synchronized (childOptions) { currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0)); } synchronized (childAttrs) { currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0)); } p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ////获取 pipeline //这里获取的 handler，对应的是 AbstractBootstrap 的 handler，这个是通过 ServerBootstrap.handler() 方法设置的 ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler);//添加进入 pipeline，这个是为了让每个处理的都能首先调用这个 handler } //执行任务，设置子 handler。这里对用的是 ServerBootstrap.childHandler() 方法设置的 handler ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } }); }=====AbstractBootstrap=====private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) { // This method is invoked before channelRegistered() is triggered. Give user handlers a chance to set up // the pipeline in its channelRegistered() implementation. //执行到这里，说明任务已经被注册到 loopgroup //所以可以开始一个监听端口的任务 channel.eventLoop().execute(new Runnable() { @Override public void run() { if (regFuture.isSuccess()) { channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); } else { promise.setFailure(regFuture.cause()); } } }); } initAndRegister初始化注册到selectorchannelFactory.newChannel()1234567891011121314151617181920212223242526272829303132final ChannelFuture initAndRegister() { Channel channel = null; try { //1. 将channelClass作为ReflectiveChannelFactory的构造函数创建出一个ReflectiveChannelFactory channel = channelFactory.newChannel(); init(channel); } catch (Throwable t) { if (channel != null) { // channel can be null if newChannel crashed (eg SocketException(&quot;too many open files&quot;)) channel.unsafe().closeForcibly(); // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); } // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE).setFailure(t); } //config().group()指的是 ServerBootstrap 的 parentLoopGroup ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } return regFuture; } new 一个channel，这里的channel是在服务启动的时候创建，我们可以和普通Socket编程中的ServerSocket对应上，表示服务端绑定的时候经过的一条流水线。 将channelClass作为ReflectiveChannelFactory的构造函数创建出一个ReflectiveChannelFactory，最终创建channel相当于调用默认构造函数new出一个 NioServerSocketChannel对象 123456789101112public NioServerSocketChannel() { this(newSocket(DEFAULT_SELECTOR_PROVIDER)); }private static ServerSocketChannel newSocket(SelectorProvider provider) { try { return provider.openServerSocketChannel(); //创建一条server端channel } catch (IOException e) { throw new ChannelException( &quot;Failed to open a server socket.&quot;, e); } } 总结一下，用户调用方法 Bootstrap.bind(port) 第一步就是通过反射的方式new一个NioServerSocketChannel对象，并且在new的过程中创建了一系列的核心组件 init(channel)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253=====ServerBootstrap=====@Override void init(Channel channel) throws Exception { //1.设置option和attr final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) { setChannelOptions(channel, options, logger); } final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) { for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) { @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); } } ChannelPipeline p = channel.pipeline(); //2. 设置新接入channel的option和attr final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; synchronized (childOptions) { currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0)); } synchronized (childAttrs) { currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0)); } //3.加入新连接处理器 //向serverChannel的流水线处理器中加入了一个 ServerBootstrapAcceptor(这是一个接入器，专门接受新请求，把新的请求扔给某个事件循环器) p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } }); } config().group().register(channel)1234=====MultithreadEventLoopGroup======public ChannelFuture register(Channel channel) { return next().register(channel); } 123456=====MultithreadEventExecutorGroup=====@Override public EventExecutor next() { return chooser.next(); }//这里的 chooser 是 MultithreadEventExecutorGroup 的成员属性，它可以对根据目前 ExectuorGroup 中的 EventExecutor 的情况策略选择 EventExecutor。这里默认使用的是 DefaultEventExecutorChooserFactory，这个是基于轮询策略操作的。 PowerOfTwoEventExecutorChooser 按位与(&amp;)操作符 GenericEventExecutorChooser 取模(%)运算符 12345678910111213141516171819202122232425262728===== DefaultEventExecutorChooserFactory =====private static final class PowerOfTwoEventExecutorChooser implements EventExecutorChooser { private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; PowerOfTwoEventExecutorChooser(EventExecutor[] executors) { this.executors = executors; } @Override public EventExecutor next() { return executors[idx.getAndIncrement() &amp; executors.length - 1]; } } private static final class GenericEventExecutorChooser implements EventExecutorChooser { private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; GenericEventExecutorChooser(EventExecutor[] executors) { this.executors = executors; } @Override public EventExecutor next() { return executors[Math.abs(idx.getAndIncrement() % executors.length)]; } } chooserFactory 最后会选择出 EventExecutor 后，就可以将 Channel 进行注册了。在 Netty 的 NioEventLoopGroup 中 EventExecutor 都是 SingleThreadEventLoop 来承担的（如果你继续跟进代码的话，你会发现其实 EventExecutor 实际上就是一个 Java 原生的线程池，最后实现的是一个 ExecutorService ）。 123456789101112=====SingleThreadEventLoop=====@Override public ChannelFuture register(Channel channel) { return register(new DefaultChannelPromise(channel, this)); } @Override public ChannelFuture register(final ChannelPromise promise) { ObjectUtil.checkNotNull(promise, &quot;promise&quot;); promise.channel().unsafe().register(this, promise); return promise; } 接下来，我们获取到了 EventExecutor 后，就可以让它帮忙注册了。 1234567891011121314151617181920212223242526===== AbstractChannel =====public final void register(EventLoop eventLoop, final ChannelPromise promise) { //...校验省略部分代码 //先将EventLoop事件循环器绑定到该NioServerSocketChannel上 AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) { register0(promise); } else { try { eventLoop.execute(new Runnable() { @Override public void run() { register0(promise); } }); } catch (Throwable t) { logger.warn( &quot;Force-closing a channel whose registration task was not accepted by an event loop: {}&quot;, AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); } } } 1234567891011121314151617181920212223242526272829303132333435363738private void register0(ChannelPromise promise) { try { // check if the channel is still open as it could be closed in the mean time when the register // call was outside of the eventLoop if (!promise.setUncancellable() || !ensureOpen(promise)) { return; } boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the // user may already fire events through the pipeline in the ChannelFutureListener. pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); //开始通知成功了 pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (isActive()) { if (firstRegistration) { pipeline.fireChannelActive(); } else if (config().isAutoRead()) { // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); } } } catch (Throwable t) { // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); } } 1234567891011121314151617181920212223===== AbstractNioChannel ===== @Override protected void doRegister() throws Exception { boolean selected = false; for (;;) { try { //将当前的channel注册到selector上 selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; } catch (CancelledKeyException e) { if (!selected) { // Force the Selector to select now as the &quot;canceled&quot; SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; } else { // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; } } } } 最终监听 OP_ACCEPT 是通过 bind 完成后的 fireChannelActive() 来触发的。 为什么注册 OP_ACCEPT(16) 到多路复用器上，怎么注册 0 呢？0 表示已注册，但不进行任何操作。这样做的原因是 注册方法是多台的。它既可以被 NioServerSocketChannel 用来监听客户端的连接接入，也可以注册 SocketChannel 用来监听网络读或写操作。 通过 SelectionKey 的 interceptOps(int pos) 可以方便修改监听的操作位。所以，此处注册需要获取 SelectionKey 并给 AbstractNioChannel 的成员变量 selectionKey 赋值。 doRegister完毕之后调用pipeline.invokeHandlerAddedIfNeeded(); 123456789final void invokeHandlerAddedIfNeeded() { assert channel.eventLoop().inEventLoop(); if (firstRegistration) { firstRegistration = false; // We are now registered to the EventLoop. It's time to call the callbacks for the ChannelHandlers, // that were added before the registration was done. callHandlerAddedForAllHandlers(); } } 当注册成功后，触发了 ChannelRegistered 事件，这个事件也是整个 pipeline 都会触发的。 ChannelRegistered 触发完后，就会判断是否 ServerSocketChannel 监听是否成功，如果成功，需要出发 NioServerSocketChannel 的 ChannelActive 事件。 123if(isAcitve()) { pipeline.fireChannelActive();} isAcitve() 方法也是多态。如果服务端判断是否监听启动；如果是客户端查看 TCP 是否连接完成。channelActive() 事件在 ChannelPipeline 中传递，找到了 pipeline.fireChannelActive(); 的发起调用的代码，不巧，刚好就是下面的doBind0()方法 123456789101112131415private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) { //通过包装一个Runnable进行异步化的，关于异步化task channel.eventLoop().execute(new Runnable() { @Override public void run() { if (regFuture.isSuccess()) { channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); } else { promise.setFailure(regFuture.cause()); } } }); } 123456789101112131415161718===== AbstractChannel =====@Override public ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) { return pipeline.bind(localAddress, promise); }===== DefaultChannelPipeline =====@Override public final ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) { return tail.bind(localAddress, promise); }===== HeadContext ======@Override public void bind( ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) { unsafe.bind(localAddress, promise); } 1234567891011121314151617181920212223242526272829303132333435363738394041@Override public final void bind(final SocketAddress localAddress, final ChannelPromise promise) { assertEventLoop(); if (!promise.setUncancellable() || !ensureOpen(promise)) { return; } // See: https://github.com/netty/netty/issues/576 if (Boolean.TRUE.equals(config().getOption(ChannelOption.SO_BROADCAST)) &amp;&amp; localAddress instanceof InetSocketAddress &amp;&amp; !((InetSocketAddress) localAddress).getAddress().isAnyLocalAddress() &amp;&amp; !PlatformDependent.isWindows() &amp;&amp; !PlatformDependent.maybeSuperUser()) { // Warn a user about the fact that a non-root user can't receive a // broadcast packet on *nix if the socket is bound on non-wildcard address. logger.warn( &quot;A non-root user can't receive a broadcast packet if the socket &quot; + &quot;is not bound to a wildcard address; binding to a non-wildcard &quot; + &quot;address (&quot; + localAddress + &quot;) anyway as requested.&quot;); } boolean wasActive = isActive(); try { doBind(localAddress); //最终调到了jdk里面的bind方法,如下 } catch (Throwable t) { safeSetFailure(promise, t); closeIfClosed(); return; } if (!wasActive &amp;&amp; isActive()) { invokeLater(new Runnable() { @Override public void run() { pipeline.fireChannelActive(); } }); } safeSetSuccess(promise); } 12345678910===== NioServerSocketChannel =====@Override protected void doBind(SocketAddress localAddress) throws Exception { if (PlatformDependent.javaVersion() &gt;= 7) { //判断JDK到版本 javaChannel().bind(localAddress, config.getBacklog()); } else { javaChannel().socket().bind(localAddress, config.getBacklog()); } } 完成之后根据配置决定是否自动出发 Channel 读操作，下面是代码实现 1234567891011121314151617181920=====DefaultChannelPipeline===== @Override public void channelActive(ChannelHandlerContext ctx) { ctx.fireChannelActive(); //注册读事件，读包括：创建连接/读取数据 readIfIsAutoRead(); }private void readIfIsAutoRead() { if (channel.config().isAutoRead()) { channel.read(); } }@Override public boolean isAutoRead() { return autoRead == 1; } AbstractChannel 的读操作出发了 ChannelPipeline 的读操作，最终调用到 HeadHandler 的读方法，代码如下 12345@Override public Channel read() { pipeline.read(); return this; } 123public void read(ChannelHandlerContext ctx){ unsafe.beginRead();} 继续看 AbstractUnsafe 的 beginRead 方法，代码如下: 由于不同类型的 Channel 对于读操作的处理是不同的，所以合格 beginRead 也算是多态方法。对于 NIO 的 channel，无论是客户端还是服务端，都是修改网络监听操作位为自身感兴趣的shi 123456789101112131415protected void doBeginRead() throws Exception { // Channel.read() or ChannelHandlerContext.read() was called //this.selectionKey就是我们在前面register步骤返回的对象，前面我们在register的时候，注册测ops是0 final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) { return; } readPending = true; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) { //readInterestOp 是不是监听了ops=16 selectionKey.interestOps(interestOps | readInterestOp); } } JDK SelectionKey 有四种操作类型，分别为： OP_READ = 1&lt;&lt;0 OP_WRITE = 1&lt;&lt;2 OP_CONNECT = 1&lt;&lt;3 OP_ACCEPT = 1&lt;&lt;4 每个操作位代表一种网络操作类型，分别为 0001，0010，0100，1000，这样做的好处是方便地通过位操作来进行网络操作位的状态判断和状态修改，从而提升操作性能。 总结netty启动一个服务所经过的流程 设置启动类参数，最重要的就是设置channel 创建server对应的channel，创建各大组件，包括ChannelConfig,ChannelId,ChannelPipeline,ChannelHandler,Unsafe等 初始化server对应的channel，设置一些attr，option，以及设置子channel的attr，option，给server的channel添加新channel接入器，并出发addHandler,register等事件 调用到jdk底层做端口绑定，并触发active事件，active触发的时候，真正做服务端口绑定 构建连接 接受连接本质就是对OP_ACCEPT事件对处理，对应于源码就是NioEventLoop的run方法： 断点打在processSelectedKeysOptimized方法中，然后启动服务端，再启动客户端进行debug 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102@Override protected void run() { for (;;) { //死循环监听事件 try { try { switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) { case SelectStrategy.CONTINUE: continue; case SelectStrategy.BUSY_WAIT: case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); //select轮询 if (wakenUp.get()) { selector.wakeup(); } // fall through default: } } catch (IOException e) { // If we receive an IOException here its because the Selector is messed up. Let's rebuild // the selector and retry. https://github.com/netty/netty/issues/8566 rebuildSelector0(); handleLoopException(e); continue; } cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) { try { processSelectedKeys(); } finally { // Ensure we always run tasks. runAllTasks(); } } else { final long ioStartTime = System.nanoTime(); try { processSelectedKeys(); //处理事件 } finally { // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); } } } catch (Throwable t) { handleLoopException(t); } // Always handle shutdown even if the loop processing threw an exception. try { if (isShuttingDown()) { closeAll(); if (confirmShutdown()) { return; } } } catch (Throwable t) { handleLoopException(t); } } }private void processSelectedKeys() { if (selectedKeys != null) { processSelectedKeysOptimized(); //优化后的 } else { processSelectedKeysPlain(selector.selectedKeys()); } }private void processSelectedKeysOptimized() { for (int i = 0; i &lt; selectedKeys.size; ++i) { final SelectionKey k = selectedKeys.keys[i]; // null out entry in the array to allow to have it GC'ed once the Channel close // See https://github.com/netty/netty/issues/2363 selectedKeys.keys[i] = null; final Object a = k.attachment(); //这里的attachment就是NioServerSocketChannel if (a instanceof AbstractNioChannel) { processSelectedKey(k, (AbstractNioChannel) a); //处理SelectedKey } else { @SuppressWarnings(&quot;unchecked&quot;) NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); } if (needsToSelectAgain) { // null out entries in the array to allow to have it GC'ed once the Channel close // See https://github.com/netty/netty/issues/2363 selectedKeys.reset(i + 1); selectAgain(); i = -1; } } } 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) { final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); if (!k.isValid()) { final EventLoop eventLoop; try { eventLoop = ch.eventLoop(); } catch (Throwable ignored) { // If the channel implementation throws an exception because there is no event loop, we ignore this // because we are only trying to determine if ch is registered to this event loop and thus has authority // to close ch. return; } // Only close ch if ch is still registered to this EventLoop. ch could have deregistered from the event loop // and thus the SelectionKey could be cancelled as part of the deregistration process, but the channel is // still healthy and should not be closed. // See https://github.com/netty/netty/issues/5125 if (eventLoop != this || eventLoop == null) { return; } // close the channel if the key is not valid anymore unsafe.close(unsafe.voidPromise()); return; } try { int readyOps = k.readyOps(); //什么事件发生了，如果是16代表的就是OP_ACCEPT // We first need to call finishConnect() before try to trigger a read(...) or write(...) as otherwise // the NIO JDK channel implementation may throw a NotYetConnectedException. if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) { // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking // See https://github.com/netty/netty/issues/924 int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); } // Process OP_WRITE first as we may be able to write some queued buffers and so free memory. if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) { // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write ch.unsafe().forceFlush(); } // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead // to a spin loop if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) { unsafe.read(); //如果是16，进入这个方法 } } catch (CancelledKeyException ignored) { unsafe.close(unsafe.voidPromise()); } } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private final class NioMessageUnsafe extends AbstractNioUnsafe { private final List&lt;Object&gt; readBuf = new ArrayList&lt;Object&gt;(); @Override public void read() { assert eventLoop().inEventLoop(); //初始化 final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.reset(config); boolean closed = false; Throwable exception = null; try { try { do { int localRead = doReadMessages(readBuf);// if (localRead == 0) { break; } if (localRead &lt; 0) { closed = true; break; } allocHandle.incMessagesRead(localRead); //记录一下创建的次数 } while (allocHandle.continueReading());//判断是不是需要继续去读 } catch (Throwable t) { exception = t; } int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) { readPending = false; //创建连接的结果通过fireChannelRead传播出去，就是pipeline中各种handle的执行 //其中有个关键的就是ServerBootStrapAcceptor 负责初始化创建的SocketChannel的 pipeline.fireChannelRead(readBuf.get(i)); } readBuf.clear(); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); if (exception != null) { closed = closeOnReadError(exception); pipeline.fireExceptionCaught(exception); } if (closed) { inputShutdown = true; if (isOpen()) { close(voidPromise()); } } } finally { // Check if there is a readPending which was not processed yet. // This could be for two reasons: // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method // // See https://github.com/netty/netty/issues/2254 if (!readPending &amp;&amp; !config.isAutoRead()) { removeReadOp(); } } } } 123456789101112131415161718192021====== NioServerSocketChannel ======@Override protected int doReadMessages(List&lt;Object&gt; buf) throws Exception { SocketChannel ch = SocketUtils.accept(javaChannel());//接受新连接创建SocketChannel try { if (ch != null) { buf.add(new NioSocketChannel(this, ch)); //创建完SocketChannel之后放入到buf数组中去 return 1; //返回1代表仅仅创建了一个连接 } } catch (Throwable t) { logger.warn(&quot;Failed to create a new channel from an accepted socket.&quot;, t); try { ch.close(); } catch (Throwable t2) { logger.warn(&quot;Failed to close a socket.&quot;, t2); } } return 0; } 1234567891011121314===== SocketUtils =====public static SocketChannel accept(final ServerSocketChannel serverSocketChannel) throws IOException { try { return AccessController.doPrivileged(new PrivilegedExceptionAction&lt;SocketChannel&gt;() { @Override public SocketChannel run() throws IOException { //非阻塞模式下，没有连接请求时返回null return serverSocketChannel.accept();//接受创建连接请求来创建一个SocketChannel } }); } catch (PrivilegedActionException e) { throw (IOException) e.getCause(); } } 1234567@Override public boolean continueReading(UncheckedBooleanSupplier maybeMoreDataSupplier) { return config.isAutoRead() &amp;&amp; (!respectMaybeMoreData || maybeMoreDataSupplier.get()) &amp;&amp; totalMessages &lt; maxMessagePerRead &amp;&amp; //maxMessagePerRead 最大次数16次 totalBytesRead &gt; 0; //读取的字节数为0 } 找到ServerBootStrapAcceptor 12345678910111213141516171819202122232425===== ServerBootStrap ======public void channelRead(ChannelHandlerContext ctx, Object msg) { final Channel child = (Channel) msg; child.pipeline().addLast(childHandler); setChannelOptions(child, childOptions, logger); for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: childAttrs) { child.attr((AttributeKey&lt;Object&gt;) e.getKey()).set(e.getValue()); } try { childGroup.register(child).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { forceClose(child, future.cause()); } } }); } catch (Throwable t) { forceClose(child, t); } } 123456789101112131415161718 @Override public ChannelFuture register(Channel channel) { return next().register(channel); //选择一个子的元素 }===== SingleThreadEventLoop ===== 此时已经是workereventloop了 @Override public ChannelFuture register(Channel channel) { return register(new DefaultChannelPromise(channel, this)); } @Override public ChannelFuture register(final ChannelPromise promise) { ObjectUtil.checkNotNull(promise, &quot;promise&quot;); promise.channel().unsafe().register(this, promise); return promise; } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102===== AbstractChannel ======@Override public final void register(EventLoop eventLoop, final ChannelPromise promise) { if (eventLoop == null) { throw new NullPointerException(&quot;eventLoop&quot;); } if (isRegistered()) { promise.setFailure(new IllegalStateException(&quot;registered to an event loop already&quot;)); return; } if (!isCompatible(eventLoop)) { promise.setFailure( new IllegalStateException(&quot;incompatible event loop type: &quot; + eventLoop.getClass().getName())); return; } AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) { //判断当前是不是eventloop所选定的线程 register0(promise); } else { try { eventLoop.execute(new Runnable() { @Override public void run() { register0(promise); } }); } catch (Throwable t) { logger.warn( &quot;Force-closing a channel whose registration task was not accepted by an event loop: {}&quot;, AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); } } }private void register0(ChannelPromise promise) { try { // check if the channel is still open as it could be closed in the mean time when the register // call was outside of the eventLoop if (!promise.setUncancellable() || !ensureOpen(promise)) { return; } boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the // user may already fire events through the pipeline in the ChannelFutureListener. pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); //这里是创建连接，就不会到bind的代码中 pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (isActive()) { //此时连接已经建立好了，已经是active了 if (firstRegistration) { pipeline.fireChannelActive();// 此时也是第一次注册，走到该方法中，触发HeadCOntent中的read方法 } else if (config().isAutoRead()) { // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); } } } catch (Throwable t) { // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); } }===== AbstractNioChannel =====@Override protected void doRegister() throws Exception { boolean selected = false; for (;;) { try { selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; } catch (CancelledKeyException e) { if (!selected) { // Force the Selector to select now as the &quot;canceled&quot; SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; } else { // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; } } } } 12345==== HeadContext =====@Override public void read(ChannelHandlerContext ctx) { unsafe.beginRead(); //和启动服务后面的类似了，接受的是read事件 } selector.select()/selectNow()/select(timeoutMillis) 发现 OP_ACCEPT 事件，处理： SocketChannel socketChannel = serverSocketChannel.accept() selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); selectionKey.interestOps(OP_READ); 注册OP_READ事件 创建连接的初始化和注册是通过 pipeline.fireChannelRead 在 ServerBootstrapAcceptor 中完成的。 第一次 Register 并不是监听 OP_READ ，而是 0 ： selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this) 。 最终监听 OP_READ 是通过“Register”完成后的fireChannelActive（io.netty.channel.AbstractChannel.AbstractUnsafe#register0中）来触发的 Worker’s NioEventLoop 是通过 Register 操作执行来启动。 接受连接的读操作，不会尝试读取更多次（16次）。 接受数据 读数据技巧 自适应数据大小的分配器（AdaptiveRecvByteBufAllocator）： 发放东西时，拿多大的桶去装？小了不够，大了浪费，所以会自己根据实际装的情况猜一猜下次情况，从而决定下次带多大的桶。 连续读（defaultMaxMessagesPerRead）： 发放东西时，假设拿的桶装满了，这个时候，你会觉得可能还有东西发放，所以直接拿个新桶等着装，而不是回家，直到后面出现没有装上的情况或者装了很多次需要给别人一点机会等原因才停止，回家。 断点位置在NioEventLoop中的697行的read方法中： 12345if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) { //如果是SocketChannel的话，跳转到NioByteChannel //如果是ServerSocketChannel的话，跳转到NioMessageChannel unsafe.read(); } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263===== AbstractNioByteChannel ======@Override public final void read() { final ChannelConfig config = config(); if (shouldBreakReadReady(config)) { clearReadPending(); return; } final ChannelPipeline pipeline = pipeline(); final ByteBufAllocator allocator = config.getAllocator(); //ByteBuf分配器 //AdaptiveRecvByteBufAllocator，帮忙决定下次分配多少 final RecvByteBufAllocator.Handle allocHandle = recvBufAllocHandle(); allocHandle.reset(config); ByteBuf byteBuf = null; boolean close = false; try { do { //经可能分配合适的大小 byteBuf = allocHandle.allocate(allocator); //读并且记录读了多少，如果读满了，下次continue的话就直接扩容 allocHandle.lastBytesRead(doReadBytes(byteBuf)); if (allocHandle.lastBytesRead() &lt;= 0) { // nothing was read. release the buffer. byteBuf.release(); byteBuf = null; close = allocHandle.lastBytesRead() &lt; 0; if (close) { // There is nothing left to read as we received an EOF. readPending = false; } break; } allocHandle.incMessagesRead(1); readPending = false; //在pipeline上执行，业务逻辑就是在这个地方 pipeline.fireChannelRead(byteBuf); byteBuf = null; } while (allocHandle.continueReading()); //判断是不是要继续读，此时不是创建连接的时候了，最后一个判断满足 //记录这次读事件总共读了多少数据，计算下次分配大小 allocHandle.readComplete(); pipeline.fireChannelReadComplete(); //相当于完成本次读事件的处理 if (close) { closeOnRead(pipeline); } } catch (Throwable t) { handleReadException(pipeline, byteBuf, t, close, allocHandle); } finally { // Check if there is a readPending which was not processed yet. // This could be for two reasons: // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method // // See https://github.com/netty/netty/issues/2254 if (!readPending &amp;&amp; !config.isAutoRead()) { removeReadOp(); } } } } 1234@Override public ByteBuf allocate(ByteBufAllocator alloc) { return alloc.ioBuffer(guess()); //猜，一开始是1024 } 1234567===== NioSocketChannel ======@Override protected int doReadBytes(ByteBuf byteBuf) throws Exception { final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.attemptedBytesRead(byteBuf.writableBytes()); return byteBuf.writeBytes(javaChannel(), allocHandle.attemptedBytesRead()); } 12345678910===== AbstractByteBuf ======@Override public int writeBytes(ScatteringByteChannel in, int length) throws IOException { ensureWritable(length); int writtenBytes = setBytes(writerIndex, in, length); if (writtenBytes &gt; 0) { writerIndex += writtenBytes; } return writtenBytes; } 123456789=====PooledByteBuf======@Override public final int setBytes(int index, ScatteringByteChannel in, int length) throws IOException { try { return in.read(internalNioBuffer(index, length)); } catch (ClosedChannelException ignored) { return -1; } } 123456789101112131415@Override public boolean continueReading(UncheckedBooleanSupplier maybeMoreDataSupplier) { return config.isAutoRead() &amp;&amp; (!respectMaybeMoreData || maybeMoreDataSupplier.get()) &amp;&amp; //maybeMoreDataSupplier.get()判断是不是满载而归 totalMessages &lt; maxMessagePerRead &amp;&amp; totalBytesRead &gt; 0; }private final UncheckedBooleanSupplier defaultMaybeMoreSupplier = new UncheckedBooleanSupplier() { @Override public boolean get() { return attemptedBytesRead == lastBytesRead; } }; 总结读取数据本质：sun.nio.ch.SocketChannelImpl#read(java.nio.ByteBuffer) NioSocketChannel read() 是读数据， NioServerSocketChannel read() 是创建连接 pipeline.fireChannelReadComplete(); 一次读事件处理完成 pipeline.fireChannelRead(byteBuf); 一次读数据完成，一次读事件处理可能会包含多次读数据操作。 为什么最多只尝试读取 16 次？“雨露均沾” AdaptiveRecvByteBufAllocator 对 bytebuf 的猜测：放大果断，缩小谨慎（需要连续 2 次判断） 业务处理 还是从NioEventLoop中的unsafe.read()开始 123if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) { unsafe.read(); } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354===== AbstractNioByteChannel =====@Override public final void read() { final ChannelConfig config = config(); if (shouldBreakReadReady(config)) { clearReadPending(); return; } final ChannelPipeline pipeline = pipeline(); final ByteBufAllocator allocator = config.getAllocator(); final RecvByteBufAllocator.Handle allocHandle = recvBufAllocHandle(); allocHandle.reset(config); ByteBuf byteBuf = null; boolean close = false; try { do { byteBuf = allocHandle.allocate(allocator); allocHandle.lastBytesRead(doReadBytes(byteBuf)); if (allocHandle.lastBytesRead() &lt;= 0) { // nothing was read. release the buffer. byteBuf.release(); byteBuf = null; close = allocHandle.lastBytesRead() &lt; 0; if (close) { // There is nothing left to read as we received an EOF. readPending = false; } break; } allocHandle.incMessagesRead(1); readPending = false; pipeline.fireChannelRead(byteBuf); //在这里处理业务逻辑 byteBuf = null; } while (allocHandle.continueReading()); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); if (close) { closeOnRead(pipeline); } } catch (Throwable t) { handleReadException(pipeline, byteBuf, t, close, allocHandle); } finally { if (!readPending &amp;&amp; !config.isAutoRead()) { removeReadOp(); } } } } 123456789101112131415161718192021222324252627282930313233343536373839404142====== DefaultChannelPipeline ======@Override public final ChannelPipeline fireChannelRead(Object msg) { AbstractChannelHandlerContext.invokeChannelRead(head, msg); return this; }===== AbstractChannelHandlerContext =====static void invokeChannelRead(final AbstractChannelHandlerContext next, Object msg) { final Object m = next.pipeline.touch(ObjectUtil.checkNotNull(msg, &quot;msg&quot;), next); EventExecutor executor = next.executor(); //默认是NioEventLoop，可以指定 if (executor.inEventLoop()) { next.invokeChannelRead(m); } else { executor.execute(new Runnable() { @Override public void run() { next.invokeChannelRead(m); } }); } }private void invokeChannelRead(Object msg) { if (invokeHandler()) { try { ((ChannelInboundHandler) handler()).channelRead(this, msg); //channelRead方法可以跳转到业务逻辑那里 } catch (Throwable t) { notifyHandlerException(t); } } else { fireChannelRead(msg); } }====== DefaultChannelPipeline ======@Override public void channelRead(ChannelHandlerContext ctx, Object msg) { ctx.fireChannelRead(msg); } 1234567891011121314151617181920212223242526272829303132===== AbstractChannelHandlerContext =====@Override public ChannelHandlerContext fireChannelRead(final Object msg) { //找head的下面一个可以执行CHANNEL_READ的方法 invokeChannelRead(findContextInbound(MASK_CHANNEL_READ), msg); return this; }private AbstractChannelHandlerContext findContextInbound(int mask) { AbstractChannelHandlerContext ctx = this; do { ctx = ctx.next; //先next一下 } while ((ctx.executionMask &amp; mask) == 0); //判断是不是有执行的资格 return ctx; }static void invokeChannelRead(final AbstractChannelHandlerContext next, Object msg) { final Object m = next.pipeline.touch(ObjectUtil.checkNotNull(msg, &quot;msg&quot;), next); EventExecutor executor = next.executor(); if (executor.inEventLoop()) { next.invokeChannelRead(m); } else { executor.execute(new Runnable() { @Override public void run() { next.invokeChannelRead(m); } }); } } 1234567public class EchoServerHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //这里写业务逻辑 ctx.write(msg); } 总结 处理业务本质：数据在 pipeline 中所有的 handler 的 channelRead() 执行过程Handler 要实现 io.netty.channel.ChannelInboundHandler#channelRead (ChannelHandlerContext ctx, Object msg)，且不能加注解 @Skip 才能被执行到。中途可退出，不保证执行到 Tail Handler。 默认处理线程就是 Channel 绑定的 NioEventLoop 线程，也可以设置其他： pipeline.addLast(new UnorderedThreadPoolEventExecutor(10), serverHandler) 发送数据写数据的三种方式 快递场景（包裹） Netty 写数据（数据） 揽收到仓库 write：写到一个 buffer 从仓库发货 flush: 把 buffer 里的数据发送出去 揽收到仓库并立马发货 （加急件） writeAndFlush：写到 buffer，立马发送 揽收与发货之间有个缓冲的仓库 Write 和 Flush 之间有个 ChannelOutboundBuffer 对方仓库爆仓时，送不了的时候，会停止送，协商等电话通知什么时候好了，再送。 Netty 写数据，写不进去时，会停止写，然后注册一个 OP_WRITE 事件，来通知什么时候可以写进去了再写。 发送快递时，对方仓库都直接收下，这个时候再发送快递时，可以尝试发送更多的快递试试，这样效果更好。 Netty 批量写数据时，如果想写的都写进去了，接下来的尝试写更多（调整 maxBytesPerGatheringWrite） 发送快递时，发到某个地方的快递特别多，我们会连续发，但是快递车毕竟有限，也会考虑下其他地方。 Netty 只要有数据要写，且能写的出去，则一直尝试，直到写不出去或者满 16 次（writeSpinCount）。 揽收太多，发送来不及时，爆仓，这个时候会出个告示牌：收不下了，最好过 2 天再来邮寄吧。 Netty 待写数据太多，超过一定的水位线（**writeBufferWaterMark.high()**），会将可写的标志位改成 false ，让应用端自己做决定要不要发送数据了。 ​ 源码分析接着上面的断点： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Override public ChannelFuture write(Object msg) { return write(msg, newPromise()); } @Override public ChannelFuture write(final Object msg, final ChannelPromise promise) { write(msg, false, promise); return promise; }===== AbstractChannelHandlerContext ===== private void write(Object msg, boolean flush, ChannelPromise promise) { ObjectUtil.checkNotNull(msg, &quot;msg&quot;); try { if (isNotValidPromise(promise, true)) { ReferenceCountUtil.release(msg); // cancelled return; } } catch (RuntimeException e) { ReferenceCountUtil.release(msg); throw e; } //当前的handle是我们自己写的业务逻辑处理handle，这里找下一个handle final AbstractChannelHandlerContext next = findContextOutbound(flush ? (MASK_WRITE | MASK_FLUSH) : MASK_WRITE); final Object m = pipeline.touch(msg, next); EventExecutor executor = next.executor(); if (executor.inEventLoop()) { if (flush) { next.invokeWriteAndFlush(m, promise); } else { next.invokeWrite(m, promise); } } else { final AbstractWriteTask task; if (flush) { task = WriteAndFlushTask.newInstance(next, m, promise); } else { task = WriteTask.newInstance(next, m, promise); //这里wirte } if (!safeExecute(executor, task, promise, m)) { // We failed to submit the AbstractWriteTask. We need to cancel it so we decrement the pending bytes // and put it back in the Recycler for re-use later. // // See https://github.com/netty/netty/issues/8343. task.cancel(); } } } 1234567891011121314151617181920private void invokeWrite(Object msg, ChannelPromise promise) { if (invokeHandler()) { invokeWrite0(msg, promise); } else { write(msg, promise); } } private void invokeWrite0(Object msg, ChannelPromise promise) { try { ((ChannelOutboundHandler) handler()).write(this, msg, promise); } catch (Throwable t) { notifyOutboundHandlerException(t, promise); } }@Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) { unsafe.write(msg, promise); } 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public final void write(Object msg, ChannelPromise promise) { assertEventLoop(); ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; //类比前面发快递的仓库了 if (outboundBuffer == null) { // If the outboundBuffer is null we know the channel was closed and so // need to fail the future right away. If it is not null the handling of the rest // will be done in flush0() // See https://github.com/netty/netty/issues/2362 safeSetFailure(promise, newClosedChannelException(initialCloseCause)); // release message now to prevent resource-leak ReferenceCountUtil.release(msg); return; } int size; try { msg = filterOutboundMessage(msg); size = pipeline.estimatorHandle().size(msg); if (size &lt; 0) { size = 0; } } catch (Throwable t) { safeSetFailure(promise, t); ReferenceCountUtil.release(msg); return; } outboundBuffer.addMessage(msg, size, promise);//把消息放入buffer中 }===== ChannelOutboundBuffer =====public void addMessage(Object msg, int size, ChannelPromise promise) { Entry entry = Entry.newInstance(msg, size, total(msg), promise); if (tailEntry == null) { flushedEntry = null; } else { Entry tail = tailEntry; tail.next = entry; } tailEntry = entry; if (unflushedEntry == null) { unflushedEntry = entry; //追加到队尾 } // increment pending bytes after adding message to the unflushed arrays. // See https://github.com/netty/netty/issues/1619 incrementPendingOutboundBytes(entry.pendingSize, false); //根据前面算的size来更改buffer中还有多少数据未处理 }private void incrementPendingOutboundBytes(long size, boolean invokeLater) { if (size == 0) { return; } long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size); if (newWriteBufferSize &gt; channel.config().getWriteBufferHighWaterMark()) { setUnwritable(invokeLater); } } write完之后就到了发送flush过程 1234567891011public class EchoServerHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ctx.write(msg); } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { ctx.flush(); //到了这里了 } 1234567891011121314151617@Override public ChannelHandlerContext flush() { //找到下一级的handle final AbstractChannelHandlerContext next = findContextOutbound(MASK_FLUSH); EventExecutor executor = next.executor(); if (executor.inEventLoop()) { next.invokeFlush(); } else { Tasks tasks = next.invokeTasks; if (tasks == null) { next.invokeTasks = tasks = new Tasks(next); } safeExecute(executor, tasks.invokeFlushTask, channel().voidPromise(), null); } return this; } 123456789101112131415private void invokeFlush() { if (invokeHandler()) { invokeFlush0(); } else { flush(); } } private void invokeFlush0() { try { ((ChannelOutboundHandler) handler()).flush(this); } catch (Throwable t) { notifyHandlerException(t); } } 123456789101112131415161718@Override public void flush(ChannelHandlerContext ctx) { unsafe.flush(); }@Override public final void flush() { assertEventLoop(); ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if (outboundBuffer == null) { return; } outboundBuffer.addFlush(); flush0(); } 12345678910111213141516171819202122232425public void addFlush() { // There is no need to process all entries if there was already a flush before and no new messages // where added in the meantime. // // See https://github.com/netty/netty/issues/2577 Entry entry = unflushedEntry; //将没有flush的数据加入到数组中 if (entry != null) { if (flushedEntry == null) { // there is no flushedEntry yet, so start with the entry flushedEntry = entry; } do { flushed ++; if (!entry.promise.setUncancellable()) { // Was cancelled so make sure we free up memory and notify about the freed bytes int pending = entry.cancel(); decrementPendingOutboundBytes(pending, false, true); } entry = entry.next; } while (entry != null); // All flushed so reset unflushedEntry unflushedEntry = null; } } 12345678910111213141516171819202122232425262728293031323334353637383940414243444546protected void flush0() { if (inFlush0) { // Avoid re-entrance return; } final ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if (outboundBuffer == null || outboundBuffer.isEmpty()) { return; } inFlush0 = true; // Mark all pending write requests as failure if the channel is inactive. if (!isActive()) { try { if (isOpen()) { outboundBuffer.failFlushed(new NotYetConnectedException(), true); } else { // Do not trigger channelWritabilityChanged because the channel is closed already. outboundBuffer.failFlushed(newClosedChannelException(initialCloseCause), false); } } finally { inFlush0 = false; } return; } try { doWrite(outboundBuffer); //在这里进入 } catch (Throwable t) { if (t instanceof IOException &amp;&amp; config().isAutoClose()) { initialCloseCause = t; close(voidPromise(), t, newClosedChannelException(t), false); } else { try { shutdownOutput(voidPromise(), t); } catch (Throwable t2) { initialCloseCause = t; close(voidPromise(), t2, newClosedChannelException(t), false); } } } finally { inFlush0 = false; } } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263===== NioSocketChannel =====protected void doWrite(ChannelOutboundBuffer in) throws Exception { SocketChannel ch = javaChannel(); int writeSpinCount = config().getWriteSpinCount(); do { if (in.isEmpty()) { // All written so clear OP_WRITE clearOpWrite(); // Directly return here so incompleteWrite(...) is not called. return; } // Ensure the pending writes are made of ByteBufs only. int maxBytesPerGatheringWrite = ((NioSocketChannelConfig) config).getMaxBytesPerGatheringWrite(); //最多返回1024个数据，总的size尽量不超过 maxBytesPerGatheringWrite ByteBuffer[] nioBuffers = in.nioBuffers(1024, maxBytesPerGatheringWrite); int nioBufferCnt = in.nioBufferCount(); // Always us nioBuffers() to workaround data-corruption. // See https://github.com/netty/netty/issues/2761 switch (nioBufferCnt) { case 0: // We have something else beside ByteBuffers to write so fallback to normal writes. writeSpinCount -= doWrite0(in); break; case 1: { // Only one ByteBuf so use non-gathering write // Zero length buffers are not added to nioBuffers by ChannelOutboundBuffer, so there is no need // to check if the total size of all the buffers is non-zero. ByteBuffer buffer = nioBuffers[0]; int attemptedBytes = buffer.remaining(); final int localWrittenBytes = ch.write(buffer); if (localWrittenBytes &lt;= 0) { incompleteWrite(true); return; } adjustMaxBytesPerGatheringWrite(attemptedBytes, localWrittenBytes, maxBytesPerGatheringWrite); in.removeBytes(localWrittenBytes); --writeSpinCount; break; } default: { // Zero length buffers are not added to nioBuffers by ChannelOutboundBuffer, so there is no need // to check if the total size of all the buffers is non-zero. // We limit the max amount to int above so cast is safe long attemptedBytes = in.nioBufferSize(); final long localWrittenBytes = ch.write(nioBuffers, 0, nioBufferCnt); if (localWrittenBytes &lt;= 0) { incompleteWrite(true); return; } // Casting to int is safe because we limit the total amount of data in the nioBuffers to int above. adjustMaxBytesPerGatheringWrite((int) attemptedBytes, (int) localWrittenBytes, maxBytesPerGatheringWrite); in.removeBytes(localWrittenBytes); --writeSpinCount; break; } } } while (writeSpinCount &gt; 0); incompleteWrite(writeSpinCount &lt; 0); } 总结 写的本质： Single write: sun.nio.ch.SocketChannelImpl#write(java.nio.ByteBuffer) gathering write：sun.nio.ch.SocketChannelImpl#write(java.nio.ByteBuffer[], int, int) 写数据写不进去时，会停止写，注册一个 OP_WRITE 事件，来通知什么时候可以写进去了。 OP_WRITE 不是说有数据可写，而是说可以写进去，所以正常情况，不能注册，否则一直触发。 批量写数据时，如果尝试写的都写进去了，接下来会尝试写更多（maxBytesPerGatheringWrite）。 只要有数据要写，且能写，则一直尝试，直到 16 次（writeSpinCount），写 16 次还没有写完，就直接 schedule 一个 task 来继续写，而不是用注册写事件来触发，更简洁有力。 待写数据太多，超过一定的水位线（writeBufferWaterMark.high()），会将可写的标志位改成 false ，让应用端自己做决定要不要继续写。 channelHandlerContext.channel().write() ：从 TailContext 开始执行； channelHandlerContext.write() : 从当前的 Context 开始。 ​ ​ 断开连接后续更新～ 关闭服务","link":"/2021/05/25/Netty%EF%BC%88%E5%85%AD%EF%BC%89%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"title":"Redis（二）IO模型","text":"Redis 是单线程，主要是指Redis 的网络 IO和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程，但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。 为什么用单线程多线程的开销日常写程序时，我们经常会听到一种说法:“使用多线程，可以增加系统吞吐率，或是可以增加系统扩展性。”的确，对于一个多线程的系统来说，在有合理的资源分配的情况下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数，即吞吐率。下面的左图是我们采用多线程时所期待的结果。 系统中通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销。 单线程为什么快Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。 基本的IO模型和阻塞的地方 当 Redis监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，导致其他客户端无法和 Redis 建立连接。 当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。 非阻塞模式Socket 网络模型的非阻塞模式设置，主要体现在三个关键的函数调用上，如果想要使用socket 非阻塞模式，就必须要了解这三个函数的调用返回类型和设置模式： socket() 方法会返回主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。 针对监听套接字，我们可以设置非阻塞模式：当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了。 针对已连接套接字设置非阻塞模式：Redis 调用 recv() 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。我们也需要有机制继续监听该已连接套接字，并在有数据达到时通知 Redis。 基于多路复用的高性能IO模型Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个IO 流的效果。 Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。 为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。那么，回调机制是怎么工作的呢？ 其实，select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升Redis 的响应性能。 以连接请求和读数据请求为例： 这两个请求分别对应 Accept 事件和 Read 事件，Redis 分别对这两个事件注册 accept 和get 回调函数。当 Linux 内核监听到有连接请求或读数据请求时，就会触发 Accept 事件和 Read 事件，此时，内核就会回调 Redis 相应的 accept 和 get 函数进行处理。 这就像病人去医院瞧病。在医生实际诊断前，每个病人（等同于请求）都需要先分诊、测体温、登记等。如果这些工作都由医生来完成，医生的工作效率就会很低。所以，医院都设置了分诊台，分诊台会一直处理这些诊断前的工作（类似于 Linux 内核监听请求），然后再转交给医生做实际诊断。这样即使一个医生（相当于 Redis 单线程），效率也能提升","link":"/2021/05/13/Redis%EF%BC%88%E4%BA%8C%EF%BC%89IO%E6%A8%A1%E5%9E%8B/"},{"title":"Redis（七）统计模式和扩展数据类型","text":"围绕这四种场景： 手机 App 中的每天的用户登录信息：一天对应一系列用户 ID 或移动设备 ID； 电商网站上商品的用户评论列表：一个商品对应了一系列的评论； 用户在手机 App 上的签到打卡信息：一天对应一系列用户的签到记录； 应用网站上的网页访问信息：一个网页对应一系列的访问点击。 集合统计模式聚合统计Set所谓的聚合统计，就是指统计多个集合元素的聚合结果，包括： 统计多个集合的共有元素（交集统计）； 把两个集合相比，统计其中一个集合独有的元素（差集统计）； 统计多个集合的所有元素（并集统计）。 统计每天的新增用户数和第二天的留存用户数，正好对应了聚合统计，用两个集合：一个集合记录所有登录过 App 的用户 ID，同时，用另一个集合记录每一天登录过 App 的用户 ID。然后，再对这两个集合做聚合统计。 举例：userid 为key ，value 为累积所有用户的id userid+日期为可以，value为当日用户id 12345678910111213141516171819//redis127.0.0.1:6379&gt; sadd userid 10001 10002 // 向 userid 的集合里面加上10001，10002(integer) 2127.0.0.1:6379&gt; scard userid //目前累积用户id为2个(integer) 2127.0.0.1:6379&gt; sadd userid:20210515 10023 10024 10025 //20210515的时候有三个用户id访问了，放入一个集合中(integer) 3127.0.0.1:6379&gt; sdiff userid userid:20210515 //比较两个集合的差异1) &quot;10001&quot;2) &quot;10002&quot;127.0.0.1:6379&gt; sunionstore userid userid userid:20210515 //将userid和userid:20210515的集合取并集放入userid中(integer) 5 //目前累积用户数为5个了127.0.0.1:6379&gt; scard userid(integer) 5127.0.0.1:6379&gt; sadd userid:20210516 10001 10023 10025 10031 10032 //20210516又有这些id访问了(integer) 5127.0.0.1:6379&gt; sdiffstore user:new userid userid:20210516 //求0516的新增用户数：取差集并保存在user:new 的集合中(integer) 2127.0.0.1:6379&gt; Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。所以，我给你分享一个小建议：你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。 排序统计Sorted Set最新评论列表包含了所有评论中的最新留言，这就要求集合类型能对元素保序，也就是说，集合中的元素可以按序排列，这种对元素保序的集合类型叫作有序集合。 List 是按照元素进入 List 的顺序进行排序的，而 Sorted Set 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set的时间确定权重值，先插入的元素权重小，后插入的元素权重大。 List12345678910111213141516171819127.0.0.1:6379&gt; lpush product1 A B C D E F //product1 商品有6个评论分别为 A B C D E F(integer) 5127.0.0.1:6379&gt; lrange product1 0 2 //展示第一页的 3 个评论时1) &quot;F&quot;2) &quot;E&quot;3) &quot;D&quot;127.0.0.1:6379&gt; lrange product1 3 5 //获取第二页的 3 个评论，1) &quot;C&quot;2) &quot;B&quot;3) &quot;A&quot;//此时如果新添加了一个评论G127.0.0.1:6379&gt; lpush product1 G(integer) 7127.0.0.1:6379&gt; lrange product1 3 5 ////获取第二页的 3 个评论就发生变化了1) &quot;D&quot;2) &quot;C&quot;3) &quot;B&quot;127.0.0.1:6379&gt; Sorted Set按评论时间的先后给每条评论设置一个权重值，然后再把评论保存到 Sorted Set中。 1ZRANGEBYSCORE comments N-9 N //返回最新的10条评论 所以，在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议你优先考虑使用 Sorted Set。 二值状态统计BitMap在签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。这个时候，我们就可以选择 Bitmap。这是 Redis 提供的扩展数据类型。我来给你解释一下它的实现原理。 基数统计","link":"/2021/05/15/Redis%EF%BC%88%E4%B8%83%EF%BC%89%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%92%8C%E6%89%A9%E5%B1%95%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"title":"Redis（六）集群模式","text":"Redis在使用 RDB 进行持久化时，会 fork 子进程来完成，而fork 操作的用时和 Redis 的数据量是正相关的， fork 在执行时会阻塞主线程。数据量越大，fork 操作造成的主线程阻塞的时间越长。 所以，在使用 RDB 对 几十G的数据进行持久化时，后台运行的子进程在 fork 创建时阻塞了主线程，于是就导致Redis 响应变慢了。因此需要进行切片集群 数据量越来越大该怎么办 纵向扩展：升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU。就像下图中，原来的实例内存是 8GB，硬盘是 50GB，纵向扩展后，内存增加到 24GB，磁盘增加到 150GB。 横向扩展：横向增加当前 Redis 实例的个数，就像下图中，原来使用 1 个 8GB 内存、50GB 磁盘的实例，现在使用三个相同配置的实例。 Redis ClusterRedis Cluster 方案采用哈希槽（Hash Slot）来处理数据和实例之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。 数据映射到哈希槽过程分为下面两步： 根据键值对的 key，按照CRC16 算法计算一个 16 bit的值； 再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。 哈希槽映射到redis实例分配过程： 我们在部署 Redis Cluster 方案时，可以使用 cluster create 命令创建集群，此时，Redis会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384/N 个。 我们也可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用cluster addslots 命令，指定每个实例上的哈希槽个数 假设集群中不同 Redis 实例的内存大小配置不一，如果把哈希槽均分在各个实例上，在保存相同数量的键值对时，和内存大的实例相比，内存小的实例就会有更大的容量压力。遇到这种情况时，你可以根据不同实例的资源配置情况，使用 cluster addslots命令手动分配哈希槽。 客户端如何定位到哪个redis实例中呢一般来说，客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的。 那么，客户端为什么可以在访问任何一个实例时，都能获得所有的哈希槽信息呢？这是因为，Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。 但是在集群中实例和哈希槽的对应关系会发生变化： 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽； 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。 客户端是无法主动感知这些变化的。这就会导致，它缓存的分配信息和最新的分配信息就不一致了， 重定向机制MOVED所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。 那客户端又是怎么知道重定向时的新实例的访问地址呢？当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址。 12GET hello:key(error) MOVED 13320 172.16.19.5:6379 MOVED 命令表示，客户端请求的键值对所在的哈希槽 13320，实际是在172.16.19.5 这个实例上。通过返回的 MOVED 命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和 172.16.19.5 连接，并发送操作请求了。 ASK在实际应用时，如果 Slot 2 中的数据比较多，就可能会出现一种情况：客户端向实例 2 发送请求，但此时，Slot 2 中的数据只有一部分迁移到了实例 3，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息， 12GET hello:key(error) ASK 13320 172.16.19.5:6379 这个结果中的 ASK 命令就表示，客户端请求的键值对所在的哈希槽 13320，在172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5这个实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 GET 命令，以读取数据。 在下图中，Slot 2 正在从实例 2 往实例 3 迁移，key1 和 key2 已经迁移过去，key3 和key4 还在实例 2。客户端向实例 2 请求 key2 后，就会收到实例 2 返回的 ASK 命令。 ASK 命令表示两层含义：第一，表明 Slot 数据还在迁移中；第二，ASK 命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 ASKING 命令，然后再发送操作命令。 和 MOVED 命令不同，ASK 命令并不会更新客户端缓存的哈希槽分配信息。所以，在上图中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。这也就是说，ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。 问题：为什么 Redis 不直接用一个表，把键值对和实例的对应关系记录下来？ 如果使用表记录键值对和实例的对应关系，一旦键值对和实例的对应关系发生了变化（例如实例有增减或者数据重新分布），就要修改表。如果是单线程操作表，那么所有操作都要串行执行，性能慢；如果是多线程操作表，就涉及到加锁开销。此外，如果数据量非常大，使用表记录键值对和实例的对应关系，需要的额外存储空间也会增加。 基于哈希槽计算时，虽然也要记录哈希槽和实例的对应关系，但是哈希槽的个数要比键值对的个数少很多，无论是修改哈希槽和实例的对应关系，还是使用额外空间存储哈希槽和实例的对应关系，都比直接记录键值对和实例的关系的开销小得多。","link":"/2021/05/15/Redis%EF%BC%88%E5%85%AD%EF%BC%89%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/"},{"title":"Redis（四）主从复制","text":"Redis 具有高可靠性，又是什么意思呢？其实，这里有两层含义： 一是数据尽量少丢失，通过RDB和AOF来保证 二是服务尽量少中断，增加副本冗余量，将一份数据同时保存在多个实例上。 主从复制的作用 数据的热备份 故障恢复 读写分离 高可用的基石 主从之间的第一次同步的三个阶段当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。 第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。 具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。 psync 命令包含了主库的 runID和复制进度 offset两个参数。 runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。 offset，此时设为 -1，表示第一次复制。 FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库 在第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。 具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。 在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录RDB 文件生成后收到的所有写操作。 第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。 主从级联模式 在一次全量复制中，对于主库来说，需要完成两个耗时的操作：生成 RDB 文件和传输 RDB 文件。 如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。那么，有没有好的解决方法可以分担主库压力呢？ 我们可以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上 一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。 网络中断后如何实现增量复制复制偏移量master/slave_repl_offset主从服务器都会维护一个复制偏移量，记录存储数据的字节数。 刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。 主库接收的新写操作越多，这个值就会越大。同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。 复制积压缓冲区repl_backlog_buffer当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。 repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。 当网络中断重新连接后，从库首先会给主库发送 psync 命令，并把自己当前的slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset之间的差距。在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset之间的命令操作同步给从库就行。 因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。 我们可以调整repl_backlog_size这个参数。这个参数和所需的缓冲空间大小有关。 一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销。另外，为了避免多个从库同时和主库进行全量复制，给主库过大的同步压力，我们也可以采用“主 - 从 - 从”这一级联模式，来缓解主库的压力。 有三种模式：全量复制、基于长连接的命令传播，以及增量复制。 命令传播阶段命令传播阶段，从服务器默认每过一秒就会发送replconf ack + 复制偏移量 给主服务器 为什么全量复制用RDB文件而不是AOF RDB是经过压缩之后的二进制文件，无论是把RDB写入磁盘还是通过网络传输，IO效率都比AOF高 RDB恢复数据的效率要高于AOF","link":"/2021/05/13/Redis%EF%BC%88%E5%9B%9B%EF%BC%89%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/05/06/hello-world/"},{"title":"测试图上传","text":"","link":"/2021/05/06/%E6%B5%8B%E8%AF%95%E5%9B%BE%E4%B8%8A%E4%BC%A0/"},{"title":"算法题","text":"哈哈 第一部分：四种基本情况 1. 无重复数字的二分查找https://leetcode-cn.com/problems/binary-search/ 123456789101112class Solution { public int search(int[] nums, int target) { int n = nums.length; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r + 1 &gt;&gt; 1; if(nums[mid] &gt; target) r = mid-1; else l = mid; } return nums[l] == target ? l : -1; }} 2. 有重复数字的二分查找第一个位置和最后一个位置https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/ 12345678910111213141516171819202122232425262728class Solution { public int[] searchRange(int[] nums, int target) { int[] res = new int[2]; int n = nums.length; if(n == 0) return new int[]{-1,-1}; //找到第一个出现的位置 int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; if(nums[mid] &lt; target) l = mid+1; else r = mid; } if(nums[l] != target) return new int[]{-1,-1}; else res[0] = l; //找到最后一个出现的位置 l = 0; r = n-1; while(l &lt; r){ int mid = l + r +1 &gt;&gt; 1; if(nums[mid] &gt; target) r = mid-1; else l = mid; } res[1] = l; return res; }} 3. 搜索插入位置https://leetcode-cn.com/problems/search-insert-position/ 12345678910111213141516class Solution { public int searchInsert(int[] nums, int target) { int n = nums.length; //1. 注意如果最后一个数小于target的话，就返回数组长度 if (n == 0 || nums[n-1] &lt; target) return n; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; if(nums[mid] &lt; target) l = mid + 1; else r = mid; } return l; }} 4. x的平方根（只保留整数部分）12345678910111213 class Solution { public int mySqrt(int x) { int l = 0 , r = x; while(l &lt; r){ int mid = l + r + 1 &gt;&gt; 1; if(mid &gt; x / mid) r = mid-1; else l = mid; } return l; }} 5. 寻找重复的数https://leetcode-cn.com/problems/find-the-duplicate-number/ 123456789101112131415161718192021class Solution { public int findDuplicate(int[] nums) { int n = nums.length; //对值的范围进而二分 int l = 0 , r = n-1; while (l &lt; r){ int mid = l+r &gt;&gt;1; //看一下数组中比mid小的数有多少 int count = 0; for (int num : nums){ if (num &lt;= mid) count++; } //比mid小的数大于mid，说明在左边,可能是mid if (count &gt; mid) r = mid; else l = mid+1; } return l; }} 6. 实现Pow(x,n)https://leetcode-cn.com/problems/powx-n/comments/ 12345678910111213class Solution { public double myPow(double x, int n) { double res = 1.0; for(int i = n ; i != 0 ; i /=2){ if(i % 2 != 0) res = res * x; x *= x; } return n &lt; 0 ? 1/res : res; }} 7. 寻找两个排序数组的中位数https://leetcode-cn.com/problems/median-of-two-sorted-arrays/ 1234567891011121314151617181920212223242526class Solution { public double findMedianSortedArrays(int[] nums1, int[] nums2) { int n = nums1.length; int m = nums2.length; int l = (n + m + 1)/2; int r = (n + m + 2)/2; return (getK(nums1, 0 , n-1 , nums2 , 0 , m-1 , l) + getK(nums1 , 0 ,n-1 , nums2 ,0,m-1,r))/2.0; } //从两个正序数组中获取第k大的数 int getK(int[] nums1 , int s1 , int e1 , int[] nums2 , int s2 , int e2 , int k){ int len1 = e1 - s1 + 1; int len2 = e2 - s2 + 1; if(len1 &gt; len2) return getK(nums2 , s2 , e2 , nums1 , s1 , e1 , k); if(len1 == 0) return nums2[s2 + k -1]; if(k == 1) return Math.min(nums1[s1] , nums2[s2]); int i = s1 + Math.min(len1 , k/2)-1; //每次取一半的值 int j = s2 + Math.min(len2 , k/2)-1; //每一轮都将较小的那半组数据舍去 if(nums1[i] &gt; nums2[j]) return getK(nums1 , s1 ,e1 , nums2 ,j+1, e2 ,k-(j-s2+1)); else return getK(nums1, i+1 ,e1 , nums2 , s2 , e2 , k-(i-s1+1)); }} 第二部分：旋转排序数组1. 寻找旋转排序数组中的最小值(无重复值)https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array/ 1234567891011121314class Solution { public int findMin(int[] nums) { int n = nums.length; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; //34512 if(nums[mid] &gt; nums[r]) l = mid+1; else r = mid; } return nums[l]; }} 2. 寻找旋转排序数组中的最小值(有重复值)https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array-ii/ 12345678910111213class Solution { public int findMin(int[] nums) { int n = nums.length; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; if(nums[mid] &gt; nums[r]) l = mid+1; else if(nums[mid] &lt; nums[r]) r = mid; else r--; } return nums[l]; }} 3. 寻找旋转排序数组中的指定值(无重复值)https://leetcode-cn.com/problems/search-in-rotated-sorted-array/ 123456789101112131415161718192021class Solution { public int search(int[] nums, int target) { int n = nums.length; if(n == 0) return -1; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; //34512 if(nums[mid] &gt; nums[r]){ if(target &gt;= nums[l] &amp;&amp; target &lt;= nums[mid]) r = mid; else l = mid+1; }else{ //561234 if(target &gt; nums[mid] &amp;&amp; target &lt;= nums[r]) l = mid+1; else r = mid; } } return nums[l] == target ? l : -1; }} 第三部分：二维矩阵1. 搜索二维矩阵https://leetcode-cn.com/problems/search-a-2d-matrix/ 123456789101112131415class Solution { public boolean searchMatrix(int[][] matrix, int target) { int m = matrix.length; //行数 int n = matrix[0].length; //列数 int l = 0 , r = m *n -1; while(l &lt; r){ int mid = l + r + 1 &gt;&gt; 1; //将一维的数组转换成二维的坐标 if(matrix[mid / n][ mid % n] &gt; target) r = mid-1; else l = mid; } return matrix[l/n][l%n] == target; }} 2. 搜索二维矩阵2https://leetcode-cn.com/problems/search-a-2d-matrix-ii/submissions/ 1234567891011121314class Solution { public boolean searchMatrix(int[][] matrix, int target) { int m = matrix.length; //行数 int n = matrix[0].length; //列数 int i = 0 , j = n-1; while(i &lt;= m-1 &amp;&amp; j &gt;= 0){ if(matrix[i][j] &gt; target) j--; else if(matrix[i][j] &lt; target) i++; else return true; } return false; }} 3. 有序矩阵中第k小的数https://leetcode-cn.com/problems/kth-smallest-element-in-a-sorted-matrix/","link":"/2021/05/06/%E7%AE%97%E6%B3%95%E9%A2%98/"},{"title":"Redis（一）数据结构类型","text":"Redis为什么这么快呢？ 基于内存操作 优化后的数据结构 单线程 键和值的保存方式在Redis中，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是Redis快速处理数据的基础。 String (字符串)、List (列表)、Hash (哈希)、Set (集合)和Sorted Set (有序集合)这些只是Redis键值对中值的数据类型，也就是数据的保存形式。而这里，我们说的数据结构，是要去看看它们的底层实现 全局哈希表为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。 一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。 其实，哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。这也就是说，不管值是String，还是集合类型，哈希桶中的元素都是指向它们的指针。 为什么哈希操作会变慢当你往哈希表中写入更多数据时，哈希冲突是不可避免的问题。这里的哈希冲突，也就是指,两个key的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。 Redis 解决哈希冲突的方式，就是链式哈希。链式哈希也很容易理解，就是指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接 当链表长度过长时，会导致这个链上元素查找事件越来越久，是一个O(n)的操作。 渐进式rehashRedis 会对哈希表做 rehash 操作。rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。 其实，为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步： 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍； 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中； 释放哈希表 1 的空间。 第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求。此时，Redis 就无法快速访问数据了。为了避免这个问题，Redis 采用了渐进式 rehash： 简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的entries。 把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。 六种数据结构 简单动态字符串SDSsimple dynamic string 12345struct { int len; //记录字节数组中已经使用的长度 == 字符串的长度 4个字节 int free; //记录字节数组中未使用的长度 4个字节 char[] buf; //字节数组，保存字符串 4个字节} 和C中字符串的区别 常数复杂度获取字符串的长度,C中的字符串获取长度需要On，而SDS中保存了len属性 杜绝了缓冲区溢出。C语言中进行字符串拼接需要先分配足够的内存，否则会发生缓冲区溢出。而SDS中的API会自动的先检查空间是否足够，因为记录了字符串长度，所以比较快。（如果空间不够，不仅会分配足够的空间，还会分配足够的未使用空间） 减少了修改字符串带来的内存重分配。C中字符串每次赠长或缩短，都要进行内存重分配，否则会发生缓冲区溢出和内存泄露的问题。redis中进行会修改字符串，所以会有未使用的空间可以使用空间预分配和惰性空间释放。 二进制安全。C字符串末尾是\\0,所以不能包含空字符串，只能保存文本数据，不能保存二进制数据。而SDS是可以的。 兼容部分C字符串的函数。 SDS是如何减少内存重分配的 空间预分配：当用SDS的API对SDS进行修改的时候，不仅会分配修改所必须使用的空间，还会分配额外的未使用空间。在扩展SDS空间之前，会先检查未使用的空间是否足够，如果足够就直接使用而无须执行内存重分配。通过这种策略：连续赠长N次字符串的内存重分配次数由N次降低为最多N次。 惰性空间释放：SDS进行缩短操作的时候，不会立即内存重分配来回收缩短后多出来的字节，而是使用free属性记录下来。 案例分析保存一个10位数的图片id和图片存储id： 12photo_id: 1101000051photo_obj_id: 3301000051 我们保存了 1 亿张图片的信息，用了约 6.4GB 的内存，一个图片 ID 和图片存储对象 ID 的记录平均用了 64 字节。但实际上实际只需要 16 字节就可以了（两个 8 字节的Long 类型表示这两个 ID。）。 但其实，除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较大了，有点“喧宾夺主”的意思。 String 类型具体是怎么保存数据的呢？我来解释一下。 当你保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数，这种保存方式通常也叫作 int 编码方式。 当你保存的数据中包含字符时，会用SDS来保存 针对于RedisObject的优化： 一方面，当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。 另一方面，当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式。 当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。 因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码的 RedisObject 保存。每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直接赋值为 8 字节的整数了。此时，每个 ID 会使用 16 字节，加起来一共是 32 字节。但是，另外的 32 字节去哪儿了呢？ Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节， 但是，这三个指针只有 24 字节，为什么会占用了 32 字节呢？这就要提到 Redis 使用的内存分配库 jemalloc 了。jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。举个例子。如果你申请 6 字节空间，jemalloc 实际会分配 8 字节空间；如果你申请 24 字节空间，jemalloc 则会分配 32 字节。所以，在我们刚刚说的场景里，dictEntry 结构就占用了 32 字节。 双向列表压缩列表压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。 在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。 压缩列表是一种非常紧凑的数据结构，占用的内存比链表要少。 哈希表跳表有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位， 整形数组RedisObject因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据。 一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向 String 类型的 SDS 结构所在的内存地址，可以看一下下面的示意图。关于 RedisObject 的具体结构细节，我会在后面的课程中详细介绍，现在你只要了解它的基本结构和元数据开销就行了。 不同操作的时间复杂度第一，单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、SREM、SRANDMEMBER 复杂度也是 O(1)。这里，有个地方你需要注意一下，集合类型支持同时对多个元素进行增删改查，例如 Hash类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。此时，这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元素时，复杂度就从 O(1) 变成 O(M) 了。第二，范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 Hash类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List类型的 LRANGE 和 ZSet 类型的 ZRANGE。这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。不过，Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。第三，统计操作，是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。 第四，例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。","link":"/2021/05/13/Redis%EF%BC%88%E4%B8%80%EF%BC%89%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%B1%BB%E5%9E%8B/"},{"title":"Netty（八）优化和安全","text":"","link":"/2021/05/27/Netty%EF%BC%88%E5%85%AB%EF%BC%89%E4%BC%98%E5%8C%96%E5%92%8C%E5%AE%89%E5%85%A8/"},{"title":"Redis（五）哨兵模式","text":"如果主库挂了，如何才能不间断的提供服务呢？ 哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的这三个问题。 哨兵的主要任务由一个或多个哨兵实例组成的哨兵系统可用监视多个主服务器及下属的所有从服务器，主服务器下线后会自动将从服务器升级成主服务器实现故障转移。哨兵本质上就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。 监控监控是指哨兵进程在运行时，周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的 PING 命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。 选主主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。 通知在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。 主服务下线的两种状态判定主观下线：哨兵默认每秒向创建命令连接的实例（主从服务器和其他哨兵）发送ping命令，根据回复判定是否在线。在配置文件中配置了down- after-minlliseconds属性，超过了这个时间没有回复就将实例的标识属性计作主观下线（不同哨兵对同一个实例的在线状态判定可能并不相同） 通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。 客观下线：哨兵认为主服务器主观下线时，还会向其他哨兵询问，看有多少哨兵也认为这个主服务器下线了，如果超过一个阈值就认为该主服务器客观下线，进行故障转移。 如何选定新主库筛选机制在选主时，除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。 具体怎么判断呢？你使用配置项 down-after-milliseconds * 10。其中，down-after\u0002milliseconds 是我们认定主从库断连的最大连接超时时间。如果在 down-after\u0002milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。 打分机制 优先级最高的从库得分高。用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如，你有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。 和旧主库同步程度最接近的从库得分高。主从库同步时有个命令传播的过程。在这个过程中，主库会用master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度。此时，我们想要找的从库，它的 slave_repl_offset 需要最接近 master_repl_offset。 ID 号小的从库得分高。在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。 哨兵集群在配置哨兵的信息时，我们只需要用到下面的这个配置项，设置主库的 IP和端口，并没有配置其他哨兵的连接信息。 sentinelmonitor 哨兵实例既然都不知道彼此的地址，又是怎么组成集群的呢？ pub/sub机制Redis的消息订阅发布机制为了区分不同应用的消息，Redis 会以频道的形式，对这些消息进行分门别类的管理。所谓的频道，实际上就是消息的类别。当消息类别相同时，它们就属于同一个频道。反之，就属于不同的频道。只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。 在主从集群中，主库上有一个名为“sentinel:hello”的频道，不同哨兵就是通过它来相互发现，实现互相通信的。 在下图中，哨兵 1 把自己的 IP（172.16.19.3）和端口（26579）发布到“sentinel:hello”频道上，哨兵 2 和 3 订阅了该频道。那么此时，哨兵 2 和 3 就可以从这个频道直接获取哨兵 1 的 IP 地址和端口号。然后，哨兵 2、3 可以和哨兵 1 建立网络连接。通过这个方式，哨兵 2 和 3 也可以建立网络连接，这样一来，哨兵集群就形成了。它们相互间可以通过网络连接进行通信，比如对主库有没有下线这件事儿进行判断和协商。 哨兵如何和从库建立连接在哨兵的监控任务中，它需要对主从库都进行心跳判断，而且在主从库切换完成后，它还需要通知从库，让它们和新主库进行同步。 哨兵是如何知道从库的 IP 地址和端口的呢？ 这是由哨兵向主库发送 INFO 命令来完成的。就像下图所示，哨兵 2 给主库发送 INFO 命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。哨兵 1和 3 可以通过相同的方法和从库建立连接。 客户端如何感知发生了主库的切换呢每个哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。 客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。 在客户端执行订阅命令，来获取不同的事件消息。 SUBSCRIBE+odown. //订阅“所有实例进入客观下线状态的事件”： PSUBSCRIBE * //订阅所有的事件 当哨兵把新主库选择出来后，客户端就会看到下面的 switch-master 事件。这个事件表示主库已经切换了，新主库的 IP 地址和端口信息已经有了。 switch-master 有了这些事件通知，客户端不仅可以在主从切换后得到新主库的连接信息，还可以监控到主从库切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。 哨兵的选举过程主库故障以后，哨兵集群有多个实例，那怎么确定由哪个哨兵来进行实际的主从切换呢？ 任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down\u0002by-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。 一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的。例如，现在有 5 个哨兵，quorum 配置的是 3，那么，一个哨兵需要 3 张赞成票，就可以标记主库为“客观下线”了。这 3 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“Leader 选举”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader。 总而言之，任何一个想成为 Leader 的哨兵，要满足两个条件： 第一，拿到半数以上的赞成票； 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。以 3 个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到2 张赞成票，就可以了。 在 T1 时刻，S1 判断主库为“客观下线”，它想成为 Leader，就先给自己投一张赞成票，然后分别向 S2 和 S3 发送命令，表示要成为 Leader。 在 T2 时刻，S3 判断主库为“客观下线”，它也想成为 Leader，所以也先给自己投一张赞成票，再分别向 S1 和 S2 发送命令，表示要成为 Leader。 在 T3 时刻，S1 收到了 S3 的 Leader 投票请求。因为 S1 已经给自己投了一票 Y，所以它不能再给其他哨兵投赞成票了，所以 S1 回复 N 表示不同意。同时，S2 收到了 T2 时 S3发送的 Leader 投票请求。因为 S2 之前没有投过票，它会给第一个向它发送投票请求的哨兵回复 Y，给后续再发送投票请求的哨兵回复 N，所以，在 T3 时，S2 回复 S3，同意 S3成为 Leader。 在 T4 时刻，S2 才收到 T1 时 S1 发送的投票命令。因为 S2 已经在 T3 时同意了 S3 的投票请求，此时，S2 给 S1 回复 N，表示不同意 S1 成为 Leader。发生这种情况，是因为S3 和 S2 之间的网络传输正常，而 S1 和 S2 之间的网络传输可能正好拥塞了，导致投票请求传输慢了。 在 T5 时刻，S1 得到的票数是来自它自己的一票 Y 和来自 S2 的一票 N。而 S3 除了自己的赞成票 Y 以外，还收到了来自 S2 的一票 Y。此时，S3 不仅获得了半数以上的Leader 赞成票，也达到预设的 quorum 值（quorum 为 2），所以它最终成为了Leader。接着，S3 会开始执行选主操作，而且在选定新主库后，会给其他从库和客户端通知新主库的信息。 如果 S3 没有拿到 2 票 Y，那么这轮投票就不会产生 Leader。哨兵集群会等待一段时间（也就是哨兵故障转移超时时间的 2 倍），再重新选举。这是因为，哨兵集群能够进行成功投票，很大程度上依赖于选举命令的正常网络传播。如果网络压力较大或有短时堵塞，就可能导致没有一个哨兵能拿到半数以上的赞成票。所以，等到网络拥塞好转之后，再进行投票选举，成功的概率就会增加。","link":"/2021/05/13/Redis%EF%BC%88%E4%BA%94%EF%BC%89%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"},{"title":"消息队列基础问题","text":"消息队列基础篇，主要描述了四个问题： 为什么要用消息队列 如何保证消息不丢失 如何保证消息不重复消费 如何处理消息的积压 消息队列的使用场景异步处理我们以常见的电商秒杀场景为例，秒杀系统需要解决的核心问题是，如何利用有限的服务器资源，尽可能多地处理短时间内的海量请求。 一个秒杀通常包含了一下几个步骤： 风险控制 库存锁定 生成订单 短信通知 更新统计数据等等。。 如果没有任何优化处理的话，正常的处理流程是：App 将请求发送给网关，依次调用上述 5 个流程，然后将结果返回给 APP。但实际上，用户能否秒杀成功主要是看风险控制和库存锁定两步，也就是说当服务端完成前面 2 个步骤，确定本次请求的秒杀结果后，就可以马上给用户返回响应，剩余的步骤都可以放入消息队列中，异步的进行后续的处理。 这样处理之后，在秒杀期间我们可以用更多的服务器资源来处理秒杀请求，秒杀结束后再异步的处理后续的步骤。 在这个场景中，消息队列被用于实现服务的异步处理。这样做的好处是： 可以更快地返回结果； 减少等待，自然实现了步骤之间的并发，提升系统总体的性能。 流量削峰还是以秒杀场景为例，我们已经通过部分异步处理提高了用户的响应效率，下一个问题是如何避免瞬间过多的请求压垮我们的秒杀系统？ 一个设计健壮的程序有自我保护的能力，也就是说，它应该可以在海量的请求下，还能在自身能力范围内尽可能多地处理请求，拒绝处理不了的请求并且保证自身运行正常。不幸的是，现实中很多程序并没有那么“健壮”，而直接拒绝请求返回错误对于用户来说也是不怎么好的体验。 使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的。 加入消息队列后，整个秒杀流程变为： 网关在收到请求后，将请求放入请求消息队列； 后端服务从请求消息队列中获取 APP 请求，完成后续秒杀处理过程，然后返回结果。 秒杀开始后，当短时间内大量的秒杀请求到达网关时，不会直接冲击到后端的秒杀服务，而是先堆积在消息队列中，后端服务按照自己的最大处理能力，从消息队列中消费请求进行处理。 对于超时的请求可以直接丢弃，APP 将超时无响应的请求处理为秒杀失败即可。运维人员还可以随时增加秒杀服务的实例数量进行水平扩容，而不用对系统的其他部分做任何更改。 这种设计的优点是：能根据下游的处理能力自动调节流量，达到“削峰填谷”的作用。但这样做同样是有代价的： 增加了系统调用链环节，导致总体的响应时延变长。 上下游系统都要将同步调用改为异步消息，增加了系统的复杂度。 消息队列实现令牌桶进行限流令牌桶控制流量的原理是：单位时间内只发放固定数量的令牌到令牌桶中，规定服务在处理请求之前必须先从令牌桶中拿出一个令牌，如果令牌桶中没有令牌，则拒绝请求。这样就保证单位时间内，能处理的请求不超过发放令牌的数量，起到了流量控制的作用。 网关在处理 APP 请求时增加一个获取令牌的逻辑。 令牌桶可以简单地用一个有固定容量的消息队列加一个“令牌发生器”来实现：令牌发生器按照预估的处理能力，匀速生产令牌并放入令牌队列（如果队列满了则丢弃令牌），网关在收到请求时去令牌队列消费一个令牌，获取到令牌则继续调用后端秒杀服务，如果获取不到令牌则直接返回秒杀失败。 服务解耦订单信息是电商系统中比较核心的数据，当一个新订单创建时： 支付系统需要发起支付流程； 风控系统需要审核订单的合法性； 客服系统需要给用户发短信告知用户； 经营分析系统需要更新统计数据； 这些订单下游的系统都需要实时获得订单数据。随着业务不断发展，这些订单下游系统不断的增加，不断变化，并且每个系统可能只需要订单数据的一个子集，负责订单服务的开发团队不得不花费很大的精力，应对不断增加变化的下游系统，不停地修改调试订单系统与这些下游系统的接口。任何一个下游系统接口变更，都需要订单模块重新进行一次上线，对于一个电商的核心服务来说，这几乎是不可接受的。 所有的电商都选择用消息队列来解决类似的系统耦合过于紧密的问题。引入消息队列后，订单服务在订单变化时发送一条消息到消息队列的一个主题 Order 中，所有下游系统都订阅主题 Order，这样每个下游系统都可以获得一份实时完整的订单数据。 如何保证消息不丢失如何检测消息是否丢失 如果是 IT 基础设施比较完善的公司，一般都有分布式链路追踪系统，使用类似的追踪系统可以很方便地追踪每一条消息。 如果没有这样的追踪系统，这里我提供一个比较简单的方法，来检查是否有消息丢失的情况。我们可以利用消息队列的有序性来验证是否有消息丢失。原理非常简单，在 Producer 端，我们给每个发出的消息附加一个连续递增的序号，然后在 Consumer 端来检查这个序号的连续性。如果没有消息丢失，Consumer 收到消息的序号必然是连续递增的，或者说收到的消息，其中的序号必然是上一条消息的序号 +1。如果检测到序号不连续，那就是丢消息了。还可以通过缺失的序号来确定丢失的是哪条消息，方便进一步排查原因。 大多数消息队列的客户端都支持拦截器机制，你可以利用这个拦截器机制，在 Producer 发送消息之前的拦截器中将序号注入到消息中，在 Consumer 收到消息的拦截器中检测序号的连续性，这样实现的好处是消息检测的代码不会侵入到你的业务代码中，待你的系统稳定后，也方便将这部分检测的逻辑关闭或者删除。 分布式系统中需要注意的点 首先，像 Kafka 和 RocketMQ 这样的消息队列，它是不保证在 Topic 上的严格顺序的，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。 如果你的系统中 Producer 是多实例的，由于并不好协调多个 Producer 之间的发送顺序，所以也需要每个 Producer 分别生成各自的消息序号，并且需要附加上 Producer 的标识，在 Consumer 端按照每个 Producer 分别来检测序号的连续性。 Consumer 实例的数量最好和分区数量一致，做到 Consumer 和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性。 如何确保消息可靠传递 生产阶段: 在这个阶段，从消息在 Producer 创建出来，经过网络传输发送到 Broker 端。 存储阶段: 在这个阶段，消息在 Broker 端存储，如果是集群，消息会在这个阶段被复制到其他的副本上。 消费阶段: 在这个阶段，Consumer 从 Broker 上拉取消息，经过网络传输发送到 Consumer 上。 1. 生产阶段： 在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传递：当你的代码调用发消息方法时，消息队列的客户端会把消息发送到 Broker，Broker 收到消息后（最好写入到磁盘中才返回确认消息），会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送。 12345678你在编写发送消息代码时，需要注意，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失。 try { RecordMetadata metadata = producer.send(record).get(); System.out.println(&quot; 消息发送成功。&quot;);} catch (Throwable e) { System.out.println(&quot; 消息发送失败！&quot;); System.out.println(e);} 异步发送时，则需要在回调方法里进行检查。这个地方是需要特别注意的，很多丢消息的原因就是，我们使用了异步发送，却没有在回调中检查发送结果。 12345678producer.send(record, (metadata, exception) -&gt; { if (metadata != null) { System.out.println(&quot; 消息发送成功。&quot;); } else { System.out.println(&quot; 消息发送失败！&quot;); System.out.println(exception); }}); 2.存储阶段： 在存储阶段正常情况下，只要 Broker 在正常运行，就不会出现丢失消息的问题，但是如果 Broker 出现了故障，比如进程死掉了或者服务器宕机了，还是可能会丢失消息的。 对于单个节点的 Broker，需要配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费。例如，在 RocketMQ 中，需要将刷盘方式 flushDiskType 配置为 SYNC_FLUSH 同步刷盘。 如果是 Broker 是由多个节点组成的集群，需要将 Broker 集群配置成：至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker，也不会发生消息丢失。 3.消费阶段 消费阶段采用和生产阶段类似的确认机制来保证消息的可靠传递，客户端从 Broker 拉取消息后，执行用户的消费业务逻辑，成功后，才会给 Broker 发送消费确认响应。如果 Broker 没有收到消费确认响应，下次拉消息的时候还会返回同一条消息，确保消息不会在网络传输过程中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失。 你在写消费代码时需要注意的是，不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。 如何保证消费过程中的重复消息（幂等性）在消息传递过程中，如果出现传递失败的情况，发送方会执行重试，重试的过程中就有可能会产生重复的消息。对使用消息队列的业务系统来说，如果没有对重复消息进行处理，就有可能会导致系统的数据出现错误 消息重复的情况必然存在在 MQTT 协议中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是： At most once: 至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。 At least once: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。 Exactly once：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。 这个服务质量标准不仅适用于 MQTT，对所有的消息队列都是适用的。我们现在常用的绝大部分消息队列提供的服务质量都是 At least once，包括 RocketMQ、RabbitMQ 和 Kafka 都是这样。也就是说，消息队列很难保证消息不重复。 用幂等性解决重复消息问题一个幂等操作的特点是，其任意多次执行所产生的影响均与一次执行的影响相同。 利用数据库的唯一约束实现幂等例如我们刚刚提到的那个不具备幂等特性的转账的例子：将账户 X 的余额加 100 元。在这个例子中，我们可以通过改造业务逻辑，让它具备幂等性。 首先，我们可以限定，对于每个转账单每个账户只可以执行一次变更操作，在分布式系统中，这个限制实现的方法非常多，最简单的是我们在数据库中建一张转账流水表，这个表有三个字段：转账单 ID、账户 ID 和变更金额，然后给转账单 ID 和账户 ID 这两个字段联合起来创建一个唯一约束，这样对于相同的转账单 ID 和账户 ID，表里至多只能存在一条记录。 基于这个思路，不光是可以使用关系型数据库，只要是支持类似“INSERT IF NOT EXIST”语义的存储类系统都可以用于实现幂等，比如，你可以用 Redis 的 SETNX 命令来替代数据库中的唯一约束，来实现幂等消费。 为更新的数据设置前置条件给数据变更设置一个前置条件，如果满足条件就更新数据，否则拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。这样，重复执行这个操作时，由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。 比如，刚刚我们说过，“将账户 X 的余额增加 100 元”这个操作并不满足幂等性，我们可以把这个操作加上一个前置条件，变为：“如果账户 X 当前的余额为 500 元，将余额加 100 元”，这个操作就具备了幂等性。对应到消息队列中的使用时，可以在发消息时在消息体中带上当前的余额，在消费的时候进行判断数据库中，当前余额是否与消息中的余额相等，只有相等才执行变更操作。 更加通用的方法是，给你的数据增加一个版本号属性，每次更数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时将版本号 +1，一样可以实现幂等更新 记录并检查操作我们还有一种通用性最强，适用范围最广的实现幂等性方法：记录并检查操作，也称为“Token 机制或者 GUID（全局唯一 ID）机制”，实现的思路特别简单：在执行数据更新操作之前，先检查一下是否执行过这个更新操作。 具体的实现方法是，在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。 更加麻烦的是，在“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作保证原子性，才能真正实现幂等，否则就会出现 Bug 比如说，对于同一条消息：“全局 ID 为 8，操作为：给 ID 为 666 账户增加 100 元”，有可能出现这样的情况： t0 时刻：Consumer A 收到条消息，检查消息执行状态，发现消息未处理过，开始执行“账户增加 100 元”； t1 时刻：Consumer B 收到条消息，检查消息执行状态，发现消息未处理过，因为这个时刻，Consumer A 还未来得及更新消息执行状态。 这样就会导致账户被错误地增加了两次 100 元，这是一个在分布式系统中非常容易犯的错误，一定要引以为戒。 对于这个问题，当然我们可以用事务来实现，也可以用锁来实现，但是在分布式系统中，无论是分布式事务还是分布式锁都是比较难解决问题。 消息积压了该怎么办优化性能来避免消息积压发送端性能优化优化消息收发性能，预防消息积压的方法有两种，增加批量或者是增加并发，在发送端这两种方法都可以使用。 Producer 发送消息的过程，Producer 发消息给 Broker，Broker 收到消息后返回确认响应，这是一次完整的交互。假设这一次交互的平均时延是 1ms，我们把这 1ms 的时间分解开，它包括了下面这些步骤的耗时： 发送端准备数据、序列化消息、构造请求等逻辑的时间，也就是发送端在发送网络请求之前的耗时； 发送消息和返回响应在网络传输中的耗时； Broker 处理消息的时延 无论是增加每次发送消息的批量大小，还是增加并发，都能成倍地提升发送性能 比如说，你的消息发送端是一个微服务，主要接受 RPC 请求处理在线业务。很自然的，微服务在处理每次请求的时候，就在当前线程直接发送消息就可以了，因为所有 RPC 框架都是多线程支持多并发的，自然也就实现了并行发送消息。并且在线业务比较在意的是请求响应时延，选择批量发送必然会影响 RPC 服务的时延。这种情况，比较明智的方式就是通过并发来提升发送性能。 如果你的系统是一个离线分析系统，离线系统在性能上的需求是什么呢？它不关心时延，更注重整个系统的吞吐量。发送端的数据都是来自于数据库，这种情况就更适合批量发送，你可以批量从数据库读取数据，然后批量来发送消息，同样用少量的并发就可以获得非常高的吞吐量。 消费端性能优化使用消息队列的时候，大部分的性能问题都出现在消费端，如果消费的速度跟不上发送端生产消息的速度，就会造成消息积压。如果这种性能倒挂的问题只是暂时的，那问题不大，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息是可以逐渐被消化掉的。 我们在设计系统的时候，一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。 消费端的性能优化除了优化消费业务逻辑以外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。特别需要注意的一点是，在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。原因我们之前讲过，因为对于消费者来说，在每个分区上实际上只能支持单线程消费 消息积压了该如何处理？能导致积压突然增加，最粗粒度的原因，只有两种：要么是发送变快了，要么是消费变慢了。 大部分消息队列都内置了监控的功能，只要通过监控数据，很容易确定是哪种原因。如果是单位时间发送的消息增多，比如说是赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升消费性能，唯一的方法是通过扩容消费端的实例数来提升总体的消费能力。 如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。 还有一种不太常见的情况，你通过监控发现，无论是发送消息的速度还是消费消息的速度和原来都没什么变化，这时候你需要检查一下你的消费端，是不是消费失败导致的一条消息反复消费这种情况比较多，这种情况也会拖慢整个系统的消费速度。 总结","link":"/2021/05/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%9F%BA%E7%A1%80%E9%97%AE%E9%A2%98/"},{"title":"git之基本操作","text":"git是工作用到的分布式的版本控制工具 –学自极客时间git专栏 使用Git之前的最小配置配置用户名和邮箱12345678910shengbinbin@192 ~ % git versiongit version 2.24.3 (Apple Git-128)//配置用户名和邮箱 shengbinbin@192 ~ % git config --global user.name 'binshow'shengbinbin@192 ~ % git config --global user.email '1157024800@qq.com'--local ： 只对某个仓库有效--global 对当前用户的所有仓库有效--system 对系统所有登陆的用户有效，基本不用 123456shengbinbin@192 ~ % git config --list //显示git的配置credential.helper=osxkeychainuser.name=binshowuser.mail=1157024800@qq.comuser.email=1157024800@qq.comshengbinbin@192 ~ % 创建第一个仓库并配置local用户信息123456789101112131415161718192021222324252627282930313233343536shengbinbin@chengbinbindeMacBook-Pro Code % pwd/Users/shengbinbin/Documents/Codeshengbinbin@chengbinbindeMacBook-Pro Code % git init git_learning //1.创建好一个git仓库文件夹，命名为 git_learninghint: Using 'master' as the name for the initial branch. This default branch namehint: is subject to change. To configure the initial branch name to use in allhint: of your new repositories, which will suppress this warning, call:hint:hint: git config --global init.defaultBranch &lt;name&gt;hint:hint: Names commonly chosen instead of 'master' are 'main', 'trunk' andhint: 'development'. The just-created branch can be renamed via this command:hint:hint: git branch -m &lt;name&gt;Initialized empty Git repository in /Users/shengbinbin/Documents/Code/git_learning/.git/shengbinbin@chengbinbindeMacBook-Pro Code % cd git_learningshengbinbin@chengbinbindeMacBook-Pro git_learning % ls -altotal 0drwxr-xr-x 3 shengbinbin staff 96 6 22 21:47 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 9 shengbinbin staff 288 6 22 21:47 .git //2. .git是核心文件夹 //3.设置local的相关信息shengbinbin@chengbinbindeMacBook-Pro git_learning % git config --local user.name 'shengbinbin'shengbinbin@chengbinbindeMacBook-Pro git_learning % git config --local user.email '1157024800@qq.com'shengbinbin@chengbinbindeMacBook-Pro git_learning % git config --local --list //4.查看local的相关信息core.repositoryformatversion=0core.filemode=truecore.bare=falsecore.logallrefupdates=truecore.ignorecase=truecore.precomposeunicode=trueuser.name=shengbinbinuser.email=1157024800@qq.com 添加第一个文件readMe1234567891011121314151617181920212223242526272829303132333435363738394041 //1. 将材料中的readMe拷贝到当前目录下shengbinbin@chengbinbindeMacBook-Pro git_learning % cp ../0-material/readme .shengbinbin@chengbinbindeMacBook-Pro git_learning % ls -altotal 8drwxr-xr-x 4 shengbinbin staff 128 6 22 21:51 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 9 shengbinbin staff 288 6 22 21:50 .git-rw-r--r--@ 1 shengbinbin staff 51 6 22 21:51 readme //2. 直接进行commit提交会报错，（-m表示这次提交的意义是什么）shengbinbin@chengbinbindeMacBook-Pro git_learning % git commit -m'Add readMe'On branch masterInitial commitUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) readmenothing added to commit but untracked files present (use &quot;git add&quot; to track) //3. 先用git add 将文件加入暂存区shengbinbin@chengbinbindeMacBook-Pro git_learning % git add readmeshengbinbin@chengbinbindeMacBook-Pro git_learning % git status //4. 查看状态On branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: readmeshengbinbin@chengbinbindeMacBook-Pro git_learning % git commit -m'Add readMe' //5. 最后成功提交[master (root-commit) d59544f] Add readMe 1 file changed, 2 insertions(+) create mode 100644 readmeshengbinbin@chengbinbindeMacBook-Pro git_learning % git logcommit d59544f7fba30a55f9511993709de2403c9cfbe5 (HEAD -&gt; master)Author: shengbinbin &lt;1157024800@qq.com&gt; //local的配置参数优先级较高Date: Tue Jun 22 21:52:44 2021 +0800 Add readMeshengbinbin@chengbinbindeMacBook-Pro git_learning % 工作区和暂存区 添加index + logo 123456789101112131415161718192021222324shengbinbin@chengbinbindeMacBook-Pro git_learning % cp ../0-material/index.html.01 index.html //复制一个网页过来shengbinbin@chengbinbindeMacBook-Pro git_learning % cp -r ../0-material/images . //复制整个文件夹过来shengbinbin@chengbinbindeMacBook-Pro git_learning % git statusOn branch masterUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) images/ index.htmlnothing added to commit but untracked files present (use &quot;git add&quot; to track)shengbinbin@chengbinbindeMacBook-Pro git_learning % git add index.html images //3.将两个文件加入到暂存区shengbinbin@chengbinbindeMacBook-Pro git_learning % git statusOn branch masterChanges to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) new file: images/git-logo.png new file: index.htmlshengbinbin@chengbinbindeMacBook-Pro git_learning % git commit -m 'ADD index + logo'[master 2a76eaa] ADD index + logo 2 files changed, 49 insertions(+) create mode 100644 images/git-logo.png create mode 100644 index.htmlshengbinbin@chengbinbindeMacBook-Pro git_learning % 添加css： 1234567891011121314151617181920212223shengbinbin@chengbinbindeMacBook-Pro git_learning % mkdir stylesshengbinbin@chengbinbindeMacBook-Pro git_learning % cp ../0-material/styles/style.css.01 styles/style.cssshengbinbin@chengbinbindeMacBook-Pro git_learning % ls -altotal 16drwxr-xr-x 7 shengbinbin staff 224 6 22 22:00 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 12 shengbinbin staff 384 6 22 21:57 .gitdrwxr-xr-x@ 3 shengbinbin staff 96 6 22 21:57 images-rw-r--r--@ 1 shengbinbin staff 1303 6 22 21:57 index.html-rw-r--r--@ 1 shengbinbin staff 51 6 22 21:51 readmedrwxr-xr-x 3 shengbinbin staff 96 6 22 22:00 stylesshengbinbin@chengbinbindeMacBook-Pro git_learning % git statusOn branch masterUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) styles/nothing added to commit but untracked files present (use &quot;git add&quot; to track)shengbinbin@chengbinbindeMacBook-Pro git_learning % git add stylesshengbinbin@chengbinbindeMacBook-Pro git_learning % git commit -m 'ADD style.css'[master 9bd6521] ADD style.css 1 file changed, 50 insertions(+) create mode 100644 styles/style.css 添加js： 123456789101112131415161718192021222324252627282930313233343536373839404142shengbinbin@chengbinbindeMacBook-Pro git_learning % cp -r ../0-material/js .shengbinbin@chengbinbindeMacBook-Pro git_learning % ls -altotal 16drwxr-xr-x 8 shengbinbin staff 256 6 22 22:04 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 12 shengbinbin staff 384 6 22 22:01 .gitdrwxr-xr-x@ 3 shengbinbin staff 96 6 22 21:57 images-rw-r--r--@ 1 shengbinbin staff 1303 6 22 21:57 index.htmldrwxr-xr-x@ 3 shengbinbin staff 96 6 22 22:04 js-rw-r--r--@ 1 shengbinbin staff 51 6 22 21:51 readmedrwxr-xr-x 3 shengbinbin staff 96 6 22 22:00 stylesshengbinbin@chengbinbindeMacBook-Pro git_learning % git add jsshengbinbin@chengbinbindeMacBook-Pro git_learning % git commit -m 'ADD js'[master 7a430c9] ADD js 1 file changed, 15 insertions(+) create mode 100644 js/script.jsshengbinbin@chengbinbindeMacBook-Pro git_learning % git log //查看git 提交日志commit 7a430c9c43daee3f83b4b3b607a8ef82e2061a46 (HEAD -&gt; master)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:06:20 2021 +0800 ADD jscommit 9bd65211b66a0a27503644f8fe66a66a428d4ecbAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:01:17 2021 +0800 ADD style.csscommit 2a76eaa0b2bbcda5419e741bd16fefa58afc9caaAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:57:59 2021 +0800 ADD index + logocommit d59544f7fba30a55f9511993709de2403c9cfbe5Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:52:44 2021 +0800 Add readMe: 文件重命名git mv123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263shengbinbin@chengbinbindeMacBook-Pro git_learning % ls -altotal 16drwxr-xr-x 8 shengbinbin staff 256 6 22 22:04 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 12 shengbinbin staff 384 6 22 22:06 .gitdrwxr-xr-x@ 3 shengbinbin staff 96 6 22 21:57 images-rw-r--r--@ 1 shengbinbin staff 1303 6 22 21:57 index.htmldrwxr-xr-x@ 3 shengbinbin staff 96 6 22 22:04 js-rw-r--r--@ 1 shengbinbin staff 51 6 22 21:51 readmedrwxr-xr-x 3 shengbinbin staff 96 6 22 22:00 stylesshengbinbin@chengbinbindeMacBook-Pro git_learning % mv readMe readMe.md //1.本地目录重命名shengbinbin@chengbinbindeMacBook-Pro git_learning % ls -altotal 16drwxr-xr-x 8 shengbinbin staff 256 6 22 22:13 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 12 shengbinbin staff 384 6 22 22:06 .gitdrwxr-xr-x@ 3 shengbinbin staff 96 6 22 21:57 images-rw-r--r--@ 1 shengbinbin staff 1303 6 22 21:57 index.htmldrwxr-xr-x@ 3 shengbinbin staff 96 6 22 22:04 js-rw-r--r--@ 1 shengbinbin staff 51 6 22 21:51 readMe.mddrwxr-xr-x 3 shengbinbin staff 96 6 22 22:00 stylesshengbinbin@chengbinbindeMacBook-Pro git_learning % git status //2. git 认为是删除了readMe 新建了readMe.mdOn branch masterChanges not staged for commit: (use &quot;git add/rm &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) deleted: readmeUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) readMe.mdno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)shengbinbin@chengbinbindeMacBook-Pro git_learning % git add readMe.md //3.将readMe.md 加到暂存区shengbinbin@chengbinbindeMacBook-Pro git_learning % git rm readme //4. 删除git上的readmerm 'readme'shengbinbin@chengbinbindeMacBook-Pro git_learning % git status //5. git就识别出来了On branch masterChanges to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) renamed: readme -&gt; readMe.mdshengbinbin@chengbinbindeMacBook-Pro git_learning % git reset --hard //6.清除本次提交，包括本地的修改HEAD is now at 7a430c9 ADD jsshengbinbin@chengbinbindeMacBook-Pro git_learning % git mv readme readme.md //7.在git上直接进行重命名shengbinbin@chengbinbindeMacBook-Pro git_learning % git statusOn branch masterChanges to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) renamed: readme -&gt; readme.md //8. 提交shengbinbin@chengbinbindeMacBook-Pro git_learning % git commit readme.md -m &quot;rename readme to readme.md&quot;[master aeb4213] rename readme to readme.md 1 file changed, 2 insertions(+) create mode 100644 readme.mdshengbinbin@chengbinbindeMacBook-Pro git_learning % 查看历史 git log123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104shengbinbin@chengbinbindeMacBook-Pro git_learning % git log --oneline //1. aeb4213 (HEAD -&gt; master) rename readme to readme.md7a430c9 ADD js9bd6521 ADD style.css2a76eaa ADD index + logod59544f Add readMeshengbinbin@chengbinbindeMacBook-Pro git_learning % git log -n2 --oneline // 看最近2次的提交历史aeb4213 (HEAD -&gt; master) rename readme to readme.md7a430c9 ADD jsshengbinbin@chengbinbindeMacBook-Pro git_learning % git branch -v //查看本地分支* master aeb4213 rename readme to readme.mdshengbinbin@chengbinbindeMacBook-Pro git_learning % git checkout -b temp 9bd6521 //创建一个新的分支D readmeSwitched to a new branch 'temp'shengbinbin@chengbinbindeMacBook-Pro git_learning % git branch -v master aeb4213 rename readme to readme.md* temp 9bd6521 ADD style.cssshengbinbin@chengbinbindeMacBook-Pro git_learning % ls -altotal 16drwxr-xr-x 7 shengbinbin staff 224 6 22 22:37 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 13 shengbinbin staff 416 6 22 22:37 .gitdrwxr-xr-x@ 3 shengbinbin staff 96 6 22 21:57 images-rw-r--r-- 1 shengbinbin staff 1303 6 22 22:36 index.html-rw-r--r-- 1 shengbinbin staff 51 6 22 22:37 readmedrwxr-xr-x 3 shengbinbin staff 96 6 22 22:00 stylesshengbinbin@chengbinbindeMacBook-Pro git_learning % vim readme // temp 分支修改了一下readmeshengbinbin@chengbinbindeMacBook-Pro git_learning % git commit -am'Add test' //直接提交（-am）[temp 2a5925a] Add test 1 file changed, 1 insertion(+)shengbinbin@chengbinbindeMacBook-Pro git_learning % git branch -av master aeb4213 rename readme to readme.md* temp 2a5925a Add testshengbinbin@chengbinbindeMacBook-Pro git_learning % git log //查看当前分支的提交记录commit 2a5925a9f096a881a838238a5ced6a5ff3b7f52a (HEAD -&gt; temp)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:38:52 2021 +0800 Add testcommit 9bd65211b66a0a27503644f8fe66a66a428d4ecbAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:01:17 2021 +0800 ADD style.csscommit 2a76eaa0b2bbcda5419e741bd16fefa58afc9caaAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:57:59 2021 +0800 ADD index + logocommit d59544f7fba30a55f9511993709de2403c9cfbe5Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:52:44 2021 +0800 Add readMe shengbinbin@chengbinbindeMacBook-Pro git_learning % git log --all --graph //查看全部分支的提交历史，图形化显示* commit 2a5925a9f096a881a838238a5ced6a5ff3b7f52a (HEAD -&gt; temp)| Author: shengbinbin &lt;1157024800@qq.com&gt;| Date: Tue Jun 22 22:38:52 2021 +0800|| Add test|| * commit aeb4213f9fe55e5ffa1a866df58a519c9dcc18e4 (master)| | Author: shengbinbin &lt;1157024800@qq.com&gt;| | Date: Tue Jun 22 22:23:50 2021 +0800| || | rename readme to readme.md| || * commit 7a430c9c43daee3f83b4b3b607a8ef82e2061a46|/ Author: shengbinbin &lt;1157024800@qq.com&gt;| Date: Tue Jun 22 22:06:20 2021 +0800|| ADD js|* commit 9bd65211b66a0a27503644f8fe66a66a428d4ecb| Author: shengbinbin &lt;1157024800@qq.com&gt;| Date: Tue Jun 22 22:01:17 2021 +0800|| ADD style.css|* commit 2a76eaa0b2bbcda5419e741bd16fefa58afc9caa| Author: shengbinbin &lt;1157024800@qq.com&gt;| Date: Tue Jun 22 21:57:59 2021 +0800|| ADD index + logo|* commit d59544f7fba30a55f9511993709de2403c9cfbe5 Author: shengbinbin &lt;1157024800@qq.com&gt; Date: Tue Jun 22 21:52:44 2021 +0800 Add readMe shengbinbin@chengbinbindeMacBook-Pro git_learning % git log --all --graph --oneline* 2a5925a (HEAD -&gt; temp) Add test| * aeb4213 (master) rename readme to readme.md| * 7a430c9 ADD js|/* 9bd6521 ADD style.css* 2a76eaa ADD index + logo* d59544f Add readMeshengbinbin@chengbinbindeMacBook-Pro git_learning % gitk可视化工具 探密.git裸仓库HEAD 和 config12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667shengbinbin@192 git_learning % ls -al //1.查看初始化的仓库中有什么total 16drwxr-xr-x 7 shengbinbin staff 224 6 22 22:38 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 14 shengbinbin staff 448 6 22 22:45 .git //核心文件夹drwxr-xr-x@ 3 shengbinbin staff 96 6 22 21:57 images-rw-r--r-- 1 shengbinbin staff 1303 6 22 22:36 index.html-rw-r--r-- 1 shengbinbin staff 57 6 22 22:38 readmedrwxr-xr-x 3 shengbinbin staff 96 6 22 22:00 stylesshengbinbin@192 git_learning % cd .gitshengbinbin@192 .git % ls -al //2. 进入核心文件夹 .git 查看内容total 56drwxr-xr-x 14 shengbinbin staff 448 6 22 22:45 .drwxr-xr-x 7 shengbinbin staff 224 6 22 22:38 ..-rw-r--r-- 1 shengbinbin staff 9 6 22 22:38 COMMIT_EDITMSG-rw-r--r-- 1 shengbinbin staff 21 6 22 22:34 HEAD-rw-r--r-- 1 shengbinbin staff 41 6 22 22:22 ORIG_HEAD-rw-r--r-- 1 shengbinbin staff 191 6 22 21:50 config-rw-r--r-- 1 shengbinbin staff 73 6 22 21:47 description-rw-r--r-- 1 shengbinbin staff 461 6 22 22:45 gitk.cachedrwxr-xr-x 15 shengbinbin staff 480 6 22 21:47 hooks-rw-r--r-- 1 shengbinbin staff 447 6 22 22:38 indexdrwxr-xr-x 3 shengbinbin staff 96 6 22 21:47 infodrwxr-xr-x 4 shengbinbin staff 128 6 22 21:52 logsdrwxr-xr-x 24 shengbinbin staff 768 6 22 22:38 objectsdrwxr-xr-x 4 shengbinbin staff 128 6 22 21:47 refsshengbinbin@192 .git % cat HEAD //3. 观察发现HEAD是一个引用，目前正指在 temp分支上ref: refs/heads/tempshengbinbin@192 .git % cd ..shengbinbin@192 git_learning % git checkout master //4. 切换分支Switched to branch 'master'shengbinbin@192 git_learning % cat .git/HEAD //5. 观察HEAD的引用也随之发生了变化ref: refs/heads/mastershengbinbin@192 git_learning % cat .git/config //6. 观察发现 config中存放的都是本地相关的配置[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true ignorecase = true precomposeunicode = true[user] name = shengbinbin email = 1157024800@qq.comshengbinbin@192 git_learning % vim .git/config //7. 直接修改这个配置文件中的usernameshengbinbin@192 git_learning % git config --local user.name //8.发现username确实发生了变化zhangkedanshengbinbin@192 git_learning % git config --local user.name 'shengbinbin' //9.还原user.nameshengbinbin@192 git_learning % git config --local user.nameshengbinbinshengbinbin@192 git_learning % cat .git/config[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true ignorecase = true precomposeunicode = true[user] name = shengbinbin email = 1157024800@qq.comshengbinbin@192 git_learning %shengbinbin@192 git_learning % ref123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172shengbinbin@192 git_learning % cd .gitshengbinbin@192 .git % ls -altotal 56drwxr-xr-x 14 shengbinbin staff 448 6 26 23:29 .drwxr-xr-x 9 shengbinbin staff 288 6 26 23:25 ..-rw-r--r-- 1 shengbinbin staff 9 6 22 22:38 COMMIT_EDITMSG-rw-r--r-- 1 shengbinbin staff 23 6 26 23:25 HEAD-rw-r--r-- 1 shengbinbin staff 41 6 22 22:22 ORIG_HEAD-rw-r--r-- 1 shengbinbin staff 191 6 26 23:29 config-rw-r--r-- 1 shengbinbin staff 73 6 22 21:47 description-rw-r--r-- 1 shengbinbin staff 461 6 22 22:45 gitk.cachedrwxr-xr-x 15 shengbinbin staff 480 6 22 21:47 hooks-rw-r--r-- 1 shengbinbin staff 626 6 26 23:25 indexdrwxr-xr-x 3 shengbinbin staff 96 6 22 21:47 infodrwxr-xr-x 4 shengbinbin staff 128 6 22 21:52 logsdrwxr-xr-x 24 shengbinbin staff 768 6 22 22:38 objectsdrwxr-xr-x 4 shengbinbin staff 128 6 22 21:47 refsshengbinbin@192 .git % cd refsshengbinbin@192 refs % ls -altotal 0drwxr-xr-x 4 shengbinbin staff 128 6 22 21:47 .drwxr-xr-x 14 shengbinbin staff 448 6 26 23:29 ..drwxr-xr-x 4 shengbinbin staff 128 6 22 22:38 heads //1. 存放的分支信息drwxr-xr-x 3 shengbinbin staff 96 6 22 22:53 tagsshengbinbin@192 refs % cd headsshengbinbin@192 heads % ls -altotal 16drwxr-xr-x 4 shengbinbin staff 128 6 22 22:38 .drwxr-xr-x 4 shengbinbin staff 128 6 22 21:47 ..-rw-r--r-- 1 shengbinbin staff 41 6 22 22:23 master-rw-r--r-- 1 shengbinbin staff 41 6 22 22:38 tempshengbinbin@192 heads % pwd/Users/shengbinbin/Documents/Code/git_learning/.git/refs/headsshengbinbin@192 heads % cat master //2. 查看master的内容（就是一个哈希码）aeb4213f9fe55e5ffa1a866df58a519c9dcc18e4shengbinbin@192 heads % git cat-file -t aeb4213f9 //3. 使用git的命令看一下这个哈希码代表了什么东西commitshengbinbin@192 heads % git branch -av* master aeb4213 rename readme to readme.md temp 2a5925a Add test shengbinbin@192 heads % cat temp2a5925a9f096a881a838238a5ced6a5ff3b7f52ashengbinbin@192 heads % cd ..shengbinbin@192 refs % ls tags //4. tags文件中存放的就是之前在gitk中加上的tag。（里程碑的概念）js01shengbinbin@192 refs % cd tagsshengbinbin@192 tags % ls -altotal 8drwxr-xr-x 3 shengbinbin staff 96 6 22 22:53 .drwxr-xr-x 4 shengbinbin staff 128 6 22 21:47 ..-rw-r--r-- 1 shengbinbin staff 41 6 22 22:53 js01shengbinbin@192 tags % cat js01 //5. tag本身有一个哈希码966bd62acdabd98c6aaf60f2cdd4f9517c810915shengbinbin@192 tags % git cat-file -t 966bd6tagshengbinbin@192 tags % git cat-file -p 966bd6 //6. 查看tag的内容，里面存放有一个object对象object 7a430c9c43daee3f83b4b3b607a8ef82e2061a46type committag js01tagger shengbinbin &lt;1157024800@qq.com&gt; 1624373582 +0800first jsshengbinbin@192 tags % git cat-file -t 7a430c9 //7.这个object对象其实就是一个提交commitshengbinbin@192 tags % object1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495shengbinbin@192 .git % cd objectsshengbinbin@192 objects % ls -altotal 0drwxr-xr-x 24 shengbinbin staff 768 6 22 22:38 .drwxr-xr-x 14 shengbinbin staff 448 6 26 23:29 ..drwxr-xr-x 3 shengbinbin staff 96 6 22 21:57 01drwxr-xr-x 4 shengbinbin staff 128 6 22 22:38 2adrwxr-xr-x 3 shengbinbin staff 96 6 22 21:52 31drwxr-xr-x 3 shengbinbin staff 96 6 22 21:52 4bdrwxr-xr-x 3 shengbinbin staff 96 6 22 21:57 6adrwxr-xr-x 3 shengbinbin staff 96 6 22 22:06 7adrwxr-xr-x 3 shengbinbin staff 96 6 22 21:52 7cdrwxr-xr-x 3 shengbinbin staff 96 6 22 22:06 87drwxr-xr-x 3 shengbinbin staff 96 6 22 22:01 91drwxr-xr-x 4 shengbinbin staff 128 6 22 22:53 96drwxr-xr-x 3 shengbinbin staff 96 6 22 22:23 99drwxr-xr-x 4 shengbinbin staff 128 6 22 22:38 9bdrwxr-xr-x 3 shengbinbin staff 96 6 22 22:06 abdrwxr-xr-x 4 shengbinbin staff 128 6 22 22:23 aedrwxr-xr-x 3 shengbinbin staff 96 6 22 22:06 b7drwxr-xr-x 3 shengbinbin staff 96 6 22 22:23 cddrwxr-xr-x 3 shengbinbin staff 96 6 22 21:52 d5drwxr-xr-x 3 shengbinbin staff 96 6 22 21:57 dadrwxr-xr-x 3 shengbinbin staff 96 6 22 22:01 efdrwxr-xr-x 3 shengbinbin staff 96 6 22 22:38 f8drwxr-xr-x 2 shengbinbin staff 64 6 22 21:47 infodrwxr-xr-x 2 shengbinbin staff 64 6 22 21:47 packshengbinbin@192 objects % cd ae //1. 先随便进入一个文件夹查看里面有什么shengbinbin@192 ae % ls -altotal 16drwxr-xr-x 4 shengbinbin staff 128 6 22 22:23 .drwxr-xr-x 24 shengbinbin staff 768 6 22 22:38 ..-r--r--r-- 1 shengbinbin staff 164 6 22 22:23 b4213f9fe55e5ffa1a866df58a519c9dcc18e4-r--r--r-- 1 shengbinbin staff 53 6 22 22:01 e37060401d19e7bd9f80b7b33920a000e96b5bshengbinbin@192 ae % git cat-file -t aeb4213f9fe55e5ffa1a866df58a519c9dcc18e4 //2.将ae和后面的哈希码拼接之后发现类型commitshengbinbin@192 ae % git cat-file -t aee37060401treeshengbinbin@192 ae % git cat-file -p aee37060401 //3. 查看这个tree里面有什么内容。发现有个blob100644 blob ef3f137d8af338a8604544a3e482090684321d93 style.cssshengbinbin@192 ae % git cat-file -p ef3f137d8 //4. 查看这个blob，发现就是之前加入的cssbody{ background-color: orange; font-family: 'Monaco', sans-serif; color: white;}body a{ color: white;}header{ text-align: center; margin-top: 50px;}h3{ color: red;}header-img{ width: 400px;}header-words{ line-height: 10px; font-size: 50px; font-family: 'Monaco', sans-serif; margin-bottom: 75px;}section{ padding: 0 50px 0px 50px; text-align: left;}div.accordion { cursor: pointer; border: none; outline: none;}div.accordion.active, div.accordion:hover { background-color: white; color: #1D2031;}div.panel { padding: 0 18px 0 0; display: none;} 在git中，只要文件内容相同，就被视为是同一个blog！！！ commit/tree/blob三个对象的关系一个commit就代表了一棵树 blob指的就是某个具体的文件 分离头指针状态指的是commit提交的时候没有基于某个分支来做，HEAD并未指向任何分支，可能会被git清理掉。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111shengbinbin@192 git_learning % git logcommit aeb4213f9fe55e5ffa1a866df58a519c9dcc18e4 (HEAD -&gt; master) //1. 一开始的HEAD指向master分支Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:23:50 2021 +0800 rename readme to readme.mdcommit 7a430c9c43daee3f83b4b3b607a8ef82e2061a46 (tag: js01)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:06:20 2021 +0800 ADD jscommit 9bd65211b66a0a27503644f8fe66a66a428d4ecbAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:01:17 2021 +0800 ADD style.csscommit 2a76eaa0b2bbcda5419e741bd16fefa58afc9caabody{Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:57:59 2021 +0800 ADD index + logocommit d59544f7fba30a55f9511993709de2403c9cfbe5Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:52:44 2021 +0800 Add readMeshengbinbin@192 git_learning % git checkout 9bd6521 //2. 切换分支，切换到某次commit上的时候，Note: switching to '9bd6521'. //3. 提示当前处于分离头指针的情况You are in 'detached HEAD' state. You can look around, make experimentalchanges and commit them, and you can discard any commits you make in thisstate without impacting any branches by switching back to a branch.If you want to create a new branch to retain commits you create, you maydo so (now or later) by using -c with the switch command. Example: git switch -c &lt;new-branch-name&gt;Or undo this operation with: git switch -Turn off this advice by setting config variable advice.detachedHead to falseHEAD is now at 9bd6521 ADD style.cssshengbinbin@192 git_learning % ls -altotal 16drwxr-xr-x 7 shengbinbin staff 224 6 27 16:02 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 14 shengbinbin staff 448 6 27 16:02 .gitdrwxr-xr-x@ 3 shengbinbin staff 96 6 22 21:57 images-rw-r--r-- 1 shengbinbin staff 1303 6 22 22:36 index.html-rw-r--r-- 1 shengbinbin staff 51 6 26 23:25 readmedrwxr-xr-x 3 shengbinbin staff 96 6 22 22:00 stylesshengbinbin@192 git_learning % vim styles/style.css //4. 在分离头指针的情况下进行修改shengbinbin@192 git_learning % git status HEAD detached at 9bd6521Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) modified: styles/style.cssno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)shengbinbin@192 git_learning % git commit -am'Background to green'[detached HEAD fcad9c2] Background to green 1 file changed, 1 insertion(+), 1 deletion(-)shengbinbin@192 git_learning % git logcommit fcad9c2c62b980debc083ff34ef0496512ab2756 (HEAD)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Sun Jun 27 16:03:31 2021 +0800 Background to greencommit 9bd65211b66a0a27503644f8fe66a66a428d4ecbAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:01:17 2021 +0800 ADD style.csscommit 2a76eaa0b2bbcda5419e741bd16fefa58afc9caaAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:57:59 2021 +0800 ADD index + logocommit d59544f7fba30a55f9511993709de2403c9cfbe5Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:52:44 2021 +0800 Add readMe shengbinbin@192 git_learning % git checkout master // 5. 切换分支的时候提示你是否对当前提交进行保存Warning: you are leaving 1 commit behind, not connected toany of your branches: fcad9c2 Background to greenIf you want to keep it by creating a new branch, this may be a good timeto do so with: git branch &lt;new-branch-name&gt; fcad9c2Switched to branch 'master'shengbinbin@192 git_learning % git branch fix_css fcad9c2 //6. 将当前分支修改的内容用分支 fix_css来保存下来shengbinbin@192 git_learning % git的基本操作比较两次提交的差异123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//比较两次提交的差异 git diff + 两个 commitIdshengbinbin@192 git_learning % git checkout -b fix_readme fix_cssSwitched to a new branch 'fix_readme'shengbinbin@192 git_learning % git log -n1commit fcad9c2c62b980debc083ff34ef0496512ab2756 (HEAD -&gt; fix_readme, fix_css)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Sun Jun 27 16:03:31 2021 +0800 Background to greenshengbinbin@192 git_learning % gitk --allshengbinbin@192 git_learning % cat .git/HEADref: refs/heads/fix_readmeshengbinbin@192 git_learning % cat .git/refs/heads/fix_readmefcad9c2c62b980debc083ff34ef0496512ab2756shengbinbin@192 git_learning % git cat-file -t fcad9c2commitshengbinbin@192 git_learning % git logcommit fcad9c2c62b980debc083ff34ef0496512ab2756 (HEAD -&gt; fix_readme, fix_css)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Sun Jun 27 16:03:31 2021 +0800 Background to greencommit 9bd65211b66a0a27503644f8fe66a66a428d4ecbAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:01:17 2021 +0800 ADD style.csscommit 2a76eaa0b2bbcda5419e741bd16fefa58afc9caaAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:57:59 2021 +0800 ADD index + logocommit d59544f7fba30a55f9511993709de2403c9cfbe5Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:52:44 2021 +0800 Add readMe shengbinbin@192 git_learning % git diff fcad9c2 9bd6521 //比较两次提交的差异diff --git a/styles/style.css b/styles/style.cssindex 4c6bc45..ef3f137 100644--- a/styles/style.css+++ b/styles/style.css@@ -1,5 +1,5 @@ body{- background-color: green;+ background-color: orange; font-family: 'Monaco', sans-serif; color: white; }shengbinbin@192 git_learning % 删除不需要的分支 123456789101112shengbinbin@192 git_learning % git branch -av fix_css fcad9c2 Background to green* fix_readme fcad9c2 Background to green master aeb4213 rename readme to readme.md temp 2a5925a Add testshengbinbin@192 git_learning % gitk --allshengbinbin@192 git_learning % git branch -d fix_css // 删除 fix_css这个分支Deleted branch fix_css (was fcad9c2).shengbinbin@192 git_learning % gitk --allshengbinbin@192 git_learning % 修改commit的message修改上一次提交的commit，使用 git commit –amend 1234567891011121314151617181920shengbinbin@192 git_learning % git log -n1commit aeb4213f9fe55e5ffa1a866df58a519c9dcc18e4 (HEAD -&gt; master)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:23:50 2021 +0800 rename readme to readme.mdshengbinbin@192 git_learning % git commit --amend 'Move filename readme to readme.md'error: pathspec 'Move filename readme to readme.md' did not match any file(s) known to gitshengbinbin@192 git_learning % git commit --amend[master 76459c3] Mobe filename readme to readme.md Date: Tue Jun 22 22:23:50 2021 +0800 1 file changed, 2 insertions(+) create mode 100644 readme.mdshengbinbin@192 git_learning % git log -n1commit 76459c3e75e7a91af40e3fcd340e4c488f4ed589 (HEAD -&gt; master)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:23:50 2021 +0800 Mobe filename readme to readme.mdshengbinbin@192 git_learning % 修改之前的commit信息，不是上一个的：git rebase -i 变基式操作 1234567891011121314151617181920212223242526272829303132333435363738394041424344shengbinbin@192 git_learning % git log -3commit 76459c3e75e7a91af40e3fcd340e4c488f4ed589 (HEAD -&gt; master)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:23:50 2021 +0800 Mobe filename readme to readme.mdcommit 7a430c9c43daee3f83b4b3b607a8ef82e2061a46 (tag: js01)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:06:20 2021 +0800 ADD jscommit 9bd65211b66a0a27503644f8fe66a66a428d4ecbAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:01:17 2021 +0800 ADD style.cssshengbinbin@192 git_learning % git rebase -i 9bd65211[detached HEAD 95a2ce3] ADD a js Date: Tue Jun 22 22:06:20 2021 +0800 1 file changed, 15 insertions(+) create mode 100644 js/script.jsSuccessfully rebased and updated refs/heads/master.shengbinbin@192 git_learning % git log -n3commit f8367296bd1af13c79e6e23f1ade3cef425bb26a (HEAD -&gt; master)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:23:50 2021 +0800 Mobe filename readme to readme.mdcommit 95a2ce35bfe6ea75912d0ab6ee6ad793e090657bAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:06:20 2021 +0800 ADD a jscommit 9bd65211b66a0a27503644f8fe66a66a428d4ecbAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:01:17 2021 +0800 ADD style.css 1234567891011121314151617181920212223242526pick 7a430c9 ADD js //将pick改成reword，保存退出pick 76459c3 Mobe filename readme to readme.md# Rebase 9bd6521..76459c3 onto 9bd6521 (2 commands)## Commands:# p, pick &lt;commit&gt; = use commit# r, reword &lt;commit&gt; = use commit, but edit the commit message# e, edit &lt;commit&gt; = use commit, but stop for amending# s, squash &lt;commit&gt; = use commit, but meld into previous commit# f, fixup &lt;commit&gt; = like &quot;squash&quot;, but discard this commit's log message# x, exec &lt;command&gt; = run command (the rest of the line) using shell# b, break = stop here (continue rebase later with 'git rebase --continue')# d, drop &lt;commit&gt; = remove commit# l, label &lt;label&gt; = label current HEAD with a name# t, reset &lt;label&gt; = reset HEAD to a label# m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;]# . create a merge commit using the original merge commit's# . message (or the oneline, if no original merge commit was# . specified). Use -c &lt;commit&gt; to reword the commit message.## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted. 1234567891011121314151617ADD a js //此时修改message# Please enter the commit message for your changes. Lines starting# with '#' will be ignored, and an empty message aborts the commit.## Date: Tue Jun 22 22:06:20 2021 +0800## interactive rebase in progress; onto 9bd6521# Last command done (1 command done):# reword 7a430c9 ADD js# Next command to do (1 remaining command):# pick 76459c3 Mobe filename readme to readme.md# You are currently editing a commit while rebasing branch 'master' on '9bd6521'.## Changes to be committed:# new file: js/script.js# 将连续的commit整理成一个12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364shengbinbin@192 git_learning % git log // 查看历史commit f8367296bd1af13c79e6e23f1ade3cef425bb26a (HEAD -&gt; master)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:23:50 2021 +0800 Mobe filename readme to readme.mdcommit 95a2ce35bfe6ea75912d0ab6ee6ad793e090657bAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:06:20 2021 +0800 ADD a jscommit 9bd65211b66a0a27503644f8fe66a66a428d4ecbAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:01:17 2021 +0800 ADD style.csscommit 2a76eaa0b2bbcda5419e741bd16fefa58afc9caaAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:57:59 2021 +0800 ADD index + logocommit d59544f7fba30a55f9511993709de2403c9cfbe5Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:52:44 2021 +0800 Add readMeshengbinbin@192 git_learning % git rebase -i d59544f7 //将这个commit 后面的三个commit合并成一个[detached HEAD 88f9280] create a complete web page ADD index + logo ADD style.css ADD a js Date: Tue Jun 22 21:57:59 2021 +0800 4 files changed, 114 insertions(+) create mode 100644 images/git-logo.png create mode 100644 index.html create mode 100644 js/script.js create mode 100644 styles/style.cssSuccessfully rebased and updated refs/heads/master.shengbinbin@192 git_learning % git log //合并完之后再看一下logcommit ea5ccd12fd5b46a7536a92fec3cf6619dbe993f3 (HEAD -&gt; master)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:23:50 2021 +0800 Mobe filename readme to readme.mdcommit 88f92801204a631a4eb1239a997b5457bc4f8c34Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:57:59 2021 +0800 create a complete web page ADD index + logo ADD style.css ADD a jscommit d59544f7fba30a55f9511993709de2403c9cfbe5Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:52:44 2021 +0800 Add readMeshengbinbin@192 git_learning % 1234567891011121314151617181920212223242526272829pick 2a76eaa ADD index + logopick 9bd6521 ADD style.css //将pick改成 spick 95a2ce3 ADD a js //将pick改成spick f836729 Mobe filename readme to readme.md# Rebase d59544f..f836729 onto d59544f (4 commands)## Commands:# p, pick &lt;commit&gt; = use commit# r, reword &lt;commit&gt; = use commit, but edit the commit message# e, edit &lt;commit&gt; = use commit, but stop for amending# s, squash &lt;commit&gt; = use commit, but meld into previous commit# f, fixup &lt;commit&gt; = like &quot;squash&quot;, but discard this commit's log message# x, exec &lt;command&gt; = run command (the rest of the line) using shell# b, break = stop here (continue rebase later with 'git rebase --continue')# d, drop &lt;commit&gt; = remove commit# l, label &lt;label&gt; = label current HEAD with a name# t, reset &lt;label&gt; = reset HEAD to a label# m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;]# . create a merge commit using the original merge commit's# . message (or the oneline, if no original merge commit was# . specified). Use -c &lt;commit&gt; to reword the commit message.## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.# 1234567891011121314151617181920212223242526272829303132# This is a combination of 3 commits.# This is the 1st commit message:create a complete web page //新加一个commit信息ADD index + logo# This is the commit message #2:ADD style.css# This is the commit message #3:ADD a js# Please enter the commit message for your changes. Lines starting# with '#' will be ignored, and an empty message aborts the commit.## Date: Tue Jun 22 21:57:59 2021 +0800## interactive rebase in progress; onto d59544f# Last commands done (3 commands done):# squash 9bd6521 ADD style.css# squash 95a2ce3 ADD a js# Next command to do (1 remaining command):# pick f836729 Mobe filename readme to readme.md# You are currently rebasing branch 'master' on 'd59544f'.## Changes to be committed:# new file: images/git-logo.png# new file: index.html# new file: js/script.js# new file: styles/style.css# 将间隔的commit整理成一个123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172shengbinbin@192 git_learning % git logcommit ea5ccd12fd5b46a7536a92fec3cf6619dbe993f3 (HEAD -&gt; master)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:23:50 2021 +0800# This is a combination of 2 commits. Mobe filename readme to readme.md // 1 commit 88f92801204a631a4eb1239a997b5457bc4f8c34Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:57:59 2021 +0800 create a complete web page ADD index + logo ADD style.css ADD a jscommit d59544f7fba30a55f9511993709de2403c9cfbe5Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:52:44 2021 +0800 Add readMe //2 ,将这个和上面的1合并在一起 shengbinbin@192 git_learning % git rebase -i d59544fSuccessfully rebased and updated refs/heads/master.shengbinbin@192 git_learning % git rebase -i d59544fThe previous cherry-pick is now empty, possibly due to conflict resolution.If you wish to commit it anyway, use: git commit --allow-emptyOtherwise, please use 'git rebase --skip'interactive rebase in progress; onto d59544fLast command done (1 command done): pick d59544fNext commands to do (2 remaining commands): squash ea5ccd1 Mobe filename readme to readme.md pick 88f9280 create a complete web page ADD index + logo ADD style.css ADD a js (use &quot;git rebase --edit-todo&quot; to view and edit)You are currently rebasing branch 'master' on 'd59544f'. (all conflicts fixed: run &quot;git rebase --continue&quot;)nothing to commit, working tree cleanCould not apply d59544f...shengbinbin@192 git_learning % git rebase --continue[detached HEAD 0a8f323] Add a new readme Date: Tue Jun 22 21:52:44 2021 +0800 2 files changed, 4 insertions(+) create mode 100644 readme create mode 100644 readme.mdSuccessfully rebased and updated refs/heads/master.shengbinbin@192 git_learning % git logcommit 01b4b51917535a1b2cdafef8fc275ab17e8b4a1d (HEAD -&gt; master)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:57:59 2021 +0800 create a complete web page ADD index + logo ADD style.css ADD a jscommit 0a8f323893329d23eb7bc2e68049391ee3957e53Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:52:44 2021 +0800 Add a new readme Add readMe Mobe filename readme to readme.md 1234567891011121314151617181920212223242526272829pick d59544fs ea5ccd1 Mobe filename readme to readme.md //改成spick 88f9280 create a complete web page ADD index + logo ADD style.css ADD a js# Rebase d59544f..ea5ccd1 onto d59544f (2 commands)## Commands:# p, pick &lt;commit&gt; = use commit# r, reword &lt;commit&gt; = use commit, but edit the commit message# e, edit &lt;commit&gt; = use commit, but stop for amending# s, squash &lt;commit&gt; = use commit, but meld into previous commit# f, fixup &lt;commit&gt; = like &quot;squash&quot;, but discard this commit's log message# x, exec &lt;command&gt; = run command (the rest of the line) using shell# b, break = stop here (continue rebase later with 'git rebase --continue')# d, drop &lt;commit&gt; = remove commit# l, label &lt;label&gt; = label current HEAD with a name# t, reset &lt;label&gt; = reset HEAD to a label# m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;]# . create a merge commit using the original merge commit's# . message (or the oneline, if no original merge commit was# . specified). Use -c &lt;commit&gt; to reword the commit message.## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.# 123456789101112131415161718192021222324252627282930# This is a combination of 2 commits.Add a new readme# This is the 1st commit message:Add readMe# This is the commit message #2:Mobe filename readme to readme.md# Please enter the commit message for your changes. Lines starting# with '#' will be ignored, and an empty message aborts the commit.## Date: Tue Jun 22 21:52:44 2021 +0800## interactive rebase in progress; onto d59544f# Last commands done (2 commands done):# pick d59544f# squash ea5ccd1 Mobe filename readme to readme.md# Next command to do (1 remaining command):# pick 88f9280 create a complete web page ADD index + logo ADD style.css ADD a js# You are currently rebasing branch 'master' on 'd59544f'.### Initial commit## Changes to be committed:# new file: readme# new file: readme.md# 暂存区和HEAD做比较head 为已经提交过后的状态 12345678910111213141516171819202122232425shengbinbin@192 git_learning % git statusOn branch masternothing to commit, working tree cleanshengbinbin@192 git_learning % vi index.html shengbinbin@192 git_learning % git add index.html shengbinbin@192 git_learning % git diff --cached //比较暂存区和Head最新的提交的差异diff --git a/index.html b/index.htmlindex 6ad4c68..0f0ee94 100644--- a/index.html+++ b/index.html@@ -14,7 +14,7 @@ &lt;div class=&quot;accordion&quot;&gt;&lt;h1&gt;Terminologys&lt;/h1&gt;&lt;/div&gt; &lt;div class=&quot;panel&quot;&gt; &lt;ol&gt;- &lt;li&gt;&lt;/li&gt;+ &lt;li&gt;add&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; shengbinbin@192 git_learning % git commit -m'Add the first git command with config'[master 6cff2f6] Add the first git command with config 1 file changed, 1 insertion(+), 1 deletion(-) 暂存区和工作区文件的比较123456789101112131415161718192021222324body{shengbinbin@192 git_learning % git branch fix_readme* master tempshengbinbin@192 git_learning % vim index.htmlshengbinbin@192 git_learning % git add index.html //加入到暂存区shengbinbin@192 git_learning % vim styles/style.cssshengbinbin@192 git_learning % git diff //默认比较的就是工作区和暂存区diff --git a/styles/style.css b/styles/style.cssindex ef3f137..f2a08e0 100644--- a/styles/style.css+++ b/styles/style.css@@ -1,7 +1,7 @@ body{ background-color: orange; font-family: 'Monaco', sans-serif;- color: white;+ color: black; } body a{shengbinbin@192 git_learning % 将暂存区恢复成HEAD一样123456789101112131415161718192021222324252627282930313233343536shengbinbin@192 git_learning % git statusOn branch masterChanges to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) modified: index.htmlChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) modified: styles/style.cssshengbinbin@192 git_learning % git add styles/style.cssshengbinbin@192 git_learning % git statusOn branch masterChanges to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) modified: index.html modified: styles/style.cssshengbinbin@192 git_learning % git reset HEAD //恢复暂存区Unstaged changes after reset:M index.htmlM styles/style.cssshengbinbin@192 git_learning % git statusOn branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) modified: index.html modified: styles/style.cssno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)shengbinbin@192 git_learning % git diff --cachedshengbinbin@192 git_learning % 将工作区恢复成暂存区12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849shengbinbin@192 git_learning % git statusOn branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) modified: index.html modified: styles/style.cssno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)shengbinbin@192 git_learning % git add index.htmlshengbinbin@192 git_learning % git diff --cacheddiff --git a/index.html b/index.htmlindex 0f0ee94..5ec8fa6 100644--- a/index.html+++ b/index.html@@ -15,7 +15,7 @@ &lt;div class=&quot;panel&quot;&gt; &lt;ol&gt; &lt;li&gt;add&lt;/li&gt;- &lt;li&gt;&lt;/li&gt;+ &lt;li&gt;bare repo&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt;shengbinbin@192 git_learning % vim index.htmlshengbinbin@192 git_learning % git statusOn branch masterChanges to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) modified: index.htmlChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) modified: index.html modified: styles/style.cssshengbinbin@192 git_learning % git restore index.htmlshengbinbin@192 git_learning % git statusOn branch masterChanges to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) modified: index.htmlChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) modified: styles/style.css 回退到之前的commit状态12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758shengbinbin@192 git_learning % git branch -av fix_readme fcad9c2 Background to green* master 6cff2f6 Add the first git command with config temp 2a5925a Add testshengbinbin@192 git_learning % git checkout tempSwitched to branch 'temp'shengbinbin@192 git_learning % git logcommit 2a5925a9f096a881a838238a5ced6a5ff3b7f52a (HEAD -&gt; temp)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:38:52 2021 +0800 Add testcommit 9bd65211b66a0a27503644f8fe66a66a428d4ecbAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:01:17 2021 +0800 ADD style.csscommit 2a76eaa0b2bbcda5419e741bd16fefa58afc9caaAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:57:59 2021 +0800 ADD index + logocommit d59544f7fba30a55f9511993709de2403c9cfbe5Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:52:44 2021 +0800 Add readMeshengbinbin@192 git_learning % gitk --allshengbinbin@192 git_learning % git reset --hard 9bd65211 //回退到指定的commitHEAD is now at 9bd6521 ADD style.cssshengbinbin@192 git_learning % gitk --allshengbinbin@192 git_learning % git logcommit 9bd65211b66a0a27503644f8fe66a66a428d4ecb (HEAD -&gt; temp)Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 22:01:17 2021 +0800 ADD style.csscommit 2a76eaa0b2bbcda5419e741bd16fefa58afc9caaAuthor: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:57:59 2021 +0800 ADD index + logocommit d59544f7fba30a55f9511993709de2403c9cfbe5Author: shengbinbin &lt;1157024800@qq.com&gt;Date: Tue Jun 22 21:52:44 2021 +0800 Add readMeshengbinbin@192 git_learning % 查看不同commit的指定文件的差异1234567891011121314151617181920shengbinbin@192 git_learning % git branch -av fix_readme fcad9c2 Background to green master 6cff2f6 Add the first git command with config* temp 9bd6521 ADD style.cssshengbinbin@192 git_learning % git diff 9bd6521 6cff2f6 -- index.html //查看不同提交指定文件的差异diff --git a/index.html b/index.htmlindex 6ad4c68..0f0ee94 100644--- a/index.html+++ b/index.html@@ -14,7 +14,7 @@ &lt;div class=&quot;accordion&quot;&gt;&lt;h1&gt;Terminologys&lt;/h1&gt;&lt;/div&gt; &lt;div class=&quot;panel&quot;&gt; &lt;ol&gt;- &lt;li&gt;&lt;/li&gt;+ &lt;li&gt;add&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt;shengbinbin@192 git_learning % 删除文件123456789101112131415161718192021222324252627282930shengbinbin@192 git_learning % ls -altotal 16drwxr-xr-x 7 shengbinbin staff 224 6 28 09:49 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 14 shengbinbin staff 448 6 28 09:49 .gitdrwxr-xr-x 3 shengbinbin staff 96 6 27 21:59 images-rw-r--r-- 1 shengbinbin staff 1303 6 28 09:47 index.html-rw-r--r-- 1 shengbinbin staff 51 6 28 09:49 readmedrwxr-xr-x 3 shengbinbin staff 96 6 28 09:46 stylesshengbinbin@192 git_learning % git branch fix_readme master* tempshengbinbin@192 git_learning % git rm readme //git 删除指定文件rm 'readme'shengbinbin@192 git_learning % git statusOn branch tempChanges to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) deleted: readmeshengbinbin@192 git_learning % ls -altotal 8drwxr-xr-x 6 shengbinbin staff 192 6 28 09:54 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 14 shengbinbin staff 448 6 28 09:54 .gitdrwxr-xr-x 3 shengbinbin staff 96 6 27 21:59 images-rw-r--r-- 1 shengbinbin staff 1303 6 28 09:47 index.htmldrwxr-xr-x 3 shengbinbin staff 96 6 28 09:46 stylesshengbinbin@192 git_learning % 指定不需要git管理的文件12345678910111213141516171819202122232425262728293031shengbinbin@192 git_learning % echo 'I am a file' &gt;docshengbinbin@192 git_learning % ls -altotal 32drwxr-xr-x 9 shengbinbin staff 288 6 28 10:03 .drwxr-xr-x@ 7 shengbinbin staff 224 6 22 21:47 ..drwxr-xr-x 14 shengbinbin staff 448 6 28 10:02 .git-rw-r--r-- 1 shengbinbin staff 5 6 28 10:02 .gitignore-rw-r--r-- 1 shengbinbin staff 12 6 28 10:03 docdrwxr-xr-x 3 shengbinbin staff 96 6 27 21:59 images-rw-r--r-- 1 shengbinbin staff 1303 6 28 09:47 index.html-rw-r--r-- 1 shengbinbin staff 51 6 28 09:56 readmedrwxr-xr-x 3 shengbinbin staff 96 6 28 09:46 stylesshengbinbin@192 git_learning % cat .gitignoredoc/shengbinbin@192 git_learning % git statusOn branch tempUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) .gitignore docnothing added to commit but untracked files present (use &quot;git add&quot; to track)shengbinbin@192 git_learning % vi .gitignoreshengbinbin@192 git_learning % git statusOn branch tempUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) .gitignorenothing added to commit but untracked files present (use &quot;git add&quot; to track)shengbinbin@192 git_learning % Git的备份常用的传输协议： 哑协议和智能协议的区别： 直观区别：哑协议传输进度不可见，而智能协议传输是可见的。 传输速度：智能协议比哑协议传输速度更快 123456789101112131415161718192021222324shengbinbin@192 git_learning % pwd/Users/shengbinbin/Documents/Code/git_learningshengbinbin@192 git_learning % cd ..shengbinbin@192 Code % mkdir backupshengbinbin@192 Code % cd backupshengbinbin@192 backup % pwd/Users/shengbinbin/Documents/Code/backupshengbinbin@192 backup % cd ..shengbinbin@192 Code % pwd/Users/shengbinbin/Documents/Codeshengbinbin@192 Code % git clone --bare /Users/shengbinbin/Documents/Code/git_learning/.git ya.gitCloning into bare repository 'ya.git'...done.shengbinbin@192 Code % git clone --bare file:///Users/shengbinbin/Documents/Code/git_learning/.git zhineng.gitCloning into bare repository 'zhineng.git'...remote: Enumerating objects: 28, done.remote: Counting objects: 100% (28/28), done.remote: Compressing objects: 100% (23/23), done.remote: Total 28 (delta 8), reused 0 (delta 0), pack-reused 0Receiving objects: 100% (28/28), 22.06 KiB | 22.06 MiB/s, done.Resolving deltas: 100% (8/8), done.shengbinbin@192 Code % 123456789shengbinbin@192 git_learning % git remote -vshengbinbin@192 git_learning % git remote add zhineng file:///Users/shengbinbin/Documents/Code/backup/zhineng.gitshengbinbin@192 git_learning % git branch -av fix_readme fcad9c2 Background to green master 6cff2f6 Add the first git command with config* temp 9bd6521 ADD style.css//可以将当前文件夹的内容备份到本地的另外一个文件夹 GitHub的交互过程配置SSH的公私钥https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account 检查一下是否已经存在了SSH密钥：https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh/checking-for-existing-ssh-keys 1234567891011shengbinbin@chengbinbindeMacBook-Pro ~ % cd ~/.sshshengbinbin@chengbinbindeMacBook-Pro .ssh % ls -altotal 24drwx------ 5 shengbinbin staff 160 5 6 15:26 .drwxr-xr-x+ 35 shengbinbin staff 1120 6 22 10:25 ..-rw------- 1 shengbinbin staff 2602 5 6 15:22 id_rsa-rw-r--r--@ 1 shengbinbin staff 571 5 6 15:22 id_rsa.pub //已经有了-rw-r--r-- 1 shengbinbin staff 1197 5 6 16:51 known_hostsshengbinbin@chengbinbindeMacBook-Pro .ssh % cat id_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDjEseQlMpM7ANSuie198dnHoopBWLaNEuIkBSwSA1NeDHY1a0gKXp8TZkujdLPUIJDcd7AOXPTZ4AmhMmHN7eC5XNR2MuXMZxbzWgdd/nTuwbeve8DmvQbgBQ4Jn6mqDdmnJO62r4XlO1CvScyQ5i+HW5LcLBXtdzUjMpaUb5mnzqIqg7QAR6m3j2oYyMzf4ccfoMEu1XbdTAV2opeRdOadUwpN3STq5X5JM5ECbcXfitMrVz1FnNNvH+UEmKqA/I4Ea4vB7npeaaECb4krMfo4InozLIdD0reZSyvHG1AP2/OdHD6Aw4/3XA8XTKv9JWwV8Xhce3B3VFjL2ajDwl0CJVFuQ6GZd778T4/hlPSSOmmQJOilsvOEqRq4EoojJyBx3TvU/GwlkwpRgbeQvKHwiV095VDAV8DKB2qMFmgQ1cvOTLRyTPgvuO6CkkZjR0UD9OQ3+uWSz3B8TA9ULALsbYsWP9LaACSkI2PyGwfLWuyCQ14ckir84sub/Bzw4s= 1157024800@qq.comshengbinbin@chengbinbindeMacBook-Pro .ssh % 将公钥粘到github上去。 创建个人仓库 将本地仓库同步到GitHub123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960shengbinbin@192 git_learning % git remote -v //查看远程分支信息 ,现在是有2个本地的备份zhineng file:///Users/shengbinbin/Documents/Code/backup/zhineng.git (fetch)zhineng file:///Users/shengbinbin/Documents/Code/backup/zhineng.git (push) ////新增远程的github仓库地址，命名为githubshengbinbin@192 git_learning % git remote add github git@github.com:binshow/git_learning.gitshengbinbin@192 git_learning % git remote -vgithub git@github.com:binshow/git_learning.git (fetch)github git@github.com:binshow/git_learning.git (push)zhineng file:///Users/shengbinbin/Documents/Code/backup/zhineng.git (fetch)zhineng file:///Users/shengbinbin/Documents/Code/backup/zhineng.git (push)shengbinbin@192 git_learning % git push github --all //将本地的所以分支push到github上Enumerating objects: 25, done.Counting objects: 100% (25/25), done.Delta compression using up to 8 threadsCompressing objects: 100% (20/20), done.Writing objects: 100% (25/25), 21.83 KiB | 7.28 MiB/s, done.Total 25 (delta 6), reused 0 (delta 0), pack-reused 0remote: Resolving deltas: 100% (6/6), done.remote:remote: Create a pull request for 'fix_readme' on GitHub by visiting:remote: https://github.com/binshow/git_learning/pull/new/fix_readmeremote:To github.com:binshow/git_learning.git * [new branch] fix_readme -&gt; fix_readme ! [rejected] master -&gt; master (fetch first) ! [rejected] temp -&gt; temp (fetch first)error: failed to push some refs to 'github.com:binshow/git_learning.git'hint: Updates were rejected because the remote contains work that you dohint: not have locally. This is usually caused by another repository pushinghint: to the same ref. You may want to first integrate the remote changeshint: (e.g., 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details.shengbinbin@192 git_learning % git pull github masterhint: Pulling without specifying how to reconcile divergent branches ishint: discouraged. You can squelch this message by running one of the followinghint: commands sometime before your next pull:hint:hint: git config pull.rebase false # merge (the default strategy)hint: git config pull.rebase true # rebasehint: git config pull.ff only # fast-forward onlyhint:hint: You can replace &quot;git config&quot; with &quot;git config --global&quot; to set a defaulthint: preference for all repositories. You can also pass --rebase, --no-rebase,hint: or --ff-only on the command line to override the configured default perhint: invocation.remote: Enumerating objects: 13, done.remote: Counting objects: 100% (13/13), done.remote: Compressing objects: 100% (8/8), done.remote: Total 13 (delta 2), reused 13 (delta 2), pack-reused 0Unpacking objects: 100% (13/13), 20.76 KiB | 2.59 MiB/s, done.From github.com:binshow/git_learning * branch master -&gt; FETCH_HEAD * [new branch] master -&gt; github/masterfatal: refusing to merge unrelated historiesshengbinbin@192 git_learning % 协同开发的常见操作不同人修改了不同文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106shengbinbin@chengbinbindeMacBook-Pro git_learn % git clone git@github.com:binshow/git_learning.gitCloning into 'git_learning'...remote: Enumerating objects: 20, done.remote: Counting objects: 100% (20/20), done.remote: Compressing objects: 100% (12/12), done.remote: Total 20 (delta 3), reused 14 (delta 3), pack-reused 0Receiving objects: 100% (20/20), 22.62 KiB | 279.00 KiB/s, done.Resolving deltas: 100% (3/3), done.shengbinbin@chengbinbindeMacBook-Pro git_learn % ls -altotal 16drwxr-xr-x 8 shengbinbin staff 256 6 22 14:45 .drwx------@ 29 shengbinbin staff 928 6 21 09:09 ..-rw-r--r--@ 1 shengbinbin staff 6148 6 22 09:23 .DS_Storedrwxr-xr-x@ 8 shengbinbin staff 256 11 25 2018 0-materialdrwxr-xr-x 4 shengbinbin staff 128 6 22 13:02 backupdrwxr-xr-x@ 8 shengbinbin staff 256 6 22 14:14 git_leanrningdrwxr-xr-x 5 shengbinbin staff 160 6 22 14:45 git_learningdrwxr-xr-x 11 shengbinbin staff 352 6 22 09:17 git_study//两个分支shengbinbin@chengbinbindeMacBook-Pro git_learn % git clone git@github.com:binshow/git_learning.git git_learning_02Cloning into 'git_learning_02'...remote: Enumerating objects: 20, done.remote: Counting objects: 100% (20/20), done.remote: Compressing objects: 100% (12/12), done.remote: Total 20 (delta 3), reused 14 (delta 3), pack-reused 0Receiving objects: 100% (20/20), 22.62 KiB | 11.31 MiB/s, done.Resolving deltas: 100% (3/3), done.shengbinbin@chengbinbindeMacBook-Pro git_learn % clearshengbinbin@chengbinbindeMacBook-Pro git_learn % ls -altotal 16drwxr-xr-x 9 shengbinbin staff 288 6 22 14:45 .drwx------@ 29 shengbinbin staff 928 6 21 09:09 ..-rw-r--r--@ 1 shengbinbin staff 6148 6 22 09:23 .DS_Storedrwxr-xr-x@ 8 shengbinbin staff 256 11 25 2018 0-materialdrwxr-xr-x 4 shengbinbin staff 128 6 22 13:02 backupdrwxr-xr-x@ 8 shengbinbin staff 256 6 22 14:14 git_leanrningdrwxr-xr-x 5 shengbinbin staff 160 6 22 14:45 git_learningdrwxr-xr-x 5 shengbinbin staff 160 6 22 14:45 git_learning_02drwxr-xr-x 11 shengbinbin staff 352 6 22 09:17 git_studyshengbinbin@chengbinbindeMacBook-Pro git_learn % cd git_learning_02shengbinbin@chengbinbindeMacBook-Pro git_learning_02 % git config --add --local user.name 'zkd'shengbinbin@chengbinbindeMacBook-Pro git_learning_02 % git config --add --local user.eamil 'zkd@qq.com'shengbinbin@chengbinbindeMacBook-Pro git_learning_02 % git config --local --listcore.repositoryformatversion=0core.filemode=truecore.bare=falsecore.logallrefupdates=truecore.ignorecase=truecore.precomposeunicode=trueremote.origin.url=git@github.com:binshow/git_learning.gitremote.origin.fetch=+refs/heads/*:refs/remotes/origin/*branch.main.remote=originbranch.main.merge=refs/heads/mainuser.name=zkduser.eamil=zkd@qq.comshengbinbin@chengbinbindeMacBook-Pro git_learning_02 % git branch -av* main 7e5f6d1 Create README.md remotes/origin/HEAD -&gt; origin/main remotes/origin/feature/add_git_commands 7e5f6d1 Create README.md remotes/origin/main 7e5f6d1 Create README.md remotes/origin/master 8773e48 ADD js remotes/origin/temp a01c150 ADD js //基于远地的分支创建一个本地的分支shengbinbin@chengbinbindeMacBook-Pro git_learning_02 % git checkout -b feature/add_git_commands origin/feature/add_git_commandsBranch 'feature/add_git_commands' set up to track remote branch 'feature/add_git_commands' from 'origin'.Switched to a new branch 'feature/add_git_commands'//第一个人修改了readMeshengbinbin@chengbinbindeMacBook-Pro git_learning_02 % git branch* feature/add_git_commands mainshengbinbin@chengbinbindeMacBook-Pro git_learning_02 % ls -altotal 16drwxr-xr-x 5 shengbinbin staff 160 6 22 14:45 .drwxr-xr-x 9 shengbinbin staff 288 6 22 14:45 ..drwxr-xr-x 12 shengbinbin staff 384 6 22 14:50 .git-rw-r--r-- 1 shengbinbin staff 1064 6 22 14:45 LICENSE-rw-r--r-- 1 shengbinbin staff 35 6 22 14:45 README.mdshengbinbin@chengbinbindeMacBook-Pro git_learning_02 % vim README.mdshengbinbin@chengbinbindeMacBook-Pro git_learning_02 % git add README.mdshengbinbin@chengbinbindeMacBook-Pro git_learning_02 % git statusOn branch feature/add_git_commandsYour branch is up to date with 'origin/feature/add_git_commands'.Changes to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) modified: README.mdshengbinbin@chengbinbindeMacBook-Pro git_learning_02 % git commit -m'ADD git commands description in readMe'[feature/add_git_commands 1a26577] ADD git commands description in readMe 1 file changed, 2 insertions(+)shengbinbin@chengbinbindeMacBook-Pro git_learning_02 % git pushEnumerating objects: 5, done.Counting objects: 100% (5/5), done.Delta compression using up to 8 threadsCompressing objects: 100% (3/3), done.Writing objects: 100% (3/3), 350 bytes | 350.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0), pack-reused 0To github.com:binshow/git_learning.git 7e5f6d1..1a26577 feature/add_git_commands -&gt; feature/add_git_commands shengbinbin@chengbinbindeMacBook-Pro git_learning_02 %","link":"/2021/06/22/git%E4%B9%8B%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"}],"tags":[{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"Java并发","slug":"Java并发","link":"/tags/Java%E5%B9%B6%E5%8F%91/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Netty","slug":"Netty","link":"/tags/Netty/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"算法题","slug":"算法题","link":"/tags/%E7%AE%97%E6%B3%95%E9%A2%98/"},{"name":"消息队列","slug":"消息队列","link":"/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"git","slug":"git","link":"/tags/git/"}],"categories":[{"name":"技术","slug":"技术","link":"/categories/%E6%8A%80%E6%9C%AF/"}]}