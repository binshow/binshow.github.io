{"pages":[],"posts":[{"title":"JVM（一）内存区域和对象详解","text":"Java是一门可以跨平台的语言，主要就是通过Java虚拟机来实现的: 编译器将Java文件编译为Java字节码文件（.class），接下来JVM对字节码文件进行解释，翻译成特定底层平台匹配的机器指令(win/linux/mac)并运行。 Java内存区域Java虚拟机定义了若干程序运行时的数据区，分为线程私有和公有的: 运行时数据区程序计数器程序计数器（Program Counter Register）也被称为PC寄存器，是一块较小的内存空间。 可以看作是当前线程所执行的字节码的行号指示器，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 线程私有的，在任意时刻，一条 Java 虚拟机线程只会执行一个方法的代码，这个正在被线程执行的方法称为该线程的当前方法。 程序计数器是唯一一个在虚拟机规范中没有规定OutOfMemoryError的区域 虚拟机栈Java虚拟机栈（Java Virtual Machine Stack）也是线程私有的，它的生命周期与线程相同。 每个方法被执行的时候，Java虚拟机都会同步创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息。每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种Java虚拟机基本数据类型（boolean、byte、char、short、int、 float、long、double）、对象引用（reference类型，它并不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress 类型（指向了一条字节码指令的地址）。 这些数据类型在局部变量表中的存储空间以局部变量槽（Slot）来表示，其中64位长度的long和 double类型的数据会占用两个变量槽，其余的数据类型只占用一个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定 的，在方法运行期间不会改变局部变量表的大小。 虚拟机栈会发生以下两种异常： 如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量时，Java 虚拟机将会抛出一个 StackOverflowError 异常。 如果 Java 虚拟机栈可以动态扩展，并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成扩展，或者在建立新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个 OutOfMemoryError 异常。 本地方法栈地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别只是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的本地（Native）方法服务。 会发生的异常和虚拟机栈相同 Java堆Java堆（Java Heap）是虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，Java里“几乎”所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的内存区域，因此一些资料中它也被称作“GC堆”（Garbage Collected Heap，）。从回收内存的角度看，由于现代垃圾收集器大部分都是基于分代收集理论设计的，所以Java堆中经常会出现“新生代”“老年代”“永久代”“Eden空间”“From Survivor空间”“To Survivor空间”等名词，需要注意的是这些区域划分仅仅是一部分垃圾收集器的共同特性或者说设计风格而已，而非某个Java虚拟机具体实现的固有内存布局，更不是《Java虚拟机规范》里对Java堆的进一步细致划分。 如果从分配内存的角度看，所有线程共享的Java堆中可以划分出多个线程私有的分配缓冲区 （Thread Local Allocation Buffer，TLAB），以提升对象分配时的效率。不过无论从什么角度，无论如何划分，都不会改变Java堆中存储内容的共性，无论是哪个区域，存储的都只能是对象的实例，将Java 堆细分的目的只是为了更好地回收内存，或者更快地分配内存。 方法区方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。 这区域的内存回收目标主要是针对常量池的回收和对类型的卸载 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池表（Constant Pool Table），用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 Class文件经过类加载器加载后，之前Class文件常量池的内容会存放到方法区的运行时常量池，需要注意的是Class文件常量池的符号引用会转变直接引用存入运行时常量池。 运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量 一定只有编译期才能产生，也就是说，并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可以将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。 直接内存在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区 （Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的 DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了 在Java堆和Native堆中来回复制数据。 JDK的内存演变 JDK1.6时期和我们上面讲的JVM内存区域是一致的： JDK1.7时发生了一些变化，将字符串常量池、静态变量，存放在堆上 在JDK1.8时彻底干掉了方法区，而在直接内存中划出一块区域作为元空间，运行时常量池、类常量池都移动到元空间。 思考一下，为什么使用元空间替换永久代？ 表面上看是为了避免OOM异常。因为通常使用PermSize和MaxPermSize设置永久代的大小就决定了永久代的上限，但是不是总能知道应该设置为多大合适, 如果使用默认值很容易遇到OOM错误。 当使用元空间时，可以加载多少类的元数据就不再由MaxPermSize控制, 而由系统的实际可用空间来控制。 更深层的原因还是要合并HotSpot和JRockit的代码，JRockit从来没有所谓的永久代，也不需要开发运维人员设置永久代的大小，但是运行良好。同时也不用担心运行性能问题了,在覆盖到的测试中, 程序启动和运行速度降低不超过1%，但是这点性能损失换来了更大的安全保障。 哪些地方会发生OOM 堆内存不足是最常见的OOM原因之一，抛出的错误信息是“java.lang.OutOfMemoryError:Java heap space”，原因可能千奇百怪，例如，可能存在内存泄漏问题；也很有可能就是堆的大小不合理，比如我们要处理比较可观的数据量，但是没有显式指定JVM堆大小或者指定数值偏小；或者出现JVM处理引用不及时，导致堆积起来，内存无法释放等。 对于Java虚拟机栈和本地方法栈，这里要稍微复杂一点。如果我们写一段程序不断的进行递归调用，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM实际会抛出StackOverFlowError；当然，如果JVM试图去扩展栈空间的的时候失败，则会抛出OutOfMemoryError。 对于老版本的Oracle JDK，因为永久代的大小是有限的，并且JVM对永久代垃圾回收（如，常量池回收、卸载不再需要的类型）非常不积极，所以当我们不断添加新类型的时候，永久代出现OutOfMemoryError也非常多见，尤其是在运行时存在大量动态类型生成的场合；类似Intern字符串缓存占用太多空间，也会导致OOM问题。对应的异常信息，会标记出来和永久代相关：“java.lang.OutOfMemoryError: PermGen space”。随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的OOM有所改观，出现OOM，异常信息则变成了：“java.lang.OutOfMemoryError: Metaspace”。 直接内存不足，也会导致OOM。 对象的创建都是在堆上吗我注意到有一些观点，认为通过逃逸分析，JVM会在栈上分配那些不会逃逸的对象，这在理论上是可行的，但是取决于JVM设计者的选择。据我所知，Oracle Hotspot JVM中并未这么做，这一点在逃逸分析相关的文档里已经说明，所以可以明确所有的对象实例都是创建在堆上。 目前很多书籍还是基于JDK 7以前的版本，JDK已经发生了很大变化，Intern字符串的缓存和静态变量曾经都被分配在永久代上，而永久代已经被元数据区取代。但是，Intern字符串缓存和静态变量并不是被转移到元数据区，而是直接在堆上分配，所以这一点同样符合前面一点的结论：对象实例都是分配在堆上。 字符串常量池的底层原理字符串常量池是全局的，JVM 中独此一份，因此也称为全局字符串常量池，在 jdk1.7（含）之后是在堆内存之中，存储的是字符串对象的引用，字符串实例是在堆中； 在HotSpot VM里实现线程池功能的是一个StringTable类，它是一个Hash表，默认值大小长度是1009；这个StringTable在每个HotSpot VM的实例只有一份，被所有的类共享。字符串常量由一个一个字符组成，放在了StringTable上。 12345678String str1 = &quot;图解Java&quot;; //先到常量池中查询有没有`&quot;图解Java&quot;`字符串的引用，如果没有，则会在`Java堆`上创建`&quot;图解Java&quot;`字符串，在常量池中存储字符串的地址，`str1`则指向字符串常量池的地址String str2 = new String(&quot;图解Java&quot;);//直接在Java堆中创建对象。`str2`指向堆中的地址。System.out.println(str1 == str2); //falseString str3 = &quot;图解Java&quot;; //str3发现字符串常量池中已经有了`&quot;图解Java&quot;`字符串的引用，则直接返回，不会创建新的对象System.out.println(str1 == str3); //true JVM中除了字符串常量池，8种基本数据类型中除了两种浮点类型剩余的6种基本数据类型的包装类，都使用了缓冲池技术，但是 Byte、Short、Integer、Long、Character 这5种整型的包装类也只是在对应值在 [-128,127] 时才会使用缓冲池，超出此范围仍然会去创建新的对象。 Java对象详解创建对象的4种方式 new 关键字： 在方法区的常量池中查看是否有new 后面参数（也就是类名）的符号引用，并检查是否有类的加载信息也就是是否被加载解析和初始化过。如果已经加载过了就不在加载，否则执行类的加载全过程。 给实例分配内存：此内存中存放对象自己的实例变量和从父类继承过来的实例变量（即使这些从超类继承过来的实例变量有可能被隐藏也会被分配空间），同时这些实例变量被赋予默认值（零值）； 调用构造函数，初始化成员字段：在Java对象初始化过程中，主要涉及三种执行对象初始化的结构，分别是实例变量初始化、实例代码块初始化以及构造函数初始化； user对象指向分配的内存空间： 注意：new操作不是原子操作，b和c的顺序可能会调换。 clone方法创建对象： 要想让一个对象支持clone，必须让这个对象对应的类实现Cloneable接口（标识接口），同时此类中也要重写clone方法 clone()方法是属于Object类的，clone是在堆内存中用二进制的方式进行拷贝，重新分配给对象一块内存 反射创建对象： 获取类的Class对象实例 1234获取方式如下：Class.forName(&quot;类全路径&quot;);类名.class; 如：Animal.class;对象名.getClass(); 通过反射创建类对象的实例对象 1Class.newInstance()：调用无参的构造方法，必需确保类中有无参数的可见的构造函数，否则将会抛出异常； 强制转换成用户所需类型 Java 反射机制是指在程序运行时，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性。这种动态的获取信息以及动态调用对象的方法的功能称为java 的反射机制。 反射机制很重要的一点就是“运行时”，其使得我们可以在程序运行时加载、探索以及使用编译期间完全未知的 .class 文件。换句话说，Java 程序可以加载一个运行时才得知名称的 .class 文件，然后获悉其完整构造，并生成其对象实体、或对其 fields（变量）设值、或调用其 methods（方法） 反序列化创建对象 Java中要序列化的类必须实现Serializable接口； 所有可在网络上传输的对象都必须是可序列化的；如RMI（remote method invoke，即远程方法调用），传入的参数或返回的对象都是可序列化的，否则会出错； 所有需要保存到磁盘的java对象都必须是可序列化的；通常建议：程序创建的每个JavaBean类都实现Serializeable接口； New对象创建过程我们以虚拟机遇到一个new指令开始： 首先检查这个指令的参数是否能在常量池中定位到一个类的符号引用 检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，就先执行相应的类加载过程 类加载检查通过后，接下来虚拟机将为新生对象分配内存。 内存分配有两种方式，指针碰撞（Bump The Pointer）、空闲列表（Free List） 指针碰撞：假设Java堆中内存是绝对规整的，所有被使用过的内存都被放在一边，空闲的内存被放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间方向挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞” 如果Java堆中的内存并不是规整的，已被使用的内存和空闲的内存相互交错在一起，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表” 两种方式的选择由Java堆是否规整决定 Java堆规整由所采用的垃圾收集器是否带有空间压缩整理（Compact）的能力决定 内存分配完成之后，虚拟机将分配到的内存空间（但不包括对象头）都初始化为零值。 设置对象头，请求头里包含了对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。 从虚拟机角度来看，设置完对象头信息以后初始化就已经完成了，但是对于Java程序而言，new指令之后会接着执行 ()方法，对对象进行初始化，这样一个真正可用的对象才算完全被构造出来。 分配对象内存的时候如何保证线程安全分配内存线程安全问题：对象创建在虚拟机中是非常频繁的行为，即使仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。 线程安全问题有两种解可选方案： 一种是对分配内存空间的动作进行同步处理——实际上虚拟机是采用CAS配上失败重试的方式保证更新操作的原子性 另外一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer，TLAB），哪个线程要分配内存，就在哪个线程的本地缓冲区中分配，只有本地缓冲区用完了，分配新的缓存区时才需要同步锁定。 对象的内存布局在HotSpot虚拟机里，对象在堆内存中的存储布局可以划分为三个部分：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding） 在64位的HotSpot虚拟机中，如对象未被同步锁锁定的状态下，Mark Word的64个比特存储空间中的31个比特用于存储对象哈希码，4个比特用于存储对象分代年龄，2个比特用于存储锁标志位，在其他状态（轻量级锁、重量级锁、偏向锁）下对象的存储内容变化如图示。 对象头的另外一部分是类型指针，即对象指向它的类型元数据的指针，Java虚拟机通过这个指针来确定该对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，查找对象的元数据信息并不一定要经过对象本身， 如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是如果数组的长度是不确定的，将无法通过元数据中的信息推断出数组的大小。 对象的访问定位Java程序会通过栈上的reference数据来操作堆上的具体对象。由于reference类型在《Java虚拟机规范》里面只规定了它是一个指向对象的引用，并没有定义这个引用应该通过什么方式去定位、访问到堆中对象的具体位置，所以对象访问方式也是由虚拟机实现而定的，主流的访问方式主要有使用句柄和直接指针两种： 如果使用句柄访问的话，Java堆中将可能会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自具体的地址信息，其结构如图所示： 如果使用直接指针访问的话，Java堆中对象的内存布局就必须考虑如何放置访问类型数据的相关信息，reference中存储的直接就是对象地址，如果只是访问对象本身的话，就不需要多一次间接访问的开销，如图所示： 这两种对象访问方式各有优势，使用句柄来访问的最大好处就是reference中存储的是稳定句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要被修改。 使用直接指针来访问最大的好处就是速度更快，它节省了一次指针定位的时间开销，由于对象访问在Java中非常频繁，因此这类开销积少成多也是一项极为可观的执行成本。 HotSpot虚拟机主要使用直接指针来进行对象访问。 总结：","link":"/2021/05/10/JVM%EF%BC%88%E4%B8%80%EF%BC%89%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%92%8C%E5%AF%B9%E8%B1%A1%E8%AF%A6%E8%A7%A3/"},{"title":"JVM（三）类文件和类加载","text":"java跨平台的实现是基于JVM虚拟机的，编写的java源码，编译后会生成一种.class文件，称为字节码文件。 java虚拟机就是负责将字节码文件翻译成特定平台下的机器码然后运行。 为了保证Class文件在多个平台的通用性，java官方制定了严格的Class文件格式。 了解Class文件结构，有利于我们反编译 .class 文件或在程序编译期间修改字节码做代码注入。 Class文件结构Class文件中包含了Java虚拟机指令集、符号表以及若干其他辅助信息。 每一个 Class 文件对应于一个如下所示的 ClassFile 结构体： 12345678910111213141516171819ClassFile { u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count];}复制代码 简单看一下各项的含义： 由于 Class 文件结构没有任何分隔符，所以无论是每个数据项的的顺序还是数量，都是严格限定的，哪个字节代表什么含义，长度多少，先后顺序如何，都是不允许改变的 魔数将class文件用16进制打开的话 第一行中有一串特殊的字符 cafebabe，它就是一个魔数，是 JVM 识别 class 文件的标志，JVM 会在验证阶段检查 class 文件是否以该魔数开头，如果不是则会抛出 ClassFormatError。 版本号第 5 和第 6 个字节是次版本号（Minor Version），第 7 和第 8 个字节是主版本号（Major Version）。高版本的 JDK 能向下兼容以前版本的 Class 文件，但不能运行以后版本的 Class 文件，即使文件格式未发生变化。 常量池常量池中主要存放两大类常量：字面量（Literal）和符号引用（Symbolic References）。字面量比较接近于Java语言层面的常量概念，如文本字符串、被声明为final的常量值等。而符号引用则属于编译原理方面的概念，主要包括下面几类常量： 被模块导出或者开放的包（Package） 类和接口的全限定名（Fully Qualified Name） 字段的名称和描述符（Descriptor） 方法的名称和描述符 方法句柄和方法类型（Method Handle、Method Type、Invoke Dynamic） 动态调用点和动态常量（Dynamically-Computed Call Site、Dynamically-Computed Constant） 这17类常量结构只有一个相同之处，表结构起始的第一位是个u1类型的标志位（tag），代表着当前常量属于哪种常量类型。 17种常量类型所代表的具体含义如表所示： 类型 标志 描述 CONSTANT_Utf8_info 1 UTF-8 编码的字符串 CONSTANT_Integer_info 3 整型字面量 CONSTANT_Float_info 4 浮点型字面量 CONSTANT_Long_info 5 长整型型字面量 CONSTANT_Double_info 6 双精度浮点型字面量 CONSTANT_Class_info 7 类或接口的符号引用 CONSTANT_String_info 8 字符串类型字面量 CONSTANT_Fieldref_info 9 字段的符号引用 CONSTANT_Methodref_info 10 类中方法的符号引用 CONSTANT_InterfaceMethodref_info 11 接口中方法的符号引用 CONSTANT_NameAndType_info 12 字段或方法的部分符号引用 CONSTANT_MethodHandle_info 15 表示方法句柄 CONSTANT_MethodType_info 16 表示方法类型 CONSTANT_Dynamic_info 17 表示一个动态计算常量 CONSTANT_InvokeDynamic_info 18 表示一个动态方法调用点 CONSTANT_Moudle_info 19 表示一个模块 CONSTANT_Package_info 20 表示一个模块中开放或者导出的包 常量池非常繁琐，17种常量类型各自有着完全独立的数据结构，彼此之间没有什么共性和联系。 访问标志在常量池结束之后，紧接着的2个字节代表访问标志（access_flags），这个标志用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否被声明为final等等。 具体的标志位以及标志的含义如表： 标志名称 标志值 含义 ACC_PUBLIC 0x0001 是否为 Public 类型 ACC_FINAL 0x0010 是否被声明为 final，只有类可以设置 ACC_SUPER 0x0020 是否允许使用 invokespecial 字节码指令的新语义 ACC_INTERFACE 0x0200 标志这是一个接口 ACC_ABSTRACT 0x0400 是否为 abstract 类型，对于接口或者抽象类来说，次标志值为真，其他类型为假 ACC_SYNTHETIC 0x1000 标志这个类并非由用户代码产生 ACC_ANNOTATION 0x2000 标志这是一个注解 ACC_ENUM 0x4000 标志这是一个枚举 access_flags中一共有16个标志位可以使用，当前只定义了其中9个，没有使用到的标志位要求一 律为零。 类索引、父类索引、接口索引这三者用来确定类的继承关系。 类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名。由于Java语言不允许多重继承，所以父类索引只有一个，除了java.lang.Object之外，所有的Java类都有父类，因此除了 java.lang.Object外，所有Java类的父类索引都不为0。 接口索引集合就用来描述这个类实现了哪些接口，这些被实现的接口将按implements关键字（后的接口顺序从左到右排列在接口索引集合中。 字段表集合接口索引结束后，接着是字段表（field_info），它用于描述接口或者类中声明的变量——这里的字段（Field）只包括类级变量以及实例级变量，不包括在方法内部声明的局部变量。 描述的主要信息包括： ①、字段的作用域（public，protected，private修饰） ②、是类级变量还是实例级变量（static修饰） ③、是否可变（final修饰） ④、并发可见性（volatile修饰，是否强制从主从读写） ⑤、是否可序列化（transient修饰） ⑥、字段数据类型（8种基本数据类型，对象，数组等引用类型） ⑦、字段名称 字段表的结构如下： 类型 名称 数量 u2 access_flags 1 u2 name_index 1 u2 descriptor_index 1 u2 attributes_count 1 attribute_info attributes attributes_count access_flags是该字段的的访问标志，它和类中的访问标志很类似，用以描述该字段的权限类型：private、protected、public；并发可见性：volatile；可变性：final； 访问标志详情如下图所示： 由于Java语法规则的约束，ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED三个标志最多只能选择其一，ACC_FINAL、ACC_VOLATILE不能同时选择。接口之中的字段必须有ACC_PUBLIC、ACC_STATIC、ACC_FINAL标志。 方法表集合方法表的结构如同字段表一样，依次包括访问标志（access_flags）、名称索引（name_index）、描述符索引（descriptor_index）、属性表集合（attributes）几项，如表所示： 有区别的部分只有方法访问标志 access_flag, 因为volatile关键字和transient关键字不能修饰方法。 方法表标志位及其取值如下： 属性表集合接下来终于到了最后一项：属性表集合。 前面提到的Class文件、字段表、方法表都可以携带自己的属性表集合，就是引用的这里。 属性表集合中的属性如下所示： 与Class文件中其他的数据项目要求严格的顺序、长度和内容不同，属性表集合的限制宽松一些，不再要求各个属性表具有严格顺序，并且《Java虚拟机规范》允许只要不与已有属性名重复，任何人实现的编译器都可以向属性表中写入自己定义的属性信息，Java虚拟机运行时会忽略掉它不认识的属性。 举例查看12345public class Hello { public static void main(String[] args) { System.out.println(&quot;Hello World&quot;); }} 12javac Hello.java //javac 命令编译成 jvm 能识别的 class 文件xxd Hello.class //以 16 进制的方式查看这个 class 文件 16进制如下： 1234567891011121314151617181920212223242526272800000000: cafe babe 0000 0034 001d 0a00 0600 0f09 .......4........ //cafe babe为魔数00000010: 0010 0011 0800 120a 0013 0014 0700 1507 ................00000020: 0016 0100 063c 696e 6974 3e01 0003 2829 .....&lt;init&gt;...()00000030: 5601 0004 436f 6465 0100 0f4c 696e 654e V...Code...LineN00000040: 756d 6265 7254 6162 6c65 0100 046d 6169 umberTable...mai00000050: 6e01 0016 285b 4c6a 6176 612f 6c61 6e67 n...([Ljava/lang00000060: 2f53 7472 696e 673b 2956 0100 0a53 6f75 /String;)V...Sou00000070: 7263 6546 696c 6501 000a 4865 6c6c 6f2e rceFile...Hello.00000080: 6a61 7661 0c00 0700 0807 0017 0c00 1800 java............00000090: 1901 000b 4865 6c6c 6f20 576f 726c 6407 ....Hello World.000000a0: 001a 0c00 1b00 1c01 0021 636f 6d2f 7869 .........!com/xi000000b0: 6173 6d2f 6173 6d64 656d 6f2f 636c 6173 asm/asmdemo/clas000000c0: 7374 6573 742f 4865 6c6c 6f01 0010 6a61 stest/Hello...ja000000d0: 7661 2f6c 616e 672f 4f62 6a65 6374 0100 va/lang/Object..000000e0: 106a 6176 612f 6c61 6e67 2f53 7973 7465 .java/lang/Syste000000f0: 6d01 0003 6f75 7401 0015 4c6a 6176 612f m...out...Ljava/00000100: 696f 2f50 7269 6e74 5374 7265 616d 3b01 io/PrintStream;.00000110: 0013 6a61 7661 2f69 6f2f 5072 696e 7453 ..java/io/PrintS00000120: 7472 6561 6d01 0007 7072 696e 746c 6e01 tream...println.00000130: 0015 284c 6a61 7661 2f6c 616e 672f 5374 ..(Ljava/lang/St00000140: 7269 6e67 3b29 5600 2100 0500 0600 0000 ring;)V.!.......00000150: 0000 0200 0100 0700 0800 0100 0900 0000 ................00000160: 1d00 0100 0100 0000 052a b700 01b1 0000 .........*......00000170: 0001 000a 0000 0006 0001 0000 0003 0009 ................00000180: 000b 000c 0001 0009 0000 0025 0002 0001 ...........%....00000190: 0000 0009 b200 0212 03b6 0004 b100 0000 ................000001a0: 0100 0a00 0000 0a00 0200 0000 0500 0800 ................000001b0: 0600 0100 0d00 0000 0200 0e ........... 1javap -c xxx 是用来对class文件进行反编译 12345678910111213141516171819xiasmdeMacBook-Pro:test xiasm$ javap -c Hello警告: 二进制文件Hello包含com.xiasm.asmdemo.classtest.Hello1 Compiled from &quot;Hello.java&quot;2 public class com.xiasm.asmdemo.classtest.Hello {3 public com.xiasm.asmdemo.classtest.Hello();4 Code:5 0: aload_06 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V7 4: return89 public static void main(java.lang.String[]);10 Code:11 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream;12 3: ldc #3 // String Hello World13 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V14 8: return15 } 第5行：aload_x 操作码用来把 对象引用 加载到 操作数栈，非静态的函数都有第一个默认参数，那就是 this，这里的 aload_0 就是把 this 入栈 第6行：invokespecial #1 invokespecial指令调用实例初始化方法、私有方法、父类方法，#1 指的是常量池中的第一个，这里是方法引用java/lang/Object.””:()V，也即构造器函数 第7行：return，这个操作码属于 ireturn、lreturn、freturn、dreturn、areturn 和 return 操作码组中的一员，其中 i 表示 int，返回整数，同类的还有 l 表示 long，f 表示 float，d 表示 double，a 表示 对象引用。没有前缀类型字母的 return 表示返回 void 到此，构造器函数就结束了，接下来是 main 函数： 第11行：getstatic #2 getstatic获取指定类的静态域，并将其值压入栈顶，#2 代表常量池中的第 2 个，这里表示的是java/lang/System.out:Ljava/io/PrintStream;，其实就是java.lang.System 类的静态变量 out（类型是 PrintStream） 第12行：ldc #3 ldc表示将int, float或String型常量值从常量池中推送至栈顶，#3 代表常量池的第三个（字符串 Hello, World） 第13行：invokevirtual #4 invokevirutal 指令调用一个对象的实例方法，#4表示 PrintStream.println(String) 函数引用，并把栈顶两个元素出栈 类加载过程 加载就是把字节码文件从IO或内存加载到内存中的过程；初始化就是使用()进行类初始化的过程，这不同于调用构造函数；使用就是字面意思；卸载就是从方法区移除类型。 类加载过程加载 ①、通过一个类的全限定名来获取定义此类的二进制字节流。 ②、将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 ③、在Java堆中生成一个代表这个类的java.lang.Class对象，作为方法区这些数据的访问入口。 它是Java将字节码数据从不同的数据源读取到JVM中，并映射为JVM认可的数据结构（Class对象），这里的数据源可能是各种各样的形态，如jar文件、class文件，甚至是网络数据源等；如果输入数据不是ClassFile的结构，则会抛出ClassFormatError。 加载阶段是用户参与的阶段，我们可以自定义类加载器，去实现自己的类加载过程。 定义此类的二进制流的获取方式有多种： 1、从 ZIP 包中读取。这称为后面的 JAR、EAR、WAR 格式的基础。 2、从网络中获取。比较典型的应用就是 Applet。 3、运行时计算生成。这就是动态代理技术。 4、由其它文件生成。比如 JSP 应用。 5、从数据库中读取。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区中，然后在Java堆中实例化一个 java.lang.Class 类的对象，这个对象将作为程序访问方法区中这些类型数据的外部接口。 注意，加载阶段与连接阶段的部分内容（如一部分字节码文件的格式校验）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始了。 验证作用是为了确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 ①、文件格式验证 ②、元数据验证 ③、字节码验证 ④、符号引用验证 准备创建类或接口中的静态变量，并初始化静态变量的初始值。但这里的“初始化”和下面的显式初始化阶段是有区别的，侧重点在于分配所需要的内存空间，不会去执行更进一步的JVM指令。 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存是在方法区中进行分配。 注意： 一、上面说的是类变量，也就是被 static 修饰的变量，不包括实例变量。实例变量会在对象实例化时随着对象一起分配在堆中。 二、初始值，指的是一些数据类型的默认值。基本的数据类型初始值如下（引用类型的初始值为null）： 解析解析阶段是虚拟机将常量池中的符号引用替换为直接引用的过程。 符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义的定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标不一定已经加载到内存中。 直接引用（Direct References）：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机实现内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那么引用的目标必定已经在内存中存在。 解析动作主要针对类或接口、字段、类方法、接口方法四类符号引用，分别对应于常量池的 CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANTS_InterfaceMethodref_info四种类型常量。 初始化初始化阶段是执行类构造器() 方法的过程。 这一步真正去执行类初始化的代码逻辑，包括静态字段赋值的动作，以及执行类定义中的静态初始化块内的逻辑，编译器在编译阶段就会把这部分逻辑整理好，父类型的初始化逻辑优先于当前类型的逻辑。 ①、() 方法 是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块中可以赋值，但是不能访问。 比如如下代码会报错： 但是你把第 14 行代码放到 static 静态代码块的上面就不会报错了。或者不改变代码顺序，将第 11 行代码移除，也不会报错。 ②、() 方法与类的构造函数（或者说是实例构造器()方法）不同，它不需要显示的调用父类构造器，虚拟机会保证在子类的()方法执行之前，父类的()方法已经执行完毕。因此虚拟机中第一个被执行的()方法的类肯定是 java.lang.Object。 ③、由于父类的() 方法先执行，所以父类中定义的静态语句块要优先于子类的变量赋值操作。 ④、() 方法对于接口来说并不是必须的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成() 方法。 ⑤、接口中不能使用静态语句块，但仍然有变量初始化的赋值操作，因此接口与类一样都会生成() 方法。但接口与类不同的是，执行接口中的() 方法不需要先执行父接口的() 方法。只有当父接口中定义的变量被使用时，父接口才会被初始化。 ⑥、接口的实现类在初始化时也一样不会执行接口的() 方法。 ⑦、虚拟机会保证一个类的() 方法在多线程环境中被正确的加锁和同步。如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的() 方法，其他的线程都需要阻塞等待，直到活动线程执行() 方法完毕。如果在一个类的() 方法中有很耗时的操作，那么可能造成多个进程的阻塞。 比如对于如下代码： View Code 运行结果如下： 线程1抢到了执行() 方法，但是该方法是一个死循环，线程2将一直阻塞等待。 知道了类的初始化过程，那么类的初始化何时被触发呢？JVM大概规定了如下几种情况： ①、当虚拟机启动时，初始化用户指定的类。 ②、当遇到用以新建目标类实例的 new 指令时，初始化 new 指定的目标类。 ③、当遇到调用静态方法的指令时，初始化该静态方法所在的类。 ④、当遇到访问静态字段的指令时，初始化该静态字段所在的类。 ⑤、子类的初始化会触发父类的初始化。 ⑥、如果一个接口定义了 default 方法，那么直接实现或间接实现该接口的类的初始化，会触发该接口的初始化。 ⑦、使用反射 API 对某个类进行反射调用时，会初始化这个类。 ⑧、当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。 类加载器分类①、启动类加载器（Bootstrap ClassLoader） 负责将存放在 /lib 目录中的，或者被**-Xbootclasspath** 参数所指定的路径中的，并且是虚拟机按照文件名识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。**** 启动类加载器无法被Java程序直接引用。**** JDK 中的源码类大都是由启动类加载器加载，比如前面说的 java.lang.String，java.util.List等，需要注意的是，启动类 main Class 也是由启动类加载器加载。 ②、扩展类加载器（Extension ClassLoader） 这个类加载器由 sun.misc.Launcher$ExtClassLoader 实现，负责加载＜JAVA_HOME＞/lib/ext 目录中的，或者被 java.ext.dirs 系统变量所指定的路径中的所有类库。 开发者可以直接使用扩展类加载器。 ③、应用程序类加载器（Application ClassLoader） 由 sun.misc.Launcher$AppClassLoader 实现。由于这个类加载器是 ClassLoader.getSystemClassLoader() 方法的返回值，所以一般也称它为系统类加载器。 它负责加载用户类路径ClassPath上所指定的类库，开发者可以直接使用这个类加载器。如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 通常项目中自定义的类，都会放在类路径下，由应用程序类加载器加载。 ④、自定义类加载器（User ClassLoader） 这是由用户自己定义的类加载器，一般情况下我们不会自定义类加载器，但有些特殊情况，比如JDBC能够通过连接各种不同的数据库就是自定义类加载器来实现的，具体用处会在后文详细介绍。 双亲委派模型双亲委派机制就是如果一个类加载器收到了类加载请求，它首先不会自己尝试去加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有父类加载器反馈到无法完成这个加载请求（它的搜索范围没有找到这个类），子加载器才会尝试自己去加载。 12345678910111213/** * Create by YSOcean */public class ClassLoadTest { public static void main(String[] args) { ClassLoader classLoader1 = ClassLoadTest.class.getClassLoader(); ClassLoader classLoader2 = classLoader1.getParent(); ClassLoader classLoader3 = classLoader2.getParent(); System.out.println(classLoader1); System.out.println(classLoader2); System.out.println(classLoader3); }} 双亲委派机制有什么好处呢? 回到上面提出的问题，如果你自定义了一个 java.lang.String类，你会发现这个自定义的String.java可以正常编译，但是永远无法被加载运行。因为加载这个类的加载器，会一层一层的往上推，最终由启动类加载器来加载，而启动类加载的会是源码包下的String类，不是你自定义的String类。 实现源码： 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } 自定义类加载器先说说我们为什么要自定义类加载器？ ①、加密 我们知道Java字节码是可以进行反编译的，在某些安全性高的场景，是不允许这种情况发生的。那么我们可以将编译后的代码用某种加密算法进行加密，加密后的文件就不能再用常规的类加载器去加载类了。而我们自己可以自定义类加载器在加载的时候先解密，然后在加载。 ②、动态创建 比如很有名的动态代理。 ③、从非标准的来源加载代码 我们不用非要从class文件中获取定义此类的二进制流，还可以从数据库，从网络中，或者从zip包等。 明白了为什么要自定义类加载器，接下来我们再来详述如何自定义类加载器。 通过第 3 小节的 java.lang.ClassLoader 类的源码分析，类加载时根据双亲委派模型会先一层层找到父加载器，如果加载失败，则会调用当前加载器的 findClass() 方法来完成加载。因此我们自定义类加载器，有两个步骤： 1、继承 ClassLoader 2、覆写 findClass() 方法 破坏双亲委派模型的情况 重写 loadClass() 方法 逆向使用类加载器，引入线程上下文类加载器，如果 API 中的基础类想要调用用户的代码(JNDI/JDBC 等),此时双亲委派模型就不能完成.为了解决这个问题,java 设计团队只好 使用一个不优雅的设计方案:Thread 的上下文类加载器,默认就是应用程序的类加载器。 追求程序的动态性：代码热替换、模块热部署等技术，希望应用程序不用重启就可以加载最新的字节码文件.此时就需要破坏双亲委派模型 动态代理的实现对于一个普通的Java动态代理，其实现过程可以简化成为： 提供一个基础的接口，作为被调用类型（com.mycorp.HelloImpl）和代理类之间的统一入口，如com.mycorp.Hello。 实现InvocationHandler，对代理对象方法的调用，会被分派到其invoke方法来真正实现动作。 通过Proxy类，调用其newProxyInstance方法，生成一个实现了相应基础接口的代理类实例，可以看下面的方法签名。 123public satic Object newProxyInsance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) 我们分析一下，动态代码生成是具体发生在什么阶段呢？ 不错，就是在newProxyInstance生成代理类实例的时候。我选取了JDK自己采用的ASM作为示例，一起来看看用ASM实现的简要过程，请参考下面的示例代码片段。 第一步，生成对应的类，其实和我们去写Java代码很类似，只不过改为用ASM方法和指定参数，代替了我们书写的源码。 123456789101112131415161718ClassWriter cw = new ClassWriter(ClassWriter.COMPUTE_FRAMES);cw.visit(V1_8, // 指定Java版本ACC_PUBLIC, // 说明是public类型&quot;com/mycorp/HelloProxy&quot;, // 指定包和类的名称null, // 签名，null表示不是泛型&quot;java/lang/Object&quot;, // 指定父类new String[]{ &quot;com/mycorp/Hello&quot; }); // 指定需要实现的接口更进一步，我们可以按照需要为代理对象实例，生成需要的方法和逻辑。MethodVisitor mv = cw.visitMethod(ACC_PUBLIC, // 声明公共方法&quot;sayHello&quot;, // 方法名称&quot;()Ljava/lang/Object;&quot;, // 描述符null, // 签名，null表示不是泛型null); // 可能抛出的异常，如果有，则指定字符串数组mv.visitCode();// 省略代码逻辑实现细节cw.visitEnd(); // 结束类字节码生成 上面的代码虽然有些晦涩，但总体还是能多少理解其用意，不同的visitX方法提供了创建类型，创建各种方法等逻辑。ASM API，广泛的使用了Visitor模式，如果你熟悉这个模式， 就会知道它所针对的场景是将算法和对象结构解耦，非常适合字节码操纵的场合，因为我们大部分情况都是依赖于特定结构修改或者添加新的方法、变量或者类型等。 按照前面的分析，字节码操作最后大都应该是生成byte数组，ClassWriter提供了一个简便的方法。 cw.toByteArray(); 然后，就可以进入我们熟知的类加载过程了， 总结","link":"/2021/05/11/JVM%EF%BC%88%E4%B8%89%EF%BC%89%E7%B1%BB%E6%96%87%E4%BB%B6%E5%92%8C%E7%B1%BB%E5%8A%A0%E8%BD%BD/"},{"title":"JVM（二）垃圾回收和内存分配","text":"Java技术体系中所提倡的 自动内存管理 最终可以归结为自动化地解决了两个问题：给对象分配内存 以及 回收分配给对象的内存，而且这两个问题针对的内存区域就是Java内存模型中的 堆区 垃圾回收在Java的内存区域中： 程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随线程而灭，栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作，所以这几个区域的内存回收是确定的，随着方法结束或者线程结束，内存自然回收。 Java堆和方法区这两个区域则有着很显著的不确定性：一个接口的多个实现类需要的内存可能会不一样，一个方法所执行的不同条件分支所需要的内存也可能不一样，只有处于运行期间，我们才能知道程序究竟会创建哪些对象，创建多少个对象，这部分内存的分配和回收是动态的。垃圾收集器所关注的正是这部分内存该如何管理 如何判断是否是垃圾 引用计数法：在对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加一；当引用失效时，计数器值就减一；任何时刻计数器为零的对象就是不可能再被使用的。 需要额外的空间来存储计数器，以及繁琐的更新操作，引用计数法还有一个重大的漏洞，那便是无法处理循环引用对象。 12345678910111213141516public static void main(String[] args) { Person father = new Person(); Person son = new Person(); father.setSon(son); son.setFather(father); father = null; son = null; /** * 调用此方法表示希望进行一次垃圾回收。但是它不能保证垃圾回收一定会进行， * 而且具体什么时候进行是取决于具体的虚拟机的，不同的虚拟机有不同的对策。 */ System.gc();} 可达性分析算法:通过一系列名为“GC Roots” 的对象作为终点，当一个对象到GC Roots 之间无法通过引用到达时，便可以进行回收了。 在Java技术体系里面，固定可作为GC Roots的对象包括以下几种： 在虚拟机栈（栈帧中的本地变量表）中引用的对象在方法区中类静态属性引用的对象，譬如Java类的引用类型静态变量。在方法区中常量引用的对象，譬如字符串常量池（String Table）里的引用。在本地方法栈中JNI（即通常所说的Native方法）引用的对象。Java虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象（比如 NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器。所有被同步锁（synchronized关键字）持有的对象。反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。 Java中的引用分类Java中的引用有四种，分为强引用（Strongly Reference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）4种，这4种引用强度依次逐渐减弱。 强引用是最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，无论任何情况下，只要强引用关系还存在，垃圾收集器就永远不会回 收掉被引用的对象。 1Object obj =new Object(); 软引用是用来描述一些还有用，但非必须的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存， 才会抛出内存溢出异常。在JDK 1.2版之后提供了SoftReference类来实现软引用。 12345Object obj = new Object();ReferenceQueue queue = new ReferenceQueue();SoftReference reference = new SoftReference(obj, queue);//强引用对象滞空，保留软引用obj = null; 弱引用也是用来描述那些非必须对象，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生为止。当垃圾收集器开始工作，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK 1.2版之后提供了WeakReference类来实现弱引用。 12345Object obj = new Object();ReferenceQueue queue = new ReferenceQueue();WeakReference reference = new WeakReference(obj, queue);//强引用对象滞空，保留软引用obj = null; 虚引用也称为“幽灵引用”或者“幻影引用”，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知。在JDK 1.2版之后提供了PhantomReference类来实现虚引用。 12345Object obj = new Object();ReferenceQueue queue = new ReferenceQueue();PhantomReference reference = new PhantomReference(obj, queue);//强引用对象滞空，保留软引用obj = null; 分代收集理论它建立在两个分代假说之上： 弱分代假说（Weak Generational Hypothesis）：绝大多数对象都是朝生夕灭的。 强分代假说（Strong Generational Hypothesis）：熬过越多次垃圾收集过程的对象就越难以消亡。 就是把Java堆划分为**新生代 （Young Generation）**和**老年代（Old Generation）两个区域**，新生代存放存活时间短的对象，而每次回收后存活的少量对象，将会逐步晋升到老年代中存放。 堆有新生代和老年代两块区域组成，而新生代区域又分为三个部分，分别是 Eden,From Surivor,To Survivor ,比例是8:1:1。 新生代采用复制算法，每次使用一块Eden区和一块Survivor区，当进行垃圾回收时，将Eden和一块Survivor区域的所有存活对象复制到另一块Survivor区域，然后清理到刚存放对象的区域，依次循环。 老年代采用标记-清除或者标记-整理算法，根据使用的垃圾回收器来进行判断。 基于分代，产生了一些垃圾收集的类型划分： 部分收集（Partial GC）：指目标不是完整收集整个Java堆的垃圾收集，其中又分为： 新生代收集（Minor GC/Young GC）：指目标只是新生代的垃圾收集。 老年代收集（Major GC/Old GC）：指目标只是老年代的垃圾收集。目前只有CMS收集器会有单独收集老年代的行为。 混合收集（Mixed GC）：指目标是收集整个新生代以及部分老年代的垃圾收集。目前只有G1收集器会有这种行为。 整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集。 垃圾回收算法标记清除标记-清除（Mark-Sweep）算法分为两个阶段： 标记 : 标记出所有需要回收的对象 清除：回收所有被标记的对象 标记-清除算法比较基础，但是主要存在两个缺点： 执行效率不稳定，如果Java堆中包含大量对象，而且其中大部分是需要被回收的，这时必须进行大量标记和清除的动作，导致标记和清除两个过程的执行效率都随对象数量增长而降低。 内存空间的碎片化问题，标记、清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致当以后在程序运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 标记-清除算法主要用于老年代，因为老年代可回收的对象比较少。 复制标记-复制算法解决了标记-清除算法面对大量可回收对象时执行效率低的问题。 过程也比较简单：将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 这种算法存在一个明显的缺点：一部分空间没有使用，存在空间的浪费。 新生代垃圾收集主要采用这种算法，因为新生代的存活对象比较少，每次复制的只是少量的存活对象。 一般虚拟机的具体实现不会采用1:1的比例划分，以HotSpot为例，HotSpot虚拟机将内存分为一块较大的Eden空间和两块较小的 Survivor空间，每次分配内存只使用Eden和其中一块Survivor。发生垃圾搜集时，将Eden和Survivor中仍然存活的对象一次性复制到另外一块Survivor空间上，然后直接清理掉Eden和已用过的那块Survivor空间。默认Eden和Survivor的大小比例是8∶1。 标记整理为了降低内存的消耗，引入一种针对性的算法：标记-整理（Mark-Compact）算法。 其中的标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界以外的内存。 标记-整理算法主要用于老年代，在老年代这种大量对象存活的区域，移动对象是个很大的负担，而且这种对象移动操作必须全程暂停用户应用程序（Stop The World）才能进行。 垃圾处理器盘点 Serial收集器它是一个单线程工作的收集器，使用一个处理器或一条收集线程去完成垃圾收集工作。并且进行垃圾收集时，必须暂停其他所有工作线程，直到垃圾收集结束——这就是所谓的“Stop The World”。 Serial/Serial Old收集器的运行过程如图： ParNew收集器ParNew收集器实质上是Serial收集器的多线程并行版本，使用多条线程进行垃圾收集。 ParNew收集器的工作过程如图所示： Parallel Scavenge收集器Parallel Scavenge收集器是一款新生代收集器，基于标记-复制算法实现，也能够并行收集。和ParNew有些类似，但Parallel Scavenge主要关注的是垃圾收集的吞吐量。 所谓吞吐量指的是运行用户代码的时间与处理器总消耗时间的比值。这个比例越高，证明垃圾收集占整个程序运行的比例越小。 Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量: -XX：MaxGCPauseMillis，最大垃圾回收停顿时间。这个参数的原理是空间换时间，收集器会控制新生代的区域大小，从而尽可能保证回收少于这个最大停顿时间。简单的说就是回收的区域越小，那么耗费的时间也越小。 所以这个参数并不是设置得越小越好。设太小的话，新生代空间会太小，从而更频繁的触发GC。 -XX：GCTimeRatio，垃圾收集时间与总时间占比。这个是吞吐量的倒数，原理和MaxGCPauseMillis相同。 由于与吞吐量关系密切，Parallel Scavenge收集器也经常被称作“吞吐量优先收集器”。 Serial Old收集器Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记-整理算法。 Parallel Old收集器Parallel Old是Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于标记-整理算法实现。 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，同样是老年代的收集齐，采用标记-清除算法。 垃圾收集器： 初始标记（CMS initial mark）：单线程运行，需要Stop The World，标记GC Roots能直达的对象。 并发标记（（CMS concurrent mark）：无停顿，和用户线程同时运行，从GC Roots直达对象开始遍历整个对象图。 重新标记（CMS remark）：多线程运行，需要Stop The World，标记并发标记阶段产生对象。 并发清除（CMS concurrent sweep）：无停顿，和用户线程同时运行，清理掉标记阶段标记的死亡的对象。 Concurrent Mark Sweep收集器运行示意图如下： 优点：CMS最主要的优点在名字上已经体现出来——并发收集、低停顿。 缺点：CMS同样有三个明显的缺点。 Mark Sweep算法会导致内存碎片比较多 CMS的并发能力比较依赖于CPU资源，并发回收时垃圾收集线程可能会抢占用户线程的资源，导致用户程序性能下降。 并发清除阶段，用户线程依然在运行，会产生所谓的“浮动垃圾”（Floating Garbage），本次垃圾收集无法处理浮动垃圾，必须到下一次垃圾收集才能处理。如果浮动垃圾太多，会触发新的垃圾回收，导致性能降低。 Garbage First收集器G1把连续的Java堆划分为多个大小相等的独立区域（Region），每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间。收集器能够对扮演不同角色的Region采用不同的策略去处理。 这样就避免了收集整个堆，而是按照若干个Region集进行收集，同时维护一个优先级列表，跟踪各个Region回收的价值，优先收集价值高的Region。 G1收集器的运行过程大致可划分为以下四个步骤： 初始标记（initial mark），标记了从GC Root开始直接关联可达的对象。STW（Stop the World）执行。 并发标记（concurrent marking），和用户线程并发执行，从GC Root开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象、 最终标记（Remark），STW，标记再并发标记过程中产生的垃圾。 筛选回收（Live Data Counting And Evacuation），制定回收计划，选择多个Region 构成回收集，把回收集中Region的存活对象复制到空的Region中，再清理掉整个旧 Region的全部空间。需要STW。 相比CMS，G1的优点有很多，可以指定最大停顿时间、分Region的内存布局、按收益动态确定回收集。 只从内存的角度来看，与CMS的“标记-清除”算法不同，G1从整体来看是基于“标记-整理”算法实现的收集器，但从局部（两个Region 之间）上看又是基于“标记-复制”算法实现，无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，垃圾收集完成之后能提供规整的可用内存。 内存分配原则MinorGC/MajorGC/FullGC的区别 ①、Minor GC 也叫Young GC，指的是新生代 GC，发生在新生代（Eden区和Survivor区）的垃圾回收。因为Java对象大多是朝生夕死的，所以 Minor GC 通常很频繁，一般回收速度也很快。 ②、Major GC 也叫Old GC，指的是老年代的 GC，发生在老年代的垃圾回收，该区域的对象存活时间比较长，通常来讲，发生 Major GC时，会伴随着一次 Minor GC，而 Major GC 的速度一般会比 Minor GC 慢10倍。 ③、Full GC 指的是全区域（整个堆）的垃圾回收，通常来说和 Major GC 是等价的。 内存溢出和内存泄漏的区别 内存溢出（Out Of Memory） ：就是申请内存时，JVM没有足够的内存空间。通俗说法就是去蹲坑发现坑位满了。 内存泄露 （Memory Leak）：就是申请了内存，但是没有释放，导致内存空间浪费。通俗说法就是有人占着茅坑不拉屎。 内存分配的5个策略 对象优先在Eden区分配，当 Eden 区没有足够的空间进行分配时，虚拟机将会发起一次 Minor GC(新生代GC)。 大对象直接分配在老年代，比较典型的就是那种很长的字符串以及数组。 长期存活的对象将进入老年代，新生代对象每熬过一次 Minor GC，年龄就增加1，当它的年龄增加到一定阈值时（默认是15岁），就会被晋升到老年代中。 新生代Survivor 区相同年龄所有对象之和大于 Survivor 所有对象之和的一半，大于等于该年龄的对象进入老年代 空间分配担保原则： 新生代内存分为一块 Eden区，和两块 Survivor 区域，当发生一次 Minor GC时，虚拟机会将Eden和一块Survivor区域的所有存活对象复制到另一块Survivor区域，通常情况下，Java对象朝生夕死，一块 Survivor 区域是能够存放GC后剩余的对象的，但是极端情况下，GC后仍然有大量存活的对象，那么一块 Survivor 区域就会存放不下这么多的对象，那么这时候就需要老年代进行分配担保，让无法放入 Survivor 区域的对象直接进入到老年代，当然前提是老年代还有空间能够存放这些对象。但是实际情况是在完成GC之前，是不知道还有多少对象能够存活下来的，所以老年代也无法确认是否能够存放GC后新生代转移过来的对象，那么这该怎么办呢? 前面我们介绍的都是Minor GC,那么何时会发生 Full GC？ 在发生 Minor GC 时，虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间，如果大于，则改为 Full GC。如果小于，则查看 HandlePromotionFailure 设置是否允许担保失败，如果允许，那只会进行一次 Minor GC，如果不允许，则也要进行一次 Full GC。 1-XX:-HandlePromotionFailure 回到第一个问题，老年代也无法确认是否能够存放GC后新生代转移过来的对象，那么这该怎么办呢? 也就是取之前每一次回收晋升到老年代对象容量的平均大小作为经验值，然后与老年代剩余空间进行比较，来决定是否进行 Full GC，从而让老年代腾出更多的空间。 通常情况下，我们会将 HandlePromotionFaile 设置为允许担保失败，这样能够避免频繁的发生 Full GC。 总结​","link":"/2021/05/10/JVM%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/"},{"title":"MySQL（一）语法和数据类型","text":"DDL，英文叫做 Data Definition Language，也就是数据定义语言，它用来定义我们的数据库对象，包括数据库、数据表和列。通过使用 DDL，我们可以创建，删除和修改数据库和表结构。 DML，英文叫做 Data Manipulation Language，数据操作语言，我们用它操作和数据库相关的记录，比如增加、删除、修改数据表中的记录。 DCL，英文叫做 Data Control Language，数据控制语言，我们用它来定义访问权限和安全级别。 DQL，英文叫做 Data Query Language，数据查询语言，我们用它查询想要的记录，它是 SQL 语言的重中之重。 DDL数据定义语言123456789101112131415shengbinbin@192 ~ % mysql -uroot -p //登陆数据库Enter password:Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 8Server version: 8.0.23 MySQL Community Server - GPLCopyright (c) 2000, 2021, Oracle and/or its affiliates.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; 12345678910111213141516171819mysql&gt; CREATE DATABASE test; //创建数据库Query OK, 1 row affected (0.00 sec)mysql&gt; CREATE DATABASE test;ERROR 1007 (HY000): Can't create database 'test'; database existsmysql&gt; show databases; //查看所有数据库+--------------------+| Database |+--------------------+| binshow || information_schema | // 存储了系统中的一些数据库对象信息，比如用户表信息，列信息，权限信息等等| mybatis || mysql | // mysql 存储了系统的用户权限信息| performance_schema || sys || test |+--------------------+7 rows in set (0.02 sec) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253mysql&gt; use test //选择数据库Database changedmysql&gt; show tables; //展示数据库中的表Empty set (0.00 sec)mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+------------------------------------------------------+| Tables_in_mysql |+------------------------------------------------------+| columns_priv || component || db || default_roles || engine_cost || func || general_log || global_grants || gtid_executed || help_category || help_keyword || help_relation || help_topic || innodb_index_stats || innodb_table_stats || password_history || plugin || procs_priv || proxies_priv || replication_asynchronous_connection_failover || replication_asynchronous_connection_failover_managed || role_edges || server_cost || servers || slave_master_info || slave_relay_log_info || slave_worker_info || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+------------------------------------------------------+35 rows in set (0.01 sec)mysql&gt; 1234567891011121314151617mysql&gt; drop database test; //删除数据库Query OK, 0 rows affected (0.01 sec)mysql&gt; show databases;+--------------------+| Database |+--------------------+| binshow || information_schema || mybatis || mysql || performance_schema || sys |+--------------------+6 rows in set (0.01 sec)mysql&gt; 12345678910111213141516mysql&gt; create table emp(ename varchar(10),hiredate date,sal decimal(10,2),deptno int(2)); //创建表Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; desc emp; //查看表的结构+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(10) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+4 rows in set (0.01 sec)mysql&gt; drop table emp; //删除表Query OK, 0 rows affected (0.01 sec) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788mysql&gt; desc emp;+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(10) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+4 rows in set (0.00 sec)mysql&gt; alter table emp modify ename varchar(20); //修改表的结构类型Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc emp;+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(20) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+4 rows in set (0.01 sec)mysql&gt; alter table emp add column age int(3); //增加字段Query OK, 0 rows affected, 1 warning (0.01 sec)Records: 0 Duplicates: 0 Warnings: 1mysql&gt; desc emp;+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(20) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | || age | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+5 rows in set (0.00 sec)mysql&gt; alter table emp drop column age; //删除字段Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc emp;+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(20) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+4 rows in set (0.01 sec)mysql&gt; alter table emp add column age int(3);Query OK, 0 rows affected, 1 warning (0.01 sec)Records: 0 Duplicates: 0 Warnings: 1mysql&gt; alter table emp change age age1 int(4); //字段改名Query OK, 0 rows affected, 1 warning (0.01 sec)Records: 0 Duplicates: 0 Warnings: 1mysql&gt; desc emp;+----------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+---------------+------+-----+---------+-------+| ename | varchar(20) | YES | | NULL | || hiredate | date | YES | | NULL | || sal | decimal(10,2) | YES | | NULL | || deptno | int | YES | | NULL | || age1 | int | YES | | NULL | |+----------+---------------+------+-----+---------+-------+5 rows in set (0.00 sec)mysql&gt; alter table emp rename emp1; //修改表名称Query OK, 0 rows affected (0.01 sec)mysql&gt; show tables;+-------------------+| Tables_in_binshow |+-------------------+| emp1 |+-------------------+1 row in set (0.00 sec) DML数据操控语言插入数据1234567891011121314151617181920212223242526272829303132mysql&gt; insert into emp(ename , hiredate , sal ,deptno) values('binshow','2020-02-02','2000',2); //插入语句Query OK, 1 row affected (0.01 sec)mysql&gt; insert into emp(ename,sal) values('wb','1000'); //部分列显示插入数据Query OK, 1 row affected (0.00 sec)mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 2000.00 | 2 | NULL || wb | NULL | 1000.00 | NULL | NULL |+---------+------------+---------+--------+------+2 rows in set (0.00 sec)mysql&gt; insert into emp values('zkd','2020-02-04','3000',3,4); //不加要插入的列名称，但是要一一对应Query OK, 1 row affected (0.00 sec)mysql&gt; insert into emp values('zkd','2020-02-04','3000',3,4),('aaa','2020-01-04','4000',3,4); //直接插入多个数据Query OK, 2 rows affected (0.00 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 2000.00 | 2 | NULL || wb | NULL | 1000.00 | NULL | NULL || zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || aaa | 2020-01-04 | 4000.00 | 3 | 4 |+---------+------------+---------+--------+------+5 rows in set (0.00 sec)mysql&gt; 更新数据1234567891011121314151617181920212223242526272829mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 2000.00 | 2 | NULL || wb | NULL | 1000.00 | NULL | NULL || zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || aaa | 2020-01-04 | 4000.00 | 3 | 4 |+---------+------------+---------+--------+------+5 rows in set (0.00 sec)mysql&gt; update emp set sal = 5000 where ename = 'binshow'; //更新语句Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || wb | NULL | 1000.00 | NULL | NULL || zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || aaa | 2020-01-04 | 4000.00 | 3 | 4 |+---------+------------+---------+--------+------+5 rows in set (0.00 sec)mysql&gt; 123456789101112131415161718192021222324mysql&gt; create table dept(deptno int, deptname varchar(10));Query OK, 0 rows affected (0.01 sec)mysql&gt; desc dept;+----------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| deptno | int | YES | | NULL | || deptname | varchar(10) | YES | | NULL | |+----------+-------------+------+-----+---------+-------+2 rows in set (0.00 sec)mysql&gt; insert into dept values(1,'tech'),(2,'sale'),(5,'fin');Query OK, 3 rows affected (0.01 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select * from dept;+--------+----------+| deptno | deptname |+--------+----------+| 1 | tech || 2 | sale || 5 | fin |+--------+----------+3 rows in set (0.00 sec)mysql&gt; 删除数据123456789101112131415mysql&gt; delete from emp where ename = 'wb';Query OK, 1 row affected (0.00 sec)mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || aaa | 2020-01-04 | 4000.00 | 3 | 4 |+---------+------------+---------+--------+------+4 rows in set (0.00 sec)mysql&gt; 查询数据1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859mysql&gt; select distinct deptno from emp; //查询不重复的数据+--------+ | deptno |+--------+| 2 || 3 |+--------+2 rows in set (0.00 sec)mysql&gt; select * from emp where sal = '5000'; //条件查询+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL |+---------+------------+---------+--------+------+1 row in set (0.00 sec)mysql&gt; select * from emp order by sal; +---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || aaa | 2020-01-04 | 4000.00 | 3 | 4 || binshow | 2020-02-02 | 5000.00 | 2 | NULL |+---------+------------+---------+--------+------+4 rows in set (0.00 sec)mysql&gt; select * from emp order by deptno,sal desc;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || aaa | 2020-01-04 | 4000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 |+---------+------------+---------+--------+------+4 rows in set (0.00 sec)mysql&gt; select * from emp order by deptno,sal desc limit 2;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || aaa | 2020-01-04 | 4000.00 | 3 | 4 |+---------+------------+---------+--------+------+2 rows in set (0.00 sec)mysql&gt; select * from emp order by deptno,sal desc limit 1,2;+-------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+-------+------------+---------+--------+------+| aaa | 2020-01-04 | 4000.00 | 3 | 4 || zkd | 2020-02-04 | 3000.00 | 3 | 4 |+-------+------------+---------+--------+------+2 rows in set (0.00 sec)mysql&gt; 聚合操作的顺序问题1select * from table a where id = 1 group by age having xxx; having 和 where的区别：having是对聚合后的结果进行条件的过滤，而where是聚合前就对记录过滤 12345678910111213141516171819202122232425262728293031323334mysql&gt; select count(1) from emp;+----------+| count(1) |+----------+| 4 |+----------+1 row in set (0.01 sec)mysql&gt; select deptno,count(1) from emp group by deptno;+--------+----------+| deptno | count(1) |+--------+----------+| 2 | 2 || 3 | 1 || 1 | 1 |+--------+----------+3 rows in set (0.00 sec)mysql&gt; select deptno,count(1) from emp group by deptno having count(1)&gt;1; //统计人数大于1的部门+--------+----------+| deptno | count(1) |+--------+----------+| 2 | 2 |+--------+----------+1 row in set (0.00 sec)mysql&gt; select sum(sal),max(sal),min(sal) from emp; //统计薪水总和，最大薪水，最小薪水+----------+----------+----------+| sum(sal) | max(sal) | min(sal) |+----------+----------+----------+| 16000.00 | 6000.00 | 1000.00 |+----------+----------+----------+1 row in set (0.00 sec)mysql&gt; 表连接 内连接和外连接的区别：内连接仅仅选出两个表中相互匹配的记录。 左连接和右连接的区别： 左连接指包含所有左表中的记录甚至是右边表中没有和她匹配的记录。 12345678910111213141516171819202122232425262728293031323334mysql&gt; select * from emp;+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || aaa | 2020-01-04 | 4000.00 | 3 | 4 || sbb | 2018-02-01 | 6000.00 | 1 | 18 || bbb | 2018-04-11 | 1000.00 | 2 | 36 |+---------+------------+---------+--------+------+4 rows in set (0.00 sec)mysql&gt; select * from dept;+--------+----------+| deptno | deptname |+--------+----------+| 1 | tech || 2 | sale || 5 | fin || 3 | hr |+--------+----------+4 rows in set (0.00 sec)mysql&gt; select ename ,deptname from emp , dept where emp.deptno = dept.deptno;+---------+----------+| ename | deptname |+---------+----------+| sbb | tech || bbb | sale || binshow | sale || aaa | hr |+---------+----------+4 rows in set (0.00 sec)mysql&gt; 12345678910111213141516171819202122232425262728mysql&gt; insert into emp values('ccc','2010-02-03','10000',4,45);Query OK, 1 row affected (0.00 sec) //查询emp中所有用户名和所在部门名称mysql&gt; select ename , deptname from emp left join dept on emp.deptno = dept.deptno;+---------+----------+| ename | deptname |+---------+----------+| binshow | sale || aaa | hr || sbb | tech || bbb | sale || ccc | NULL |+---------+----------+5 rows in set (0.01 sec)mysql&gt; select ename , deptname from dept right join emp on emp.deptno = dept.deptno; //和上面相同+---------+----------+| ename | deptname |+---------+----------+| binshow | sale || aaa | hr || sbb | tech || bbb | sale || ccc | NULL |+---------+----------+5 rows in set (0.00 sec)mysql&gt; 子查询123456789101112mysql&gt; select * from emp where deptno in(select deptno from dept);+---------+------------+---------+--------+------+| ename | hiredate | sal | deptno | age1 |+---------+------------+---------+--------+------+| binshow | 2020-02-02 | 5000.00 | 2 | NULL || aaa | 2020-01-04 | 4000.00 | 3 | 4 || sbb | 2018-02-01 | 6000.00 | 1 | 18 || bbb | 2018-04-11 | 1000.00 | 2 | 36 |+---------+------------+---------+--------+------+4 rows in set (0.00 sec)mysql&gt; Union联合123456789101112131415161718192021222324252627282930313233mysql&gt; select deptno from emp -&gt; union -&gt; select deptno from dept; //去重了+--------+| deptno |+--------+| 2 || 3 || 1 || 4 || 5 |+--------+5 rows in set (0.00 sec)mysql&gt; select deptno from emp -&gt; union all -&gt; select deptno from dept;+--------+| deptno |+--------+| 2 || 3 || 1 || 2 || 4 || 1 || 2 || 5 || 3 |+--------+9 rows in set (0.00 sec)mysql&gt; DCL数据控制语言暂无 数据类型/运算符/常用函数待补充","link":"/2021/05/11/MySQL%EF%BC%88%E4%B8%80%EF%BC%89%E8%AF%AD%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"title":"Java并发理论基础-上","text":"并发编程领域可以抽象成三个核心问题：分配任务、相互协作和互斥： 分配任务：将一个大的任务交给不同的进程/线程来做 相互协作：线程间的协作，比如一个线程执行完了一个任务，如何通知执行后续任务的线程开工 互斥：要实现在同一时刻内只有一个线程访问共享变量 第一部分、并发编程的发展1. 并发编程问题的由来随着CPU 、 内存 、IO设备的不断发展，三者的速度差异一直是存在的（CPU一天 ， 内存一年 ， IO设备十年） 为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为： CPU 增加了缓存，以均衡与内存的速度差异； 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异； 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用 1.1 缓存导致的可见性问题 一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为可见性。 单核时代，电脑只有1个CPU，所有的线程操作的是同一个CPU的缓存，也就不存在可见性问题。 多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存，如下图 1.2 线程切换带来的原子性问题 一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性 在一个时间片内，如果一个进程进行一个 IO 操作，例如读个文件，这个时候该进程可以把自己标记为“休眠状态”并出让 CPU 的使用权，待文件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得 CPU 的使用权了。 早期的操作系统基于进程来调度 CPU，不同进程间是不共享内存空间的，所以进程要做任务切换就要切换内存映射地址，而一个进程创建的所有线程，都是共享一个内存空间的，所以线程做任务切换成本就很低了。现代的操作系统都基于更轻量的线程来调度，现在我们提到的“任务切换”都是指“线程切换”。 Java 并发程序都是基于多线程的，自然也会涉及到任务切换，也许你想不到，任务切换竟然也是并发编程里诡异 Bug 的源头之一。任务切换的时机大多数是在时间片结束的时候，我们现在基本都使用高级语言编程，高级语言里一条语句往往需要多条 CPU 指令完成，例如上面代码中的count += 1，至少需要三条 CPU 指令。 指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器； 指令 2：之后，在寄存器中执行 +1 操作； 指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存） 1.3 编译优化带来的有序性问题有序性指的是程序按照代码的先后顺序执行。编译器为了优化性能，有时候会进行指令重排序。 重排序分3种类型。 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术(Instruction-Level Parallelism，ILP)来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应 机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上 去可能是在乱序执行 例如程序中：“a=6；b=7；”编译器优化后可能变成“b=7；a=6；”，在这个例子中，编译器调整了语句的顺序，但是不影响程序的最终结果，但是有时会出现问题。 比如单例模式中的双重检验模式： 1234567891011121314public class Singleton { static Singleton instance; public Singleton getInstance(){ if (instance == null){ synchronized (Singleton.class){ if (instance == null) instance = new Singleton(); //在CPU指令上并不是一步操作 } } return instance; }} new一个新的对象分为如下几步（先在内存中初始化对象再赋值给变量）： 分配一块内存 M； 在内存 M 上初始化 Singleton 对象； 然后 M 的地址赋值给 instance 变量。 经过指令重排序变成了下面这种情况（先将内存赋值给变量再进行初始化）： 分配一块内存 M； 将 M 的地址赋值给 instance 变量； 最后在内存 M 上初始化 Singleton 对象。 不安全的情况：假设线程 A 先执行 getInstance() 方法，当执行完指令 2 时恰好发生了线程切换，切换到了线程 B 上；如果此时线程 B 也执行 getInstance() 方法，那么线程 B 在执行第一个判断时会发现 instance != null ，所以直接返回 instance，而此时的 instance 是没有初始化过的，如果我们这个时候访问 instance 的成员变量就可能触发空指针异常。 2. 并发编程面临的挑战并发编程的目的是为了让程序运行得更快，但是，并不是启动更多的线程就能让程序最大限度地并发执行。 2.1上下文切换所谓的多线程并发执行是通过CPU给每个线程分配CPU时间片来实现的，因为时间片非常短（一般是几十毫秒ms），所以CPU通过不停地切 换线程执行，让我们感觉多个线程是同时执行的。 上下文切换是指：当前任务执行完一个时间片后需要切换到下一个任务，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这 个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换 多线程一定快吗？不一定，因为线程有创建和上下文切换的开销。 如何减少上下文切换： 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一 些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。 CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。 协程:在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。 2.2 死锁及避免办法 避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。 3. 什么是线程安全？线程安全需要保证几个基本特性： 原子性，简单说就是相关操作不会中途被其他线程干扰，一般通过同步机制实现。 可见性，是一个线程修改了某个共享变量，其状态能够立即被其他线程知晓，通常被解释为将线程本地状态反映到主内存上，volatile就是负责保证可见性的。 有序性，是保证线程内串行语义，避免指令重排等。 第二部分、Java中如何实现并发安全由上一部分可知：解决可见性、有序性最直接的办法就是禁用缓存和编译优化，但是性能上会带来问题。因此需要做到按需禁用。站在程序员的视角看就是 Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括 volatile、synchronized 和 final 三个关键字，以及六项 Happens-Before 规则， 1. volatile保证可见性volatile是轻量级的 synchronized，它在多处理器开发中保证了共享变量的“可见性”,不会引起线程上下文的切换和调度。 1volatile int x = 0; //告诉编译器，对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入 1.1 如何实现的可见性有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码: 0x01a3de1d: movb 0×0,0×1104800(0×0,0×1104800(%esi); 0x01a3de24: lock addl 0×0,0×1104800(0×0,(%esp); Lock前缀的指令： 1)将当前处理器缓存行的数据写回到系统内存。 2)这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存(L1，L2或其他)后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的 变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据 写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操 作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一 致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当 处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状 态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存 里。 1.2 volatile的使用优化追加64字节能够提高并发编程的效率？ 处理器的L1、L2或L3缓存的高速缓存行是64个字节宽，如果队列的头节点和尾节点都不足64字节的话，处理器会将 它们都读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头、尾节点，当一 个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致 其他处理器不能访问自己高速缓存中的尾节点，而队列的入队和出队操作则需要不停修改头 节点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率。Doug lea使 用追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存 行，使头、尾节点在修改时不会互相锁定。 2. synchronized保证原子性2.1 应用方法·对于普通同步方法，锁是当前实例对象。 ·对于静态同步方法，锁是当前类的Class对象。 ·对于同步方法块，锁是Synchonized括号里配置的对象。 123456789101112131415161718class X { // 修饰非静态方法,锁定的是当前实例对象 this synchronized void foo() { // 临界区 } // 修饰静态方法,锁定的是当前类的 Class 对象 synchronized static void bar() { // 临界区 } // 修饰代码块 //当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。 Object obj = new Object()； void baz() { synchronized(obj) { // 临界区 } }} 2.2 实现原理 在Java6之前，synchronized完全依靠操作系统的互斥锁来实现，需要进行用户态和内核态的切换，所以开销较大，但随着一系列的锁优化，synchronized的性能也越来越好了 JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。 代码块同步是使用monitorenter 和monitorexit指令实现的，而方法同步是使用另外一种方式实现的 monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。 任何对象都有 一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter 指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。 源代码获取： 首先，synchronized的行为是JVM runtime的一部分，所以我们需要先找到Runtime相关的功能实现。通过在代码中查询类似“monitor_enter”或“Monitor Enter”，很直观的就 可以定位到： sharedRuntime.cpp/hpp，它是解释器和编译器运行时的基类。 synchronizer.cpp/hpp，JVM同步相关的各种基础逻辑。 在sharedRuntime.cpp中，下面代码体现了synchronized的主要逻辑。 1234567Handle h_obj(THREAD, obj); if (UseBiasedLocking) { //检查是否开启了偏向锁 // Retry fas entry if bias is revoked to avoid unnecessary infation ObjectSynchronizer::fast_enter(h_obj, lock, true, CHECK); //完整的流程 } else { ObjectSynchronizer::slow_enter(h_obj, lock, CHECK); //直接进入轻量级锁获取逻辑 } 偏斜锁并不适合所有应用场景，撤销操作（revoke）是比较重的行为，只有当存在较多不会真正竞争的synchronized块儿时，才能体现出明显改善。实践中对于偏斜锁的一直是有 争议的，有人甚至认为，当你需要大量使用并发类库时，往往意味着你不需要偏斜锁。从具体选择来看，我还是建议需要在实践中进行测试，根据结果再决定是否使用。 还有一方面是，偏斜锁会延缓JIT 预热的进程，所以很多性能测试中会显式地关闭偏斜锁， -XX:-UseBiasedLocking 12345678910111213141516171819void ObjectSynchronizer::fas_enter(Handle obj, BasicLock* lock, bool attempt_rebias, TRAPS) { if (UseBiasedLocking) { if (!SafepointSynchronize::is_at_safepoint()) { //revoke_and_rebias是获取偏斜锁的入口方法 BiasedLocking::Condition cond = BiasedLocking::revoke_and_rebias(obj, attempt_rebias, THREAD); if (cond == BiasedLocking::BIAS_REVOKED_AND_REBIASED) { return; } } else { assert(!attempt_rebias, &quot;can not rebias toward VM thread&quot;); //revoke_at_safepoint则定义了当检测到安全点时的处理逻辑 BiasedLocking::revoke_at_safepoint(obj); } assert(!obj-&gt;mark()-&gt;has_bias_pattern(), &quot;biases should be revoked by now&quot;); } slow_enter(obj, lock, THREAD);} 1234567891011121314151617181920212223void ObjectSynchronizer::slow_enter(Handle obj, BasicLock* lock, TRAPS) { markOop mark = obj-&gt;mark(); if (mark-&gt;is_neutral()) { // 将目前的Mark Word复制到Displaced Header上 lock-&gt;set_displaced_header(mark); // 利用CAS设置对象的Mark Word if (mark == obj()-&gt;cas_set_mark((markOop) lock, mark)) { TEVENT(slow_enter: release sacklock); return; } // 检查存在竞争 } else if (mark-&gt;has_locker() &amp;&amp; THREAD-&gt;is_lock_owned((address)mark-&gt;locker())) { // 清除 lock-&gt;set_displaced_header(NULL); return; } // 重置Displaced Header lock-&gt;set_displaced_header(markOopDesc::unused_mark()); ObjectSynchronizer::infate(THREAD, obj(), infate_cause_monitor_enter)-&gt;enter(THREAD);} 2.3 锁的优化过程synchronized用的锁是存在Java对象头里的。如果对象是数组类型，还会存数组类型： 锁一共有4种状态，级别从低到高依次是: 无锁状态、 偏向锁状态、 轻量级锁状态、 重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级 2.3.1 偏向锁经验：大多数情况下，锁都是由同一个线程多次获得。 偏向锁的加锁： 当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出 同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否 存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需 要再测试一下Mark Word中偏向锁的标识是否设置成1(表示当前是偏向锁):如果没有设置，则 使用CAS竞争锁;如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 偏向锁的撤销： 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时， 持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点(在这个时间点上没有正 在执行的字节码)。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着， 如果线程不处于活动状态，则将对象头设置成无锁状态;如果线程仍然活着，拥有偏向锁的栈 会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他 线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。 偏向锁的启用： 偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活 2.3.2 轻量级锁加锁过程： 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并 将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用 CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁 解锁过程： 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成 功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁 因为自旋会消耗CPU，为了避免无用的自旋(比如获得锁的线程被阻塞住了)，一旦锁升级 成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时， 都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮 的夺锁之争 2.3.3 原子操作的实现原理处理器如何实现： 锁总线：多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入 系统内存中。那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享 变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。 处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个 LOCK#信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该 处理器可以独占共享内存。 锁缓存：总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处 理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下 使用缓存锁定代替总线锁定来进行优化。缓存锁定”是指内存区域如果被缓存在处理器的缓存 行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声 言LOCK#信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子 性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处 理器回写已被锁定的缓存行的数据时，会使缓存行无效 Java如何实现： 使用循环CAS实现原子操作：JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。 从Java 1.5开始，JDK的并发包里提供了一些类来支持原子操作，如AtomicBoolean(用原子 方式更新的boolean值)、AtomicInteger(用原子方式更新的int值)和AtomicLong(用原子方式更 新的long值)。这些原子包装类还提供了有用的工具方法，比如以原子的方式将当前值自增1和 自减1。 CAS实现原子操作的三大问题： 1)ABA问题 2)循环时间长开销大 3)只能保证一个共享变量的原子操作 (3)使用锁机制实现原子操作 2.4 转账为例分析锁保护没有关联关系的多个资源，例如，银行业务中有针对账户余额（余额是一种资源）的取款操作，也有针对账户密码（密码也是一种资源）的更改操作，我们可以为账户余额和账户密码分配不同的锁来解决并发问题，这个还是很简单的。 1234567891011121314151617181920212223242526272829303132333435363738394041//不同的资源用不同的锁保护class Account { // 锁：保护账户余额 private final Object balLock = new Object(); // 账户余额 private Integer balance; // 锁：保护账户密码 private final Object pwLock = new Object(); // 账户密码 private String password; // 取款 void withdraw(Integer amt) { synchronized(balLock) { if (this.balance &gt; amt){ this.balance -= amt; } } } // 查看余额 Integer getBalance() { synchronized(balLock) { return balance; } } // 更改密码 void updatePassword(String pw){ synchronized(pwLock) { this.password = pw; } } // 查看密码 String getPassword() { synchronized(pwLock) { return password; } }} 当然，我们也可以用一把互斥锁来保护多个资源，例如我们可以用 this 这一把锁来管理账户类里所有的资源：账户余额和用户密码。具体实现很简单，示例程序中所有的方法都增加同步关键字 synchronized 就可以了. 但是用一把锁有个问题，就是性能太差，会导致取款、查看余额、修改密码、查看密码这四个操作都是串行的。而我们用两把锁，取款和修改密码是可以并行的。用不同的锁对受保护资源进行精细化管理，能够提升性能。这种锁还有个名字，叫细粒度锁。 保护有关联关系的多个资源 例如银行业务里面的转账操作，账户 A 减少 100 元，账户 B 增加 100 元。这两个账户就是有关联关系的。那对于像转账这种有关联关系的操作，我们应该怎么去解决呢？ 12345678910111213class Account { private int balance; // 转账 //临界区内有两个资源，分别是转出账户的余额 this.balance 和转入账户的余额 target.balance，并且用的是一把锁 this //问题就出在 this 这把锁上，this 这把锁可以保护自己的余额 this.balance，却保护不了别人的余额 target.balance，就像你不能用自家的锁来保护别人家的资产 synchronized void transfer( Account target, int amt){ if (this.balance &gt; amt) { this.balance -= amt; target.balance += amt; } } } ​ 下面我们具体分析一下，假设有 A、B、C 三个账户，余额都是 200 元，我们用两个线程分别执行两个转账操作：账户 A 转给账户 B 100 元，账户 B 转给账户 C 100 元，最后我们期望的结果应该是账户 A 的余额是 100 元，账户 B 的余额是 200 元， 账户 C 的余额是 300 元。 我们假设线程 1 执行账户 A 转账户 B 的操作，线程 2 执行账户 B 转账户 C 的操作。这两个线程分别在两颗 CPU 上同时执行，那它们是互斥的吗？我们期望是，但实际上并不是。因为线程 1 锁定的是账户 A 的实例（A.this），而线程 2 锁定的是账户 B 的实例（B.this），所以这两个线程可以同时进入临界区 transfer()。同时进入临界区的结果是什么呢？线程 1 和线程 2 都会读到账户 B 的余额为 200，导致最终账户 B 的余额可能是 300（线程 1 后于线程 2 写 B.balance，线程 2 写的 B.balance 值被线程 1 覆盖），可能是 100（线程 1 先于线程 2 写 B.balance，线程 1 写的 B.balance 值被线程 2 覆盖），就是不可能是 200。 使用锁的正确姿势 很简单，只要我们的锁能覆盖所有受保护资源就可以了。在上面的例子中，this 是对象级别的锁，所以 A 对象和 B 对象都有自己的锁，如何让 A 对象和 B 对象共享一把锁呢？ 用 Account.class 作为共享的锁, 缺点就是转账操作都成串行了 123456789101112class Account { private int balance; // 转账 void transfer(Account target, int amt){ synchronized(Account.class) { if (this.balance &gt; amt) { this.balance -= amt; target.balance += amt; } } } } 现实世界里，账户转账操作是支持并发的，而且绝对是真正的并行，银行所有的窗口都可以做转账操作。只要我们能仿照现实世界做转账操作，串行的问题就解决了。 我们试想在古代，没有信息化，账户的存在形式真的就是一个账本，而且每个账户都有一个账本，这些账本都统一存放在文件架上。银行柜员在给我们做转账时，要去文件架上把转出账本和转入账本都拿到手，然后做转账。这个柜员在拿账本的时候可能遇到以下三种情况： 文件架上恰好有转出账本和转入账本，那就同时拿走； 如果文件架上只有转出账本和转入账本之一，那这个柜员就先把文件架上有的账本拿到手，同时等着其他柜员把另外一个账本送回来； 转出账本和转入账本都没有，那这个柜员就等着两个账本都被送回来。 上面这个过程在编程的世界里怎么实现呢？其实用两把锁就实现了，转出账本一把，转入账本另一把。在 transfer() 方法内部，我们首先尝试锁定转出账户 this（先把转出账本拿到手），然后尝试锁定转入账户 target（再把转入账本拿到手），只有当两者都成功时，才执行转账操作。 12345678910111213141516class Account { private int balance; // 转账 void transfer(Account target, int amt){ // 锁定转出账户 synchronized(this) { // 锁定转入账户 synchronized(target) { if (this.balance &gt; amt) { this.balance -= amt; target.balance += amt; } } } } } 使用细粒度锁可以提高并行度，是性能优化的一个重要手段,但是会出现死锁的情况，比如下面这种情况： 账户 A 转账户 B 100 元，此时另一个客户找柜员李四也做个转账业务：账户 B 转账户 A 100 元，于是张三和李四同时都去文件架上拿账本，这时候有可能凑巧张三拿到了账本 A，李四拿到了账本 B。张三拿到账本 A 后就等着账本 B（账本 B 已经被李四拿走），而李四拿到账本 B 后就等着账本 A（账本 A 已经被张三拿走），他们要等多久呢？他们会永远等待下去…因为张三不会把账本 A 送回去，李四也不会把账本 B 送回去。我们姑且称为死等吧。 解决死锁在第四节讲。 3. Happens-Before 规则前面一个操作的结果对后续操作是可见的,Happens-Before 约束了编译器的优化行为，虽允许编译器优化，但是要求编译器优化后一定遵守 Happens-Before 规则 3.1 程序的顺序性规则在一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作 12345678910111213class VolatileExample { int x = 0; volatile boolean v = false; public void writer() { x = 42; //先发生 v = true; //后发生 } public void reader() { if (v == true) { // 这里 x 会是多少呢？ } }} 3.2 volatile 变量规则对一个 volatile 变量的写操作， Happens-Before 于后续对这个 volatile 变量的读操作 3.3 传递性规则如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C 3.4 管程中锁的规则对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。 管程是一种通用的同步原语，在 Java 中指的就是 synchronized，synchronized 是 Java 里对管程的实现。 123456synchronized (this) { // 此处自动加锁 // x 是共享变量, 初始值 =10 if (this.x &lt; 12) { this.x = 12; } } // 此处自动解锁 假设 x 的初始值是 10，线程 A 执行完代码块后 x 的值会变成 12（执行完自动释放锁），线程 B 进入代码块时，能够看到线程 A 对 x 的写操作，也就是线程 B 能够看到 x==12。这个也是符合我们直觉的 3.5 线程 start() 规则主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。 123456789Thread B = new Thread(()-&gt;{ // 主线程调用 B.start() 之前 // 所有对共享变量的修改，此处皆可见 // 此例中，var==77});// 此处对共享变量 var 修改var = 77;// 主线程启动子线程B.start(); 3.6 线程 join() 规则主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作。当然所谓的“看到”，指的是对共享变量的操作. 换句话说就是，如果在线程 A 中，调用线程 B 的 join() 并成功返回，那么线程 B 中的任意操作 Happens-Before 于该 join() 操作的返回。 123456789101112Thread B = new Thread(()-&gt;{ // 此处对共享变量 var 修改 var = 66;});// 例如此处对共享变量修改，// 则这个修改结果对线程 B 可见// 主线程启动子线程B.start();B.join()// 子线程所有对共享变量的修改// 在主线程调用 B.join() 之后皆可见// 此例中，var==66 4. 如何预防死锁4.1 死锁发生的四个条件 互斥，共享资源 X 和 Y 只能被一个线程占用； 占有且等待，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X； 不可抢占，其他线程不能强行抢占线程 T1 占有的资源； 循环等待，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等待。 4.2 破坏死锁条件 对于“占用且等待”这个条件，我们可以一次性申请所有的资源，这样就不存在等待了。 对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。 对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不存在循环了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//利用上面转账的例子class Allocator { private List&lt;Object&gt; als = new ArrayList&lt;&gt;(); // 一次性申请所有资源 synchronized boolean apply( Object from, Object to){ if(als.contains(from) || als.contains(to)){ return false; } else { als.add(from); als.add(to); } return true; } // 归还资源 synchronized void free( Object from, Object to){ als.remove(from); als.remove(to); }} class Account { // actr 应该为单例 private Allocator actr; private int balance; // 转账 void transfer(Account target, int amt){ // 一次性申请转出账户和转入账户，直到成功 while(!actr.apply(this, target))； //while 死循环 try{ // 锁定转出账户 synchronized(this){ // 锁定转入账户 synchronized(target){ if (this.balance &gt; amt){ this.balance -= amt; target.balance += amt; } } } } finally { actr.free(this, target) } } } 破坏不可抢占条件看上去很简单，核心是要能够主动释放它占有的资源，这一点 synchronized 是做不到的。原因是 synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。 1234567891011121314151617181920212223class Account { private int id; private int balance; // 转账 void transfer(Account target, int amt){ Account left = this ① Account right = target; ② if (this.id &gt; target.id) { ③ left = target; ④ right = this; ⑤ } ⑥ // 锁定序号小的账户 synchronized(left){ // 锁定序号大的账户 synchronized(right){ if (this.balance &gt; amt){ this.balance -= amt; target.balance += amt; } } } } } 5. 等待通知模式优化循环等待最好的方案应该是：如果线程要求的条件（转出账本和转入账本同在文件架上）不满足，则线程阻塞自己，进入等待状态；当线程要求的条件（转出账本和转入账本同在文件架上）满足后，通知等待的线程重新执行。其中，使用线程阻塞的方式就能避免循环等待消耗 CPU 的问题。 类比就医环节： 就医流程基本上是这样： 患者先去挂号，然后到就诊门口分诊，等待叫号； 当叫到自己的号时，患者就可以找大夫就诊了； 就诊过程中，大夫可能会让患者去做检查，同时叫下一位患者； 当患者做完检查后，拿检测报告重新分诊，等待叫号； 当大夫再次叫到自己的号时，患者再去找大夫就诊。 下面我们来对比看一下前面都忽视了哪些细节。 患者到就诊门口分诊，类似于线程要去获取互斥锁；当患者被叫到时，类似线程已经获取到锁了。 大夫让患者去做检查（缺乏检测报告不能诊断病因），类似于线程要求的条件没有满足。 患者去做检查，类似于线程进入等待状态；然后大夫叫下一个患者，这个步骤我们在前面的等待 - 通知机制中忽视了，这个步骤对应到程序里，本质是线程释放持有的互斥锁。 患者做完检查，类似于线程要求的条件已经满足；患者拿检测报告重新分诊，类似于线程需要重新获取互斥锁，这个步骤我们在前面的等待 - 通知机制中也忽视了。 5.1 synchronized 实现等待 - 通知机制wait方法原理（会释放锁）： notify方法原理： 为什么说是曾经满足过呢？因为notify() 只能保证在通知时间点，条件是满足的。而被通知线程的执行时间点和通知的时间点基本上不会重合，所以当线程执行的时候，很可能条件已经不满足了（保不齐有其他线程插队）。 上面我们一直强调 wait()、notify()、notifyAll() 方法操作的等待队列是互斥锁的等待队列，所以如果 synchronized 锁定的是 this，那么对应的一定是 this.wait()、this.notify()、this.notifyAll()；如果 synchronized 锁定的是 target，那么对应的一定是 target.wait()、target.notify()、target.notifyAll() 。而且 wait()、notify()、notifyAll() 这三个方法能够被调用的前提是已经获取了相应的互斥锁，所以我们会发现 wait()、notify()、notifyAll() 都是在 synchronized{}内部被调用的。如果在 synchronized{}外部调用，或者锁定的 this，而用 target.wait() 调用的话，JVM 会抛出一个运行时异常：java.lang.IllegalMonitorStateException。 等待 - 通知机制的基本原理搞清楚后，我们就来看看它如何解决一次性申请转出账户和转入账户的问题吧。在这个等待 - 通知机制中，我们需要考虑以下四个要素。 互斥锁：上一篇文章我们提到 Allocator 需要是单例的，所以我们可以用 this 作为互斥锁。 线程要求的条件：转出账户和转入账户都没有被分配过。 何时等待：线程要求的条件不满足就等待。 何时通知：当有线程释放账户时就通知。 ps：因为当 wait() 返回时，有可能条件已经发生变化了，曾经条件满足，但是现在已经不满足了，所以要重新检验条件是否满足。 12345678910111213141516171819202122class Allocator { private List&lt;Object&gt; als; // 一次性申请所有资源 synchronized void apply(Object from, Object to){ // 经典写法 while(als.contains(from) || als.contains(to)){ try{ wait(); //不满足就wait }catch(Exception e){ } } als.add(from); als.add(to); } // 归还资源 synchronized void free( Object from, Object to){ als.remove(from); als.remove(to); notifyAll(); }} notify() 是会随机地通知等待队列中的一个线程，而 notifyAll() 会通知等待队列中的所有线程。 尽量使用 notifyAll()，因为使用notify可能会造成有的线程再也不能被唤醒了 6. 管程Java 采用的是管程技术，synchronized 关键字及 wait()、notify()、notifyAll() 这三个方法都是管程的组成部分。而管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。但是管程更容易使用，所以 Java 选择了管程。 管程，对应的英文是 Monitor，很多 Java 领域的同学都喜欢将其翻译成“监视器“。所谓管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。翻译为 Java 领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。那管程是怎么管的呢？ 6.1 MESA 模型在管程的发展史上，先后出现过三种不同的管程模型，分别是：Hasen 模型、Hoare 模型和 MESA 模型。其中，现在广泛应用的是 MESA 模型，并且 Java 管程的实现参考的也是 MESA 模型。所以今天我们重点介绍一下 MESA 模型。 在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。 6.1.1 解决互斥管程解决互斥问题的思路很简单，就是将共享变量及其对共享变量的操作统一封装起来。 在下图中，管程 X 将共享变量 queue 这个队列和相关的操作入队 enq()、出队 deq() 都封装起来了； 线程 A 和线程 B 如果想访问共享变量 queue，只能通过调用管程提供的 enq()、deq() 方法来实现； enq()、deq() 保证互斥性，只允许一个线程进入管程。不知你有没有发现，管程模型和面向对象高度契合的。 6.1.2 解决同步在管程模型里，共享变量和对共享变量的操作是被封装起来的，图中最外层的框就代表封装的意思。框的上面只有一个入口，并且在入口旁边还有一个入口等待队列。当多个线程同时试图进入管程内部时，只允许一个线程进入，其他线程则在入口等待队列中等待。这个过程类似就医流程的分诊，只允许一个患者就诊，其他患者都在门口等待。 管程里还引入了条件变量的概念，而且每个条件变量都对应有一个等待队列，如下图，条件变量 A 和条件变量 B 分别都有自己的等待队列。 那条件变量和等待队列的作用是什么呢？其实就是解决线程同步问题。你也可以结合上面提到的入队出队例子加深一下理解。 假设有个线程 T1 执行数据出队操作，不过需要注意的是执行出队操作，有个前提条件，就是队列中的数据不能是空的，而队列不空这个前提条件就是管程里的条件变量。 如果线程 T1 进入管程后恰好发现队列是空的，那怎么办呢？等待啊，去哪里等呢？就去条件变量对应的等待队列里面等。此时线程 T1 就去“队列不空”这个条件变量的等待队列中等待。这个过程类似于大夫发现你要去验个血，于是给你开了个验血的单子，你呢就去验血的队伍里排队。线程 T1 进入条件变量的等待队列后，是允许其他线程进入管程的。这和你去验血的时候，医生可以给其他患者诊治，道理都是一样的。 再假设之后另外一个线程 T2 执行数据入队操作，入队操作执行成功之后，“队列不空”这个条件对于线程 T1 来说已经满足了，此时线程 T2 要通知 T1，告诉它需要的条件已经满足了。当线程 T1 得到通知后，会从等待队列里面出来，但是出来之后不是马上执行，而是重新进入到入口等待队列里面。这个过程类似你验血完，回来找大夫，需要重新分诊。 条件变量及其等待队列我们讲清楚了，下面再说说 wait()、notify()、notifyAll() 这三个操作。前面提到线程 T1 发现“队列不空”这个条件不满足，需要进到对应的等待队列里等待。这个过程就是通过调用 wait() 来实现的。如果我们用对象 A 代表“队列不空”这个条件，那么线程 T1 需要调用 A.wait()。同理当“队列不空”这个条件满足时，线程 T2 需要调用 A.notify() 来通知 A 等待队列中的一个线程，此时这个队列里面只有线程 T1。至于 notifyAll() 这个方法，它可以通知等待队列中的所有线程。 这里我还是来一段代码再次说明一下吧。下面的代码实现的是一个阻塞队列，阻塞队列有两个操作分别是入队和出队，这两个方法都是先获取互斥锁，类比管程模型中的入口。 对于入队操作，如果队列已满，就需要等待直到队列不满，所以这里用了notFull.await();。 对于出队操作，如果队列为空，就需要等待直到队列不空，所以就用了notEmpty.await();。 如果入队成功，那么队列就不空了，就需要通知条件变量：队列不空notEmpty对应的等待队列。 如果出队成功，那就队列就不满了，就需要通知条件变量：队列不满notFull对应的等待队列。 123456789101112131415161718192021222324252627282930313233343536373839//实现的是一个阻塞队列，阻塞队列有两个操作分别是入队和出队，这两个方法都是先获取互斥锁public class BlockedQueue&lt;T&gt;{ final Lock lock = new ReentrantLock(); // 条件变量：队列不满 final Condition notFull = lock.newCondition(); // 条件变量：队列不空 final Condition notEmpty = lock.newCondition(); // 入队 void enq(T x) { lock.lock(); try { while (队列已满){ // 等待队列不满 notFull.await(); } // 省略入队操作... // 入队后, 通知可出队 notEmpty.signal(); }finally { lock.unlock(); } } // 出队 void deq(){ lock.lock(); try { while (队列已空){ // 等待队列不空 notEmpty.await(); } // 省略出队操作... // 出队后，通知可入队 notFull.signal(); }finally { lock.unlock(); } }} 6.1.3 wait() 的正确姿势1234//编程范式：用if会造成虚假唤醒while(条件不满足) { wait();} Hasen 模型、Hoare 模型和 MESA 模型的一个核心区别就是当条件满足后，如何通知相关线程。管程要求同一时刻只允许一个线程执行，那当线程 T2 的操作使线程 T1 等待的条件满足时，T1 和 T2 究竟谁可以执行呢？ Hasen 模型里面，要求 notify() 放在代码的最后，这样 T2 通知完 T1 后，T2 就结束了，然后 T1 再执行，这样就能保证同一时刻只有一个线程执行。hasen 是执行完，再去唤醒另外一个线程，能够保证线程的执行。 Hoare 模型里面，T2 通知完 T1 后，T2 阻塞，T1 马上执行；等 T1 执行完，再唤醒 T2，也能保证同一时刻只有一个线程执行。但是相比 Hasen 模型，T2 多了一次阻塞唤醒操作。hoare，是中断当前线程，唤醒另外一个线程，执行玩再去唤醒，也能够保证完成。 MESA 管程里面，T2 通知完 T1 后，T2 还是会接着执行，T1 并不立即执行，仅仅是从条件变量的等待队列进到入口等待队列里面。这样做的好处是 notify() 不用放到代码的最后，T2 也没有多余的阻塞唤醒操作。但是也有个副作用，就是当 T1 再次执行的时候，可能曾经满足的条件，现在已经不满足了，所以需要以循环方式检验条件变量。 6.1.4 notify什么时候使用 所有等待线程拥有相同的等待条件； 所有等待线程被唤醒后，执行相同的操作； 只需要唤醒一个线程。 wait和sleep的区别 相同点： 都是让线程阻塞 都可以接受到中断通知 不同点： 在同步代码块中，sleep不会释放锁，wait会释放锁。所以wait方法必须在synchronized 保护的代码中使用，而sleep没有这个要求。 sleep方法必须定义一个时间，时间到期后自动恢复。而wait可以不设置参数，意味着永久等待 wait是Object类的方法，sleep是Thread的方法。 第三部分、Java中的线程现代操作系统调度的最小单元是线程，也叫轻量级进程(Light Weight Process)，在一个进程里可以创建多个线程，这些线程都拥有各自的计数器、堆栈和局部变量等属性，并且能够访问共享的内存变量。处理器在这些线程上高速切换，让使用者感觉到这些线程在同时执行。 1. 线程的发展路程1.1 操作系统的发展操作系统的发展经历了三个阶段： 手工操作： 单道批处理系统：输入机与主机之间增加了一个存储设备磁带(盘)，单道批处理系统是将作业一个一个加入内存的，那么某一个作业因为等待磁带（盘）或者其他I/O操作而暂停时，那计算机就只能一直阻塞，直到该I/O完成。对于CPU操作密集型的程序，I/O操作相对较少，因此浪费的时间也很少。但是对于I/O操作较多的场景来说，CPU的资源是属于严重浪费的。 多道批处理系统： 为了解决单道批处理系统因为输入/输出（I/O）请求后，导致计算机等待I/O完成而造成的计算机的资源的浪费。接下来又出现了多道批处理系统。多道批处理系统与单道批处理系统的主要区别是在内存中允许一个或多个作业，当一个作业在等待I/O处理时，多批处理系统会通过相应调度算法调度另外一个作业让计算机执行。从而使CPU的利用率得到更大的提高 1.2 进程的由来在多道批处理系统中引申出了一个非常重要的模式，即允许多个作业进入内存并运行。由于在内存中存储了多个作业，那么多个作业如何进行区分？当某个作业因为等待I/O暂停时，怎么恢复到之前的运行状态呢？ 所以这个时候，人们就发明了进程这一概念，用进程来保存每个作业的数据与运行状态，同时对每个进程划分对应的内存地址空间（代码、数据、进程空间、打开的文件），并且要求进程只能使用它自己的内存空间。那么就可以达到作业的区分及恢复。 1.3 线程的由来因为一个进程在一个时间段内只能做一件事情。如果某个程序有多个任务，只能逐个执行这些任务。同时进程中存储了大量信息（数据，进程运行状态信息等）。那么当计算机进行进程切换的时候，必然存在着很大的时间与空间消耗（因为每个进程对应不同内存地址空间，进程的切换，实际是处理器处理不同的地址空间） 为了实现一个进程中任务的切换同时又避免地址空间的切换：发明了线程这一概念，用线程表示进程中的不同任务，同时又将计算机实际调度的单元转到线程。这样就避免了进程的内存地址空间的切换，也达到了多任务的并发执行。 1.4 进程和线程的区别 进程是CPU分配系统资源的基本单位，线程是CPU调度和执行的基本单位。 一个进程可以包含多个线程，进程拥有自己独立的地址空间，而进程中的不同线程共享该进程的地址空间 进程的切换会涉及到虚拟地址空间的切换，开销比较大，线程的切换开销比较小 1.5 为什么要使用多线程 更多的处理器核心：一个 单线程程序在运行时只能使用一个处理器核心，那么再多的处理器核心加入也无法显著提升 该程序的执行效率。相反，如果该程序使用多线程技术，将计算逻辑分配到多个处理器核心 上，就会显著减少程序的处理时间，并且随着更多处理器核心的加入而变得更有效率 更快的响应时间：一笔订单的创建，它包括插入订单数据、生成订单快照、发送邮件通知卖家和记录 货品销售数量等。可以使用多线程技术，即将数据一致性不强的操作派发给其他线程处 理(也可以使用消息队列)，如生成订单快照、发送邮件等。这样做的好处是响应用户请求的线 程能够尽可能快地处理完成，缩短了响应时间，提升了用户体验 更好的编程模型 1.6 线程的优先级现代操作系统基本采用时分的形式调度运行的线程，操作系统会分出一个个时间片，线程会分配到若干时间片，当线程的时间片用完了就会发生线程调度，并等待着下次分配。线程分配到的时间片多少也就决定了线程使用处理器资源的多少，而线程优先级就是决定线程需要多或者少分配一些处理器资源的线程属性。 在Java线程中，通过一个整型成员变量priority来控制优先级，优先级的范围从1~10，在线程构建的时候可以通过setPriority(int)方法来修改优先级，默认优先级是5，优先级高的线程分配时间片的数量要多于优先级低的线程。 1.7 线程的6种状态 NEW（初始化状态） RUNNABLE（可运行 / 运行状态） BLOCKED（阻塞状态） WAITING（无时限等待） TIMED_WAITING（有时限等待） TERMINATED（终止状态） 1.8 Daemon线程Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持性工作。这 意味着，当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。可以通过调 用Thread.setDaemon(true)将线程设置为Daemon线程。 2. 启动和终止线程调用线程的start()方法进行启动，随着run()方法的执行完毕，线程也随之终止 2.1 构造线程的三种方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package server.doc.thread;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;public class ThreadTest { public static void main(String[] args) throws ExecutionException, InterruptedException { A a = new A(); Thread threadA = new Thread(a); threadA.start(); B b = new B(); Thread threadB = new Thread(b); threadB.start(); C c = new C(); FutureTask&lt;Integer&gt; integerFutureTask = new FutureTask&lt;&gt;(c); //FutureTask&lt;V&gt;()是Runnable的实现类 Thread threadC = new Thread(integerFutureTask); threadC.start(); System.out.println(integerFutureTask.get());//可通过get方法获得返回值 }}class A extends Thread{ @Override public void run() { System.out.println(&quot;=======继承Thread类创建线程====&quot;); }}class B implements Runnable{ @Override public void run() { System.out.println(&quot;=======实现runnable接口创建线程====&quot;); }}//实现Callable接口创建线程,Integer就是返回值class C implements Callable&lt;Integer&gt; { @Override public Integer call() throws Exception { System.out.println(&quot;=======实现Callable接口创建线程====&quot;); return 2; }} 2.2 启动线程start源码1234567891011121314151617181920212223242526272829// 该方法可以创建一个新的线程出来public synchronized void start() { // 如果没有初始化，抛异常 if (threadStatus != 0) throw new IllegalThreadStateException(); group.add(this); // started 是个标识符，我们在做一些事情的时候，经常这么写 // 动作发生之前标识符是 false，发生完成之后变成 true boolean started = false; try {// 这里会创建一个新的线程，执行完成之后，新的线程已经在运行了，既 target 的内容已经在运行了 start0(); // 这里执行的还是主线程 started = true; } finally { try { // 如果失败，把线程从线程组中删除 if (!started) { group.threadStartFailed(this); } // Throwable 可以捕捉一些 Exception 捕捉不到的异常，比如说子线程抛出的异常 } catch (Throwable ignore) { /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ } }}// 开启新线程使用的是 native 方法private native void start0(); 2.3 正确的停止线程中断可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程的interrupt() 方法对其进行中断操作。 从原理上讲应该用 interrupt 来请求中断，而不是强制停止，因为这样可以避免数据错乱，也可以让线程有时间结束收尾工作。 123while (!Thread.currentThread().islnterrupted() &amp;&amp; more work to do) { do more work} 我们一旦调用某个线程的 interrupt() 之后，这个线程的中断标记位就会被设置成 true。每个线程都有这样的标记位，当线程执行时，应该定期检查这个标记位，如果标记位被设置成 true，就说明有程序想终止该线程。回到源码，可以看到在 while 循环体判断语句中，首先通过 Thread.currentThread().isInterrupt() 判断线程是否被中断，随后检查是否还有工作要做。 被 interrupt 的线程，是怎么收到通知的呢？一种是异常，另一种是主动检测。 异常： 当线程 A 处于 WAITING、TIMED_WAITING 状态时，如果其他线程调用线程 A 的 interrupt() 方法，会使线程 A 返回到 RUNNABLE 状态，同时线程 A 的代码会触发 InterruptedException 异常。上面我们提到转换到 WAITING、TIMED_WAITING 状态的触发条件，都是调用了类似 wait()、join()、sleep() 这样的方法，我们看这些方法的签名，发现都会 throws InterruptedException 这个异常。这个异常的触发条件就是：其他线程调用了该线程的 interrupt() 方法。 当线程 A 处于 RUNNABLE 状态时，并且阻塞在 java.nio.channels.InterruptibleChannel 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 会触发 java.nio.channels.ClosedByInterruptException 这个异常；而阻塞在 java.nio.channels.Selector 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 的 java.nio.channels.Selector 会立即返回。 主动监测： 线程通过检查自身是否被中断来进行响应，线程通过方法isInterrupted()来进行判断是否 被中断，也可以调用静态方法Thread.interrupted()对当前线程的中断标识位进行复位。 sleep情况下能否感召到打断位？ 如果 sleep、wait 等可以让线程进入阻塞的方法使线程休眠了，而处于休眠中的线程被中断，那么线程是可以感受到中断信号的，并且会抛出一个 InterruptedException 异常，同时清除中断信号，将中断标记位设置成 false。这样一来就不用担心长时间休眠中线程感受不到中断了，因为即便线程还在休眠，仍然能够响应中断通知，并抛出异常。 3.线程间通信的几种方式 volatile和synchronized关键字 对于同步块的实现使用了monitorenter和monitorexit指令，而同步方法则 是依靠方法修饰符上的ACC_SYNCHRONIZED来完成的。无论采用哪种方式，其本质是对一 个对象的监视器(monitor)进行获取，而这个获取过程是排他的，也就是同一时刻只能有一个 线程获取到由synchronized所保护对象的监视器。 任意一个对象都拥有自己的监视器，当这个对象由同步块或者这个对象的同步方法调用 时，执行方法的线程必须先获取到该对象的监视器才能进入同步块或者同步方法，而没有获 取到监视器(执行该方法)的线程将会被阻塞在同步块和同步方法的入口处，进入BLOCKED 状态。 等待/通知机制（wait / notify） 等待/通知机制，是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B 调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而 执行后续操作。上述两个线程通过对象O来完成交互，而对象上的wait()和notify/notifyAll()的 关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package _2不同的生产者消费者模式;/** * 线程之间的通信问题：两个线程交替执行A B操作同一个变量+1，-1* */public class A { public static void main(String[] args) { Data data = new Data(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.increment(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;A&quot;).start(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.decrement(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;B&quot;).start(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.increment(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;C&quot;).start(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.decrement(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;D&quot;).start(); }}//1.判断是否需要等待//2.执行业务//3.通知其他线程class Data{ //数字，资源类 private int num = 0; //+1 public synchronized void increment() throws InterruptedException { while (num != 0) { //用if会出现虚假唤醒现象 this.wait(); } num++; System.out.println(Thread.currentThread().getName()+&quot;=====&quot;+num); //通知其他线程，+1完毕 this.notifyAll(); } //-1 public synchronized void decrement() throws InterruptedException { while (num == 0) { this.wait(); } num--; System.out.println(Thread.currentThread().getName()+&quot;=====&quot;+num); this.notifyAll(); }}复制代码 Thread.join()方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package server.doc.thread;public class JoinTest implements Runnable { @Override public void run() { System.out.println(&quot;join thread demo&quot;); } public static void main(String[] args) throws InterruptedException { System.out.println(&quot;main thread start...&quot;); JoinTest joinTest = new JoinTest(); Thread thread = new Thread(joinTest); thread.setName(&quot;joinTest thread&quot;); thread.start(); thread.join(); System.out.println(&quot;main thread end&quot;); }}//没有join的时候：main thread start...main thread endjoin thread demo//有join的时候main thread start...join thread demomain thread end也就是说：当main线程去调用t.join()是，会将自己当前线程阻塞，等到t线程执行完成到达完结状态，main线程才可以继续执行复制代码//join 源码public final synchronized void join(long millis) throws InterruptedException { long base = System.currentTimeMillis(); long now = 0; // 首先校验参数是否合法 if (millis &lt; 0) { throw new IllegalArgumentException(&quot;timeout value is negative&quot;); } // 如果join方法没有参数，则相当于直接调用wait方法 if (millis == 0) { while (isAlive()) { wait(0); } } else { while (isAlive()) {//判断当前的线程是否处于活动状态。什么是活动状态呢？活动状态就是线程已经启动且尚未终止 long delay = millis - now; if (delay &lt;= 0) { break; } wait(delay); now = System.currentTimeMillis() - base; } } }复制代码 ThreadLocal（后续讲解）","link":"/2021/05/06/Java%E5%B9%B6%E5%8F%91%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80-%E4%B8%8A/"},{"title":"Java并发理论基础-下","text":"Java并发理论基础下章主要描述了以下内容 Lock接口实现的锁 常见的并发容器 常见的并发工具类 线程池 Lock接口synchronized在1.6之后做了很多的优化，效率提高了很多，但是还有很多问题是synchronized无法解决的，因此Lock接口及其实现方法就出现了： 能够响应中断。synchronized 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程。但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有机会释放曾经持有的锁 A。这样就破坏了不可抢占条件了。 支持超时。如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。 非阻塞地获取锁。如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。 API接口方法123456void lock(); //获取锁，调用该方法的线程会获得锁，获得锁之后从该方法返回void lockInterruptibly() throws InterruptedException; //可中断的获得锁boolean tryLock(); //尝试非阻塞的获取锁，调用该方法后立即返回，如果能获取返回true，否则返回falseboolean tryLock(long time, TimeUnit unit) throws InterruptedException; //超时的获取锁void unlock(); //释放锁Condition newCondition(); //获取等待通知组件，该组件和当前锁绑定，当前线程获得了锁之后才能调用组件的wait方法释放锁 Lock的一般使用实例1234567Lock lock = new ReentrantLock(); lock.lock(); try { //业务逻辑 }finally { lock.unlock();//在finally块中释放锁，目的是保证在获取到锁之后，最终能够被释放。 } synchronized和ReentrantLock的区别 synchronized是JVM内建的同步机制，是一个关键字，ReentrantLock是一个类。 ReentrantLock可以实现公平锁，可以自定义条件，可以定义超时时间，需要显式的释放锁，而synchronized只能是非公平锁。 每一个lock操作，为了保证锁的释放，最好在finally中显式的unlock lock只适用于代码块，而synchronized可以用来修饰方法，代码块 在Java6之前，synchronized完全依靠操作系统的互斥锁来实现，需要进行用户态和内核态的切换，所以开销较大，但随着一系列的锁优化，synchronized的性能也越来越好了 队列同步器AQSAQS的全称是AbstractQueuedSynchronizer，它的定位是为Java中几乎所有的锁和同步器提供一个基础框架。 AQS是基于FIFO的队列实现的，并且内部维护了一个volatile修饰的状态变量state，通过原子更新这个状态变量state即可以实现加锁解锁操作。 AQS的源码解析 主要内部类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647static final class Node { //初始化两个节点引用 static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; static final int CANCELLED = 1; // 标识线程已取消 static final int SIGNAL = -1; // 标识后继节点需要唤醒 static final int CONDITION = -2; // 标识线程等待在一个条件上 static final int PROPAGATE = -3; // 标识后面的共享锁需要无条件的传播（共享锁需要连续唤醒读的线程） volatile int waitStatus; //// 当前节点保存的线程对应的等待状态 volatile Node prev; volatile Node next; volatile Thread thread; // 当前节点保存的线程 Node nextWaiter; final boolean isShared() { return nextWaiter == SHARED; } final Node predecessor() throws NullPointerException { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } Node() { // Used to establish initial head or SHARED marker } Node(Thread thread, Node mode) { // Used by addWaiter this.nextWaiter = mode; this.thread = thread; } Node(Thread thread, int waitStatus) { // Used by Condition this.waitStatus = waitStatus; this.thread = thread; } } 主要属性 123456789101112131415161718 private transient volatile Node head; //维护一个头节点和尾节点的引用 private transient volatile Node tail; private volatile int state; //同步状态，用volatile修饰 //获取当前同步状态 protected final intgetState() { return state; } //设置新的同步状态 protected final void setState(int newState) { state = newState;} //通过unsafe类的CAS修改同步状态 protected final boolean compareAndSetState(int expect, int update) { // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } 子类需要实现的方法–模版方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495//提供给子类重写，独占式的获取同步状态，实现该方法需要查询当前状态并判断是否符合预期，然后用CAS来设置同步状态 protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } //提供给子类重写，独占式的释放同步状态，等待的线程将有机会获取同步状态 protected boolean tryRelease(int arg) { throw new UnsupportedOperationException(); } //共享式的获取同步状态，返回值大于0表示成功 protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException(); } //共享式的释放同步状态 protected boolean tryReleaseShared(int arg) { throw new UnsupportedOperationException(); } //当前同步器是否在独占模式下被线程占用 protected boolean isHeldExclusively() { throw new UnsupportedOperationException(); } //独占式获取同步状态，获取成功则返回，否则进入同步队列等待 public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } //和上面这个方法相同，但是响应中断 public final void acquireInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); } //在上面的方法中增加了时间限制 public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout); } //独占式释放同步状态，释放后唤醒同步队列中的第一个节点 public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } //共享式的获取同步状态，主要区别是同一时间可以有多个线程获取到同步状态 public final void acquireShared(int arg) { if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); } //和上面相同，响应中断 public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); } public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); return tryAcquireShared(arg) &gt;= 0 || doAcquireSharedNanos(arg, nanosTimeout); } //共享式的释放同步状态 public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; } 节点加入等待队列流程同步器将节点加入到同步队列的过程：加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法:**compareAndSetTail(Node expect,Node update)**，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式 与之前的尾节点建立关联。 1234private final boolean compareAndSetTail(Node expect, Node update) { return unsafe.compareAndSwapObject(this, tailOffset, expect, update);} 设置首节点的过程设置首节点的过程：同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。 设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节 点设置成为原首节点的后继节点并断开原首节点的next引用即可。 acquire流程分析123456AQS ----&gt; acquire()public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 123456789101112131415161718192021222324252627282930313233343536373839404142tryAcquire 方法针对公平锁和非公平锁有着不同的实现，总的来说是保证线程安全的获取同步状态 //Fair version of tryAcquire. Don't grant access unless recursive call or no waiters or is first. protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; //hasQueuedPredecessors 是公平锁和非公平锁的区别 compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //可重入锁的实现 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } 如果tryAcquire不能获取锁： 123456789101112131415161718192021222324252627282930313233343536373839404142434445//构造新的尾节点，通过CAS来放入队列尾部//Creates and enqueues node for current thread and given mode.Params://mode – Node.EXCLUSIVE for exclusive, Node.SHARED for sharedReturns://the new nodeprivate Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); ////如果多个线程获取同步状态失败，并发的添加到list，也许会顺序混乱，通过CAS变 得“串行化”了 return node; }/*Inserts node into queue, initializing if necessary. See picture above.Params:node – the node to insertReturns:node's predecessor*/private Node enq(final Node node) { for (;;) { ////通过“死循环”来保证节点的正确添加 Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; //只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线 程不断地尝试设置 if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 12345678910111213141516171819202122//acquireQueued --- 节点进入同步队列之后，就进入了一个自旋的过程，每个节点(或者说每个线程)都在自 省地观察，当条件满足，获取到了同步状态，就可以从这个自旋过程中退出，否则依旧留在这 个自旋过程中(并会阻塞节点的线程):final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { //死循环自旋的过程 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } acquire方法调用流程： 前驱节点为头节点且能够获取同步状态的判断条件和线程进入等待状态是获 取同步状态的自旋过程。当同步状态获取成功之后，当前线程从acquire(int arg)方法返回，如果 对于锁这种并发组件而言，代表着当前线程获取了锁。 当前线程获取同步状态并执行了相应逻辑之后，就需要释放同步状态，使得后续节点能 够继续获取同步状态。通过调用同步器的release(int arg)方法可以释放同步状态，该方法在释 放了同步状态之后，会唤醒其后继节点(进而使后继节点重新尝试获取同步状态)。 12345678910@ReservedStackAccess public final boolean release(int arg) { if (tryRelease(arg)) { //tryRelease针对公平锁和非公平锁也有不同的实现 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } 重入锁重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞，该特性的实现需要解决以下两个问题。 线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。 锁的最终释放。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。 12345678910111213141516171819protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { //如果当前线程就是拥有锁的线程 int nextc = c + acquires; //则共享变量++ if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } 读写锁读写锁，并不是 Java 语言特有的，而是一个广为使用的通用技术，所有的读写锁都遵守以下三条基本原则： 允许多个线程同时读共享变量； 只允许一个线程写共享变量； 如果一个写线程正在执行写操作，此时禁止读线程读共享变量。 读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升。 LockSupport类LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread) 方法来唤醒一个被阻塞的线程： 1234567891011public static void park(Object blocker) { //阻塞当前线程 Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null); }public static void unpark(Thread thread) { //唤醒当前线程 if (thread != null) UNSAFE.unpark(thread); } Condition接口等待通知模式：任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、 wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式 Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式 新版生产者和消费者一般都会将Condition对象作为成员变量。当调用await()方法后，当前线程会释放锁并在此等待，而其他线程调用Condition对象的signal()方法，通知当前线程后，当前线程才从await()方法返回，并且在返回前已经获取了锁 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class SharedDate{ //共享资源类 private int num = 0; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void increment(){ lock.lock(); try { while (num != 0) condition.await(); //1. 判断释放满足条件，注意用while num++; //2. 业务逻辑 System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); condition.signal(); //3. 唤醒其他线程 } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } public void decrement(){ lock.lock(); try { while (num == 0) condition.await(); num--; System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); condition.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }}/** 需求：两个线程操作一个初始值为0的变量，一个线程操作变量+1，另一个线程操作变量-1。操作10次后变量依旧为0 * */public class ConditionDemo { public static void main(String[] args) { // 线程操作资源类 SharedDate sharedDate = new SharedDate(); Thread a = new Thread(()-&gt;{ for (int i = 0; i &lt; 5; i++) { sharedDate.increment(); } },&quot;A&quot;); Thread b = new Thread(()-&gt;{ for (int i = 0; i &lt; 5; i++) { sharedDate.decrement(); } },&quot;B&quot;); a.start(); b.start(); } } 精确通知不同的等待者12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485class SharedDate{ //共享资源类 private int num = 1; //1 A ，2 B ， 3 C private Lock lock = new ReentrantLock(); private Condition c1 = lock.newCondition(); //多个条件实现精确通知 private Condition c2 = lock.newCondition(); private Condition c3 = lock.newCondition(); public void print2(int a){ lock.lock(); try { while (num != 1) c1.await(); for (int i = 0; i &lt; a; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); } num = 2; //要修改状态位，以此来唤醒不同的线程 c2.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } public void print4(int a){ lock.lock(); try { while (num != 2) c2.await(); for (int i = 0; i &lt; a; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); } num = 3;//要修改状态位，以此来唤醒不同的线程 c3.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } public void print8(int a){ lock.lock(); try { while (num != 3) c3.await(); for (int i = 0; i &lt; a; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); } num = 1;//要修改状态位，以此来唤醒不同的线程 c1.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }}/** 需求：三个线程依次打印1，2，3。其中A线程打印2次，B线程打印4次，C线程打印6次** */public class ConditionDemo { public static void main(String[] args) { // 线程操作资源类 SharedDate sharedDate = new SharedDate(); Thread a = new Thread(()-&gt;{ sharedDate.print2(2); },&quot;A&quot;); Thread b = new Thread(()-&gt;{ sharedDate.print4(4); },&quot;B&quot;); Thread c = new Thread(()-&gt;{ sharedDate.print8(8); },&quot;C&quot;); a.start(); b.start(); c.start(); }} Java并发容器CopyOnWriteArrayListCopyOnWrite，顾名思义就是写的时候会将共享变量新复制一份出来，这样做的好处是读操作完全无锁 CopyOnWriteArrayList 内部维护了一个数组，成员变量 array 就指向这个内部数组，所有的读操作都是基于 array 进行的。 如果在遍历 array 的同时，还有一个写操作，例如增加元素，CopyOnWriteArrayList 是如何处理的呢？CopyOnWriteArrayList 会将 array 复制一份，然后在新复制处理的数组上执行增加元素的操作，执行完之后再将 array 指向这个新的数组。通过下图你可以看到，读写是可以并行的，遍历操作一直都是基于原 array 执行，而写操作则是基于新 array 进行。 ConcurrentHashMap1.1 为什么要使用ConcurrentHashMap hashMap线程不安全，hashtable效率低下 ConcurrentHashMap的锁分段技术可有效提升并发访问率，首先将数据分成一段一段地存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问 1.2 结构![image-20210502103840847](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210502103840847.png) ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁（ReentrantLock），在ConcurrentHashMap里扮演锁的角色；HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似，是一种数组和链表结构。一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得与它对应的Segment锁 1.3 初始化1.4 定位segment1.5 常用的方法操作2. ConcurrentLinkedQueue3. Java中的阻塞队列3.1 什么是阻塞队列阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。 1）支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。 2）支持阻塞的移除方法：意思是在队列为空时，获取元素的线程会等待队列变为非空。 阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器 3.2 常见的阻塞队列种类JDK 7提供了7个阻塞队列，如下。 ·ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。 ·LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。 ·PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。 ·DelayQueue：一个使用优先级队列实现的无界阻塞队列。 ·SynchronousQueue：一个不存储元素的阻塞队列。 ·LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 ·LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。 3.3 阻塞队列的实现原理ArrayBlockingQueue使用了Condition来实现 1234567891011121314151617181920212223242526272829303132333435363738394041/** Condition for waiting takes */private fnal Condition notEmpty;/** Condition for waiting puts */private fnal Condition notFull;public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); }//put方法public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == items.length) notFull.await(); enqueue(e); } finally { lock.unlock(); } }//take public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) notEmpty.await(); return dequeue(); } finally { lock.unlock(); } } 第七部分、13个原子操作类1. 原子更新基本类型3个·AtomicBoolean：原子更新布尔类型。 ·AtomicInteger：原子更新整型。 ·AtomicLong：原子更新长整型。 1.1 实现原理基于CAS（compare-and-swap）技术来实现的，所谓CAS，表征的是一些列操作的集合，获取当前数值，进行一些运算，利用CAS指令试图进行更新。如果当前数值未变，代表没有其他线程进行并发修改，则成功更新。否则，可能出现不同的选择，要么进行重试，要么就返回一个成功或者失败的结果。 1234567891011121314151617181920public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); //使用了unsafe类 private static final long valueOffset; private volatile int value; //volatile修饰的变量 static { try { valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } public AtomicInteger(int initialValue) { value = initialValue; } public AtomicInteger() { } 12345678910111213141516public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1); //调用的是unsafe类中的方法实现原子自增的 }public final int getAndAddInt(Object o, long offset, int delta) { int v; do { v = getIntVolatile(o, offset); } while (!compareAndSwapInt(o, offset, v, v + delta)); return v; }//cas底层是unsafe类中的本地方法，依赖于CPU提供的特定指令public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); 1.2 CAS的问题 CAS也并不是没有副作用，试想，其常用的失败重试机制，隐含着一个假设，即竞争情况是短暂的。大多数应用场景中，确实大部分重试只会发生一次就获得了成功，但是总是有意外情况，所以在有需要的时候，还是要考虑限制自旋的次数，以免过度消耗CPU。 另外一个就是著名的ABA问题，这是通常只在lock-free算法下暴露的问题。我前面说过CAS是在更新时比较前值，如果对方只是恰好相同，例如期间发生了 A -&gt; B -&gt; A的更新，仅仅判断数值是A，可能导致不合理的修改操作。针对这种情况，Java提供了AtomicStampedReference工具类，通过为引用建立类似版本号（stamp）的方式，来保证CAS的正确性 2. 原子更新数组·AtomicIntegerArray：原子更新整型数组里的元素。 ·AtomicLongArray：原子更新长整型数组里的元素。 ·AtomicReferenceArray：原子更新引用类型数组里的元素。 ·AtomicIntegerArray类主要是提供原子的方式更新数组里的整型，其常用方法如下。 3.原子更新引用类型4. 原子更新字段类第八部分、并发工具类1.倒计时器CountDownLatchCountDownLatch允许一个或多个线程等待其他线程完成操作。 运动员进行跑步比赛时，假设有 6 个运动员参与比赛，裁判员在终点会为这 6 个运动员分别计时，可以想象没当一个运动员到达终点的时候，对于裁判员来说就少了一个计时任务。直到所有运动员都到达终点了，裁判员的任务也才完成。这 6 个运动员可以类比成 6 个线程，当线程调用 CountDownLatch.countDown 方法时就会对计数器的值减一，直到计数器的值为 0 的时候，裁判员（调用 await 方法的线程）才能继续往下执行。 1.1 方法解析12345//整型数 N，之后调用 CountDownLatch 的countDown方法会对 N 减一，知道 N 减到 0 的时候，当前调用await方法的线程继续执行。public CountDownLatch(int count) { if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync = new Sync(count); } public void await() throws InterruptedException：调用await()方法的线程会被挂起，等待直到count值为0再继续执行。 public boolean await(long timeout, TimeUnit unit) throws InterruptedException：同await()，若等待timeout时长后，count值还是没有变为0，不再等待，继续执行。时间单位如下常用的毫秒、天、小时、微秒、分钟、纳秒、秒。 public void countDown()： count值递减1. public long getCount()：获取当前count值。 public String toString()：重写了toString()方法，多打印了count值，具体参考源码。 1.2 使用实例 创建CountDownLatch并设置计数器值。 启动多线程并且调用CountDownLatch实例的countDown()方法。 主线程调用 await() 方法，这样主线程的操作就会在这个方法上阻塞，直到其他线程完成各自的任务，count值为0，停止阻塞，主线程继续执行。 123456789101112131415161718192021222324252627282930313233343536373839404142public class CountDownLatchDemo { //线程数 private static int N = 10; // 单位：min private static int countDownLatchTimeout = 5; public static void main(String[] args) { //创建CountDownLatch并设置计数值，该count值可以根据线程数的需要设置 CountDownLatch countDownLatch = new CountDownLatch(N); //创建线程池 ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; N; i++) { cachedThreadPool.execute(() -&gt; { try { System.out.println(Thread.currentThread().getName() + &quot; do something!&quot;); } catch (Exception e) { System.out.println(&quot;Exception: do something exception&quot;); } finally { //该线程执行完毕-1 countDownLatch.countDown(); } }); } System.out.println(&quot;main thread do something-1&quot;); try { countDownLatch.await(countDownLatchTimeout, TimeUnit.MINUTES); } catch (InterruptedException e) { System.out.println(&quot;Exception: await interrupted exception&quot;); } finally { System.out.println(&quot;countDownLatch: &quot; + countDownLatch.toString()); } System.out.println(&quot;main thread do something-2&quot;); //若需要停止线程池可关闭;// cachedThreadPool.shutdown(); }} 2.循环栅栏：CyclicBarrier 开运动会时，会有跑步这一项运动，我们来模拟下运动员入场时的情况，假设有 6 条跑道，在比赛开始时，就需要 6 个运动员在比赛开始的时候都站在起点了，裁判员吹哨后才能开始跑步。跑道起点就相当于“barrier”，是临界点，而这 6 个运动员就类比成线程的话，就是这 6 个线程都必须到达指定点了，意味着凑齐了一波，然后才能继续执行，否则每个线程都得阻塞等待，直至凑齐一波即可。cyclic 是循环的意思，也就是说 CyclicBarrier 当多个线程凑齐了一波之后，仍然有效，可以继续凑齐下一波 2.1 常用方法12345678910//等到所有的线程都到达指定的临界点await() throws InterruptedException, BrokenBarrierException//与上面的await方法功能基本一致，只不过这里有超时限制，阻塞等待直至到达超时时间为止await(long timeout, TimeUnit unit) throws InterruptedException,BrokenBarrierException, TimeoutException//获取当前有多少个线程阻塞等待在临界点上int getNumberWaiting()//用于查询阻塞等待的线程是否被中断boolean isBroken() 2.2 使用实例123456789101112131415161718192021222324public class CyclicBarrierDemo { //指定必须有6个运动员到达才行 private static CyclicBarrier barrier = new CyclicBarrier(6, () -&gt; { System.out.println(&quot;所有运动员入场，裁判员一声令下！！！！！&quot;); }); public static void main(String[] args) { System.out.println(&quot;运动员准备进场，全场欢呼............&quot;); ExecutorService service = Executors.newFixedThreadPool(6); for (int i = 0; i &amp;lt; 6; i++) { service.execute(() -&amp;gt; { try { System.out.println(Thread.currentThread().getName() + &quot; 运动员，进场&quot;); barrier.await(); System.out.println(Thread.currentThread().getName() + &quot; 运动员出发&quot;); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }); }}} 2.3 CyclicBarrier 和CountDownLatch 的区别 CountDownLatch是不可以重置的，所以无法重用；而CyclicBarrier则没有这种限制，可以重用。 CountDownLatch的基本操作组合是countDown/await。调用await的线程阻塞等待countDown足够的次数，不管你是在一个线程还是多个线程里countDown，只要次数足够即可。所以就像Brain Goetz说过的，CountDownLatch操作的是事件。 CyclicBarrier的基本操作组合，则就是await，当所有的伙伴（parties）都调用了await，才会继续进行任务，并自动进行重置。注意，正常情况下，CyclicBarrier的重置都是自动发生的，如果我们调用reset方法，但还有线程在等待，就会导致等待线程被打扰，抛出BrokenBarrierException异常。CyclicBarrier侧重点是线程，而不是调用事件，它的典型应用场景是用来等待并发线程结束。 3.控制并发线程数的SemaphoreSemaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源 第九部分、线程池1. 为什么要使用线程池第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 第三：提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。但是，要做到合理利用线程池，必须对其实现原理了如指掌。 2. 线程池的实现原理2.1五种不同的标准线程池Executors目前提供了5种不同的线程池创建配置： newCachedThreadPool()，它是一种用来处理大量短时间工作任务的线程池，具有几个鲜明特点：它会试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置的时间超过60秒，则被终止并移出缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用SynchronousQueue作为工作队列。 newFixedThreadPool(int nThreads)，重用指定数目（nThreads）的线程，其背后使用的是无界的工作队列，任何时候最多有nThreads个工作线程是活动的。这意味着，如果任务数量超过了活动队列数目，将在工作队列中等待空闲线程出现；如果有工作线程退出，将会有新的工作线程被创建，以补足指定的数目nThreads。 newSingleThreadExecutor()，它的特点在于工作线程数目被限制为1，操作一个无界的工作队列，所以它保证了所有任务的都是被顺序执行，最多会有一个任务处于活动状态，并且不允许使用者改动线程池实例，因此可以避免其改变线程数目。 newSingleThreadScheduledExecutor()和newScheduledThreadPool(int corePoolSize)，创建的是个ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程。 newWorkStealingPool(int parallelism)，这是一个经常被人忽略的线程池，Java 8才加入这个创建方法，其内部会构建ForkJoinPool，利用Work-Stealing算法，并行地处理任务，不保证处理顺序。 2.2 创建七大参数 corePoolSize：核心线程数 maximumPoolSize：最大线程数 keepAliveTime：线程存活时间 TimeUnit：存活时间的单位 workQueue：工作队列，必须是阻塞队列 ThreadFactory ：创建线程的工厂 RejectedExecutionHandler：拒绝执行的策略 2.3 四大拒绝策略·AbortPolicy：直接抛出异常。 ·CallerRunsPolicy：只用调用者所在线程来运行任务。 ·DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。 ·DiscardPolicy：不处理，丢弃掉。 Ps：可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。如记录日志或持久化存储不能处理的任务。 2.4 任务处理流程![image-20210502114404422](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210502114404422.png) 2.5 提交任务submit和execute execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。 execute()方法输入的任务是一个Runnable类的实例。 submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。 2.6 线程池的大小选择策略 如果是计算型任务，说明CPU是一种稀缺的资源，线程太多会导致上下文切换，所以线程数一般为按照CPU核的数目N或者N+1； 如果是IO密集型任务，线程数 = CPU核数 × （1 + 平均等待时间/平均工作时间） 第十部分、Executor框架1. Executor框架简介1.1Executor框架的两级调度模型 在HotSpot VM的线程模型中，Java线程（java.lang.Thread）被一对一映射为本地操作系统线 程。Java线程启动时会创建一个本地操作系统线程；当该Java线程终止时，这个操作系统线程也会被回收。操作系统会调度所有线程并将它们分配给可用的CPU。 在上层，Java多线程程序通常把应用分解为若干个任务，然后使用用户级的调度器（Executor框架）将这些任务映射为固定数量的线程；在底层，操作系统内核将这些线程映射到硬件处理器上: ![image-20210503091113831](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210503091113831.png) 1.2 三大组成部分 任务。包括被执行任务需要实现的接口：Runnable接口或Callable接口。 任务的执行。包括任务执行机制的核心接口Executor，以及继承自Executor的 ExecutorService接口。Executor框架有两个关键类实现了ExecutorService接口 （ThreadPoolExecutor和ScheduledThreadPoolExecutor）。 异步计算的结果。包括接口Future和实现Future接口的FutureTask类。 ![image-20210503091241378](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210503091241378.png) 2. ThreadPoolExecutor详解Executor框架最核心的类是ThreadPoolExecutor，它是线程池的实现类，主要由下列4个组件构成。 ·corePool：核心线程池的大小。 ·maximumPool：最大线程池的大小。 ·BlockingQueue：用来暂时保存任务的工作队列。 ·RejectedExecutionHandler：当ThreadPoolExecutor已经关闭或ThreadPoolExecutor已经饱和 时（达到了最大线程池大小且工作队列已满），execute()方法将要调用的Handler。 2.1 FixedThreadPoolFixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads。 123456public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory); } keepAliveTime设置为0L，意味着多余的空闲线程会被立即终止 FixedThreadPool使用无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为 Integer.MAX_VALUE）。使用无界队列作为工作队列会对线程池带来如下影响: 1）当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中 的线程数不会超过corePoolSize。 2）由于1，使用无界队列时maximumPoolSize将是一个无效参数。 3）由于1和2，使用无界队列时keepAliveTime将是一个无效参数。 4）由于使用无界队列，运行中的FixedThreadPool（未执行方法shutdown()或 shutdownNow()）不会拒绝任务（不会调用RejectedExecutionHandler.rejectedExecution方法）。 2.2 SingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); } SingleThreadExecutor的corePoolSize和maximumPoolSize被设置为1。其他参数与 FixedThreadPool相同。SingleThreadExecutor使用无界队列LinkedBlockingQueue作为线程池的工 作队列（队列的容量为Integer.MAX_VALUE）。SingleThreadExecutor使用无界队列作为工作队列 对线程池带来的影响与FixedThreadPool相同. 2.3 CachedThreadPool12345public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); } CachedThreadPool的corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置为 Integer.MAX_VALUE，即maximumPool是无界的。这里把keepAliveTime设置为60L，意味着 CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被 终止。 如果主线程提交任务的速度高于 maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下， CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。","link":"/2021/05/07/Java%E5%B9%B6%E5%8F%91%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80-%E4%B8%8B/"},{"title":"MySQL（二）存储引擎","text":"本篇讲述了MySQL的逻辑分层和存储引擎InnoDB MySQL的逻辑分层插件式的存储引擎架构将查询处理和其它的系统任务以及数据的存储提取相分离。 这种架构可以根据业务的需求和实际需要选择合适的存储引擎。 连接层：最上层是一些客户端和连接服务。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。 服务层：第二层服务层，主要完成大部分的核心服务功能， 包括查询解析、分析、优化、缓存、以及所有的内置函数，所有跨存储引擎的功能也都在这一层实现，包括触发器、存储过程、视图等 引擎层：第三层存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取 存储层：第四层为数据存储层，主要是将数据存储在运行于该设备的文件系统之上，并完成与存储引擎的交互 一条SQL语句的执行流程 客户端请求 连接器（验证用户身份，给予权限） 查询缓存（存在缓存则直接返回，不存在则执行后续操作，mysql8.0之后取消了缓存） 分析器（对SQL进行词法分析和语法分析操作 优化器（主要对执行的sql优化选择最优的执行方案方法） 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口） 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果） InnoDB存储引擎InnoDB 现在是 MySQL 默认的存储引擎，支持事务、行级锁定和外键 InnoDB体系结构InnoDB存储引擎中有很多内存块，可以认为这些内存块组成了一个大的内存池，负责如下工作： 维护所有进程/线程需要访问的多个内部数据结构 缓存磁盘上的数据 重做日志redo log 缓冲 ​ 后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存是最近的数据。此外将已经修改后的数据文件刷新到磁盘中去，同时保证在发生异常情况下可以恢复到正常运行状态。 后台线程的分类Master线程一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性。包括脏页的刷新、合并插入缓存、UNDO页的回收等等 IO线程共有四种IO线程： insert buffer thread log thread read thread ， 4个 write thread，4个 12345678910111213141516171819mysql&gt; show engine innodb status; //可以查看InnoDB状态FILE I/O--------I/O thread 0 state: waiting for i/o request (insert buffer thread)I/O thread 1 state: waiting for i/o request (log thread)I/O thread 2 state: waiting for i/o request (read thread)I/O thread 3 state: waiting for i/o request (read thread)I/O thread 4 state: waiting for i/o request (read thread)I/O thread 5 state: waiting for i/o request (read thread)I/O thread 6 state: waiting for i/o request (write thread)I/O thread 7 state: waiting for i/o request (write thread)I/O thread 8 state: waiting for i/o request (write thread)I/O thread 9 state: waiting for i/o request (write thread)Pending normal aio reads: [0, 0, 0, 0] , aio writes: [0, 0, 0, 0] , ibuf aio reads:, log i/o's:, sync i/o's:Pending flushes (fsync) log: 0; buffer pool: 0900 OS file reads, 1594 OS file writes, 930 OS fsyncs0.00 reads/s, 0 avg bytes/read, 0.00 writes/s, 0.00 fsyncs/s Purge Thread事务被提交之后，其使用的undolog可能不再需要了，因此purge thread会回收已经使用并分配的undo页。 Page Cleaner Thread将脏页中的刷新操作放入到单独的线程中来完成，减轻Master Thread的工作对用户查询线程的阻塞。 内存缓冲池缓冲池简单来说就是一块内存区域，通过内存的速度来弥补CPU和磁盘之间速度的差异。 在数据库中读取页的操作，首先将从磁盘读到的页存放在缓冲池中，下次再读相同的页时，首先判断该页是否在缓冲池中，如果在则命中，否则从磁盘中进行读取。 在数据库中修改页的操作，首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上（通过一种checkpoint到机制触发）。 1234567891011121314mysql&gt; select version();+-----------+| version() |+-----------+| 8.0.23 |+-----------+1 row in set (0.00 sec)mysql&gt; show variables like 'innodb_buffer_pool_size';+-------------------------+-----------+| Variable_name | Value |+-------------------------+-----------+| innodb_buffer_pool_size | 134217728 |+-------------------------+-----------+1 row in set (0.01 sec) 缓冲池中存放着各种类型的页： LRU列表、Free列表、Flush列表这么多页使用优化之后的LRU算法来进行管理的。 123456789101112131415161718192021mysql&gt; show engine innodb status;----------------------BUFFER POOL AND MEMORY----------------------Total large memory allocated 136970240Dictionary memory allocated 500792Buffer pool size 8191 //8191个页，每个页16KB = 128GFree buffers 7079 // free列表中的页数Database pages 1107 // LRU列表中的页数Old database pages 423Modified db pages 0 //Flush 脏页列表的页数，FLUSH列表即为脏页列表。Pending reads 0Pending writes: LRU 0, flush list 0, single page 0Pages made young 1, not young 0 //Pages made young 表示LRU列表中页移动到前端的次数0.00 youngs/s, 0.00 non-youngs/s //表示每秒上面两个操作的次数Pages read 899, created 208, written 9350.00 reads/s, 0.00 creates/s, 0.00 writes/sNo buffer pool page gets since the last printoutPages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/sLRU len: 1107, unzip_LRU len: 0 //可以压缩页，unzip_LRU列表管理着非16KB的页I/O sum[0]:cur[0], unzip sum[0]:cur[0] LRU列表中的页被修改之后，称该页为脏页（缓冲池中的页和磁盘上的页出现了数据不一致）。 重做日志缓冲从图2-2可以看到，InnoDB 存储引擎的内存区域除了有缓冲池外，还有重做日志缓冲(redo log buffer)。InnoDB 存储引擎首先将重做日志信息先放入到这个缓冲区，然后按一定频率将其刷新到重做日志文件。重做日志缓冲一般不需要设置得很大，因为- -般情况下每一秒钟会将重做日志缓冲刷新到日志文件，因此用户只需要保证每秒产生的事务量在这个缓冲大小之内即可。该值可由配置参数innodb_ log_ buffer_ size控制，默认为8MB: 123456789mysql&gt; show variables like 'innodb_log_buffer_size';+------------------------+----------+| Variable_name | Value |+------------------------+----------+| innodb_log_buffer_size | 16777216 |+------------------------+----------+1 row in set (0.00 sec)mysql&gt; 重做日志在下列三种情况下会将重做日志缓冲中的内容刷新到外部磁盘的重做日志文件中: MasterThread每一秒将重做日志缓冲刷新到重做日志文件; 每个事务提交时会将重做日志缓冲刷新到重做日志文件; 当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲刷新到重做日志文件。 Checkpoint技术Checkpoint技术就是将缓存池中脏页在某个时间点刷回到磁盘的操作 一个DML语句，进行数据update或delete 操作时，此时改变了缓冲池页中的记录，此时因为缓冲池页的数据比磁盘的新，此时的页就叫做脏页。 不管怎样，总会后的内存页数据需要刷回到磁盘里，这里就涉及几个问题： 若每次一个页发生变化，就将新页的版本刷新到磁盘，那么这个开销是非常大的 若热点数据集中在某几个页中，那么数据库的性能将变得非常差 如果在从缓冲池将页的新版本刷新到磁盘时发生了宕机，那么数据就不能恢复了 — Write Ahead Log Write Ahead Log（预写式日志）WAL策略解决了刷新页数据到磁盘时发生宕机而导致数据丢失的问题，它是关系数据库系统中用于提供原子性和持久性（ACID 属性中的两个）的一系列技术。 WAL策略核心点就是redo log，每当有事务提交时，先写入 redo log（重做日志），在修改缓冲池数据页，这样当发生掉电之类的情况时系统可以在重启后继续操作。 按理说有了WAL策略，我们就可以高枕无忧了。但其问题点又出现在redo log上面： redo log 不可能是无限大的，不能没完没了的存储我们的数据等待一起刷新到磁盘 在数据库怠机恢复时，如果redo log 太大的话恢复的代价也是非常大的 所以为了解决脏页的刷新性能，脏页应该在什么时间、什么情况下进行脏页的刷新就用到了Checkpoint技术。 Checkpoint 的目的1、缩短数据库的恢复时间 当数据库怠机恢复时，不需要重做所有的日志信息。因为Checkpoint前的数据页已经刷回到磁盘了。只需要Checkpoint后的redo log进行恢复就好了。 2、缓冲池不够用时，将脏页刷新到磁盘 当缓冲池空间不足时，根据LRU算法会溢出最近最少使用的页，若此页为脏页，那么需要强制执行Checkpoint，将脏页也就是页的新版本刷回磁盘。 3、redo log不可用时，刷新脏页 如图redo log 的不可用是因为当前数据库对其设计都是循环使用的，所以其空间并不是无限大。 当redo log被写满, 因为此时系统不能接受更新, 所有更新语句都会被堵住。 此时必须强制产生Checkpoint需要将 write pos 向前推进，推进范围内的脏页都需要刷新到磁盘 Checkpoint 的种类Checkpoint发生的时间、条件及脏页的选择等都非常复杂。 Checkpoint 每次刷新多少脏页到磁盘？ Checkpoint每次从哪里取脏页？ Checkpoint 什么时间被触发？ 面对上面的问题，InnoDB存储引擎内部为我们提供了两种Checkpoint： Sharp Checkpoint：发生在数据库关闭时将所有的脏页都刷新回磁盘，这是默认的工作方式，参数innodb_fast_shutdown=1 Fuzzy Checkpoint：InnoDB存储引擎内部使用这种模式,只刷新一部分脏页，而不是刷新所有的脏页回磁盘 FuzzyCheckpoint发生的情况 Master Thread Checkpoint 差不多以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘。 这个过程是异步的，即此时InnoDB存储引擎可以进行其他的操作，用户查询线程不会阻塞 FLUSH_LRU_LIST Checkpoint 因为LRU列表要保证一定数量的空闲页可被使用，所以如果不够会从尾部移除页，如果移除的页有脏页，就会进行此Checkpoint。 5.6版本后，这个Checkpoint放在了一个单独的Page Cleaner线程中进行，并且用户可以通过参数innodb_lru_scan_depth控制LRU列表中可用页的数量，该值默认为1024 Async/Sync Flush Checkpoint 指的是redo log文件不可用的情况，这时需要强制将一些页刷新回磁盘，而此时脏页是从脏页列表中选取的 5.6版本后不会阻塞用户查询 Dirty Page too much Checkpoint 即脏页的数量太多，导致InnoDB存储引擎强制进行Checkpoint。 其目的总的来说还是为了保证缓冲池中有足够可用的页。 其可由参数innodb_max_dirty_pages_pct控制,比如该值为75，表示当缓冲池中脏页占据75%时，强制进行CheckPoint 因为CPU和磁盘间的鸿沟的问题，从而出现缓冲池数据页来加快数据库DML操作 因为缓冲池数据页与磁盘数据一致性的问题，从而出现WAL策略（核心就是redo log） 因为缓冲池脏页的刷新性能问题，从而出现Checkpoint技术 InnoDB 为了提高执行效率，并不会每次DML操作都和磁盘交互进行持久化。而是通过Write Ahead Log 先策略写入redo log保证事物的持久化。 对于事物中修改的缓冲池脏页，会通过异步的方式刷盘，而内存空闲页和redo log的可用是通过Checkpoint技术来保证的。 不同存储引擎文件存储结构每个数据表都有一个对应的.frm文件，保存每个数据表的元数据信息，包括表结构的定义信息。 MyISAM 物理文件结构为： .frm文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等 .MYD (MYData) 文件：MyISAM 存储引擎专用，用于存储MyISAM 表的数据 .MYI (MYIndex)文件：MyISAM 存储引擎专用，用于存储MyISAM 表的索引相关信息 InnoDB 物理文件结构为： .frm 文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等 .ibd 文件或 .ibdata 文件： 这两种文件都是存放 InnoDB 数据的文件，之所以有两种文件形式存放 InnoDB 的数据，是因为 InnoDB 的数据存储方式能够通过配置来决定是使用共享表空间存放存储数据，还是用独享表空间存放存储数据。 独享表空间存储方式使用.ibd文件，并且每个表一个.ibd文件 共享表空间存储方式使用.ibdata文件，所有表共同使用一个.ibdata文件（或多个，可自己配置） InnoDB和MyISAM的区别（5点） InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败； InnoDB 是聚簇索引，MyISAM 是非聚簇索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 InnoDB 不保存表的具体行数，执行select count(*) from table 时需要全表扫描。而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快； InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； 一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15 ? 如果表的类型是MyISAM，那么是18。因为MyISAM表会把自增主键的最大ID 记录到数据文件中，重启MySQL自增主键的最大ID也不会丢失； 如果表的类型是InnoDB，那么是15。因为InnoDB 表只是把自增主键的最大ID记录到内存中，所以重启数据库或对表进行OPTION操作，都会导致最大ID丢失 InnoDB的逻辑存储结构记录是按照行来存储的，但是数据库的读取并不以行为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，效率会非常低。因此在数据库中，不论读一行，还是读多行，都是将这些行所在的页进行加载。也就是说，数据库管理存储空间的基本单位是页（Page）。 一个页中可以存储多个行记录（Row），同时在数据库中，还存在着区（Extent）、段（Segment）和表空间（Tablespace）。行、页、区、段、表空间的关系如下图所示： 从图中你能看到一个表空间包括了一个或多个段，一个段包括了一个或多个区，一个区包括了多个页，而一个页中可以有多行记录，这些概念我简单给你讲解下。 表空间表空间（Tablespace）是一个逻辑容器，表空间存储的对象是段，在一个表空间中可以有一个或多个段，但是一个段只能属于一个表空间。数据库由一个或多个表空间组成，表空间从管理上可以划分为系统表空间、用户表空间、撤销表空间、临时表空间等。 在 InnoDB 中存在两种表空间的类型：共享表空间和独立表空间。如果是共享表空间就意味着多张表共用一个表空间。如果是独立表空间，就意味着每张表有一个独立的表空间，也就是数据和索引信息都会保存在自己的表空间中。独立的表空间可以在不同的数据库之间进行迁移。 12345678910mysql&gt; show variables like 'innodb_file_per_table';+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| innodb_file_per_table | ON | //每张表都会单独保存为一个.ibd 文件。+-----------------------+-------+1 row in set (0.00 sec)mysql&gt; 段段（Segment）由一个或多个区组成，区在文件系统是一个连续分配的空间（在 InnoDB 中是连续的 64 个页），不过在段中不要求区与区之间是相邻的。段是数据库中的分配单位，不同类型的数据库对象以不同的段形式存在。当我们创建数据表、索引的时候，就会相应创建对应的段，比如创建一张表时会创建一个表段，创建一个索引时会创建一个索引段。 区区（Extent）是比页大一级的存储结构，在 InnoDB 存储引擎中，一个区会分配 64 个连续的页。因为 InnoDB 中的页大小默认是 16KB，所以一个区的大小是 64*16KB=1MB。 页内结构页（Page）如果按类型划分的话，常见的有数据页（保存 B+ 树节点）、系统页、Undo 页和事务数据页等。数据页是我们最常使用的页。在 MySQL 的 InnoDB 存储引擎中，默认页的大小是 16KB，我们可以通过下面的命令来进行查看： 123456789mysql&gt; show variables like '%innodb_page_size%';+------------------+-------+| Variable_name | Value |+------------------+-------+| innodb_page_size | 16384 |+------------------+-------+1 row in set (0.00 sec)mysql&gt; 数据库 I/O 操作的最小单位是页，与数据库相关的内容都会存储在页结构里。数据页包括七个部分，分别是文件头（File Header）、页头（Page Header）、最大最小记录（Infimum+supremum）、用户记录（User Records）、空闲空间（Free Space）、页目录（Page Directory）和文件尾（File Tailer）。 可以分为一下三个部分： 首先是文件通用部分，也就是文件头和文件尾。它们类似集装箱，将页的内容进行封装，通过文件头和文件尾校验的方式来确保页的传输是完整的。在文件头中有两个字段，分别是 FIL_PAGE_PREV 和 FIL_PAGE_NEXT，它们的作用相当于指针，分别指向上一个数据页和下一个数据页。连接起来的页相当于一个双向的链表 第二个部分是记录部分，页的主要作用是存储记录，所以“最小和最大记录”和“用户记录”部分占了页结构的主要空间。另外空闲空间是个灵活的部分，当有新的记录插入时，会从空闲空间中进行分配用于存储新记录， 第三部分是索引部分，这部分重点指的是页目录，它起到了记录的索引作用，因为在页中，记录是以单向链表的形式进行存储的。单向链表的特点就是插入、删除非常方便，但是检索效率不高，最差的情况下需要遍历链表上的所有节点才能完成检索，因此在页目录中提供了二分查找的方式，用来提高记录的检索效率。这个过程就好比是给记录创建了一个目录： 将所有的记录分成几个组，这些记录包括最小记录和最大记录，但不包括标记为“已删除”的记录。 第 1 组，也就是最小记录所在的分组只有 1 个记录；最后一组，就是最大记录所在的分组，会有 1-8 条记录；其余的组记录数量在 4-8 条之间。这样做的好处是，除了第 1 组（最小记录所在组）以外，其余组的记录数会尽量平分。 在每个组中最后一条记录的头信息中会存储该组一共有多少条记录，作为 n_owned 字段。 页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），每个槽相当于指针指向了不同组的最后一个记录。如下图所示： 页目录存储的是槽，槽相当于分组记录的索引。我们通过槽查找记录，实际上就是在做二分查找。这里我以上面的图示进行举例，5 个槽的编号分别为 0，1，2，3，4，我想查找主键为 9 的用户记录，我们初始化查找的槽的下限编号，设置为 low=0，然后设置查找的槽的上限编号 high=4，然后采用二分查找法进行查找。 首先找到槽的中间位置 p=(low+high)/2=(0+4)/2=2，这时我们取编号为 2 的槽对应的分组记录中最大的记录，取出关键字为 8。因为 9 大于 8，所以应该会在槽编号为 (p,high] 的范围进行查找 接着重新计算中间位置 p’=(p+high)/2=(2+4)/2=3，我们查找编号为 3 的槽对应的分组记录中最大的记录，取出关键字为 12。因为 9 小于 12，所以应该在槽 3 中进行查找。 遍历槽 3 中的所有记录，找到关键字为 9 的记录，取出该条记录的信息即为我们想要查找的内容。 从数据页的角度看 B+ 树是如何进行查询的MySQL 的 InnoDB 存储引擎采用 B+ 树作为索引，而索引又可以分成聚集索引和非聚集索引（二级索引），这些索引都相当于一棵 B+ 树，如图所示。一棵 B+ 树按照节点类型可以分成两部分： 叶子节点，B+ 树最底层的节点，节点的高度为 0，存储行记录。 非叶子节点，节点的高度大于 0，存储索引键和页面指针，并不存储行记录本身。 在一棵 B+ 树中，每个节点都是一个页，每次新建节点的时候，就会申请一个页空间。同一层上的节点之间，通过页的结构构成一个双向的链表（页文件头中的两个指针字段）。非叶子节点，包括了多个索引行，每个索引行里存储索引键和指向下一层页面的页面指针。最后是叶子节点，它存储了关键字和行记录，在节点内部（也就是页结构的内部）记录之间是一个单向的链表，但是对记录进行查找，则可以通过页目录采用二分查找的方式来进行。 当我们从页结构来理解 B+ 树的结构的时候，可以帮我们理解一些通过索引进行检索的原理： 1.B+ 树是如何进行记录检索的？ 如果通过 B+ 树的索引查询行记录，首先是从 B+ 树的根开始，逐层检索，直到找到叶子节点，也就是找到对应的数据页为止，将数据页加载到内存中，页目录中的槽（slot）采用二分查找的方式先找到一个粗略的记录分组，然后再在分组中通过链表遍历的方式查找记录。 2. 普通索引和唯一索引在查询效率上有什么不同？ 我们创建索引的时候可以是普通索引，也可以是唯一索引，那么这两个索引在查询效率上有什么不同呢？ 唯一索引就是在普通索引上增加了约束性，也就是关键字唯一，找到了关键字就停止检索。而普通索引，可能会存在用户记录中的关键字相同的情况，根据页结构的原理，当我们读取一条记录的时候，不是单独将这条记录从磁盘中读出去，而是将这个记录所在的页加载到内存中进行读取。InnoDB 存储引擎的页大小为 16KB，在一个页中可能存储着上千个记录，因此在普通索引的字段上进行查找也就是在内存中多几次“判断下一条记录”的操作，对于 CPU 来说，这些操作所消耗的时间是可以忽略不计的。所以对一个索引字段进行检索，采用普通索引还是唯一索引在检索效率上基本上没有差别。 总结今天我们学习了数据库中的基本存储单位，也就是页（Page），磁盘 I/O 都是基于页来进行读取的，在页之上还有区、段和表空间，它们都是更大的存储单位。我们在分配空间的时候会按照页为单位来进行分配，同一棵树上同一层的页与页之间采用双向链表，而在页里面，记录之间采用的单向链表的方式。 链表这种数据结构的特点是增加、删除比较方便，所以在对记录进行删除的时候，有时候并不是真的删除了记录，而只是逻辑上的删除，也就是在标记为上标记为“已删除”。但链表还有个问题就是查找效率低，因此在页结构中还专门设计了页目录这个模块，专门给记录做一个目录，通过二分查找法的方式进行检索提升效率。","link":"/2021/05/11/MySQL%EF%BC%88%E4%BA%8C%EF%BC%89%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/05/06/hello-world/"},{"title":"测试图上传","text":"","link":"/2021/05/06/%E6%B5%8B%E8%AF%95%E5%9B%BE%E4%B8%8A%E4%BC%A0/"},{"title":"消息队列基础问题","text":"消息队列基础篇，主要描述了四个问题： 为什么要用消息队列 如何保证消息不丢失 如何保证消息不重复消费 如何处理消息的积压 消息队列的使用场景异步处理我们以常见的电商秒杀场景为例，秒杀系统需要解决的核心问题是，如何利用有限的服务器资源，尽可能多地处理短时间内的海量请求。 一个秒杀通常包含了一下几个步骤： 风险控制 库存锁定 生成订单 短信通知 更新统计数据等等。。 如果没有任何优化处理的话，正常的处理流程是：App 将请求发送给网关，依次调用上述 5 个流程，然后将结果返回给 APP。但实际上，用户能否秒杀成功主要是看风险控制和库存锁定两步，也就是说当服务端完成前面 2 个步骤，确定本次请求的秒杀结果后，就可以马上给用户返回响应，剩余的步骤都可以放入消息队列中，异步的进行后续的处理。 这样处理之后，在秒杀期间我们可以用更多的服务器资源来处理秒杀请求，秒杀结束后再异步的处理后续的步骤。 在这个场景中，消息队列被用于实现服务的异步处理。这样做的好处是： 可以更快地返回结果； 减少等待，自然实现了步骤之间的并发，提升系统总体的性能。 流量削峰还是以秒杀场景为例，我们已经通过部分异步处理提高了用户的响应效率，下一个问题是如何避免瞬间过多的请求压垮我们的秒杀系统？ 一个设计健壮的程序有自我保护的能力，也就是说，它应该可以在海量的请求下，还能在自身能力范围内尽可能多地处理请求，拒绝处理不了的请求并且保证自身运行正常。不幸的是，现实中很多程序并没有那么“健壮”，而直接拒绝请求返回错误对于用户来说也是不怎么好的体验。 使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的。 加入消息队列后，整个秒杀流程变为： 网关在收到请求后，将请求放入请求消息队列； 后端服务从请求消息队列中获取 APP 请求，完成后续秒杀处理过程，然后返回结果。 秒杀开始后，当短时间内大量的秒杀请求到达网关时，不会直接冲击到后端的秒杀服务，而是先堆积在消息队列中，后端服务按照自己的最大处理能力，从消息队列中消费请求进行处理。 对于超时的请求可以直接丢弃，APP 将超时无响应的请求处理为秒杀失败即可。运维人员还可以随时增加秒杀服务的实例数量进行水平扩容，而不用对系统的其他部分做任何更改。 这种设计的优点是：能根据下游的处理能力自动调节流量，达到“削峰填谷”的作用。但这样做同样是有代价的： 增加了系统调用链环节，导致总体的响应时延变长。 上下游系统都要将同步调用改为异步消息，增加了系统的复杂度。 消息队列实现令牌桶进行限流令牌桶控制流量的原理是：单位时间内只发放固定数量的令牌到令牌桶中，规定服务在处理请求之前必须先从令牌桶中拿出一个令牌，如果令牌桶中没有令牌，则拒绝请求。这样就保证单位时间内，能处理的请求不超过发放令牌的数量，起到了流量控制的作用。 网关在处理 APP 请求时增加一个获取令牌的逻辑。 令牌桶可以简单地用一个有固定容量的消息队列加一个“令牌发生器”来实现：令牌发生器按照预估的处理能力，匀速生产令牌并放入令牌队列（如果队列满了则丢弃令牌），网关在收到请求时去令牌队列消费一个令牌，获取到令牌则继续调用后端秒杀服务，如果获取不到令牌则直接返回秒杀失败。 服务解耦订单信息是电商系统中比较核心的数据，当一个新订单创建时： 支付系统需要发起支付流程； 风控系统需要审核订单的合法性； 客服系统需要给用户发短信告知用户； 经营分析系统需要更新统计数据； 这些订单下游的系统都需要实时获得订单数据。随着业务不断发展，这些订单下游系统不断的增加，不断变化，并且每个系统可能只需要订单数据的一个子集，负责订单服务的开发团队不得不花费很大的精力，应对不断增加变化的下游系统，不停地修改调试订单系统与这些下游系统的接口。任何一个下游系统接口变更，都需要订单模块重新进行一次上线，对于一个电商的核心服务来说，这几乎是不可接受的。 所有的电商都选择用消息队列来解决类似的系统耦合过于紧密的问题。引入消息队列后，订单服务在订单变化时发送一条消息到消息队列的一个主题 Order 中，所有下游系统都订阅主题 Order，这样每个下游系统都可以获得一份实时完整的订单数据。 如何保证消息不丢失如何检测消息是否丢失 如果是 IT 基础设施比较完善的公司，一般都有分布式链路追踪系统，使用类似的追踪系统可以很方便地追踪每一条消息。 如果没有这样的追踪系统，这里我提供一个比较简单的方法，来检查是否有消息丢失的情况。我们可以利用消息队列的有序性来验证是否有消息丢失。原理非常简单，在 Producer 端，我们给每个发出的消息附加一个连续递增的序号，然后在 Consumer 端来检查这个序号的连续性。如果没有消息丢失，Consumer 收到消息的序号必然是连续递增的，或者说收到的消息，其中的序号必然是上一条消息的序号 +1。如果检测到序号不连续，那就是丢消息了。还可以通过缺失的序号来确定丢失的是哪条消息，方便进一步排查原因。 大多数消息队列的客户端都支持拦截器机制，你可以利用这个拦截器机制，在 Producer 发送消息之前的拦截器中将序号注入到消息中，在 Consumer 收到消息的拦截器中检测序号的连续性，这样实现的好处是消息检测的代码不会侵入到你的业务代码中，待你的系统稳定后，也方便将这部分检测的逻辑关闭或者删除。 分布式系统中需要注意的点 首先，像 Kafka 和 RocketMQ 这样的消息队列，它是不保证在 Topic 上的严格顺序的，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。 如果你的系统中 Producer 是多实例的，由于并不好协调多个 Producer 之间的发送顺序，所以也需要每个 Producer 分别生成各自的消息序号，并且需要附加上 Producer 的标识，在 Consumer 端按照每个 Producer 分别来检测序号的连续性。 Consumer 实例的数量最好和分区数量一致，做到 Consumer 和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性。 如何确保消息可靠传递 生产阶段: 在这个阶段，从消息在 Producer 创建出来，经过网络传输发送到 Broker 端。 存储阶段: 在这个阶段，消息在 Broker 端存储，如果是集群，消息会在这个阶段被复制到其他的副本上。 消费阶段: 在这个阶段，Consumer 从 Broker 上拉取消息，经过网络传输发送到 Consumer 上。 1. 生产阶段： 在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传递：当你的代码调用发消息方法时，消息队列的客户端会把消息发送到 Broker，Broker 收到消息后（最好写入到磁盘中才返回确认消息），会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送。 12345678你在编写发送消息代码时，需要注意，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失。 try { RecordMetadata metadata = producer.send(record).get(); System.out.println(&quot; 消息发送成功。&quot;);} catch (Throwable e) { System.out.println(&quot; 消息发送失败！&quot;); System.out.println(e);} 异步发送时，则需要在回调方法里进行检查。这个地方是需要特别注意的，很多丢消息的原因就是，我们使用了异步发送，却没有在回调中检查发送结果。 12345678producer.send(record, (metadata, exception) -&gt; { if (metadata != null) { System.out.println(&quot; 消息发送成功。&quot;); } else { System.out.println(&quot; 消息发送失败！&quot;); System.out.println(exception); }}); 2.存储阶段： 在存储阶段正常情况下，只要 Broker 在正常运行，就不会出现丢失消息的问题，但是如果 Broker 出现了故障，比如进程死掉了或者服务器宕机了，还是可能会丢失消息的。 对于单个节点的 Broker，需要配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费。例如，在 RocketMQ 中，需要将刷盘方式 flushDiskType 配置为 SYNC_FLUSH 同步刷盘。 如果是 Broker 是由多个节点组成的集群，需要将 Broker 集群配置成：至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker，也不会发生消息丢失。 3.消费阶段 消费阶段采用和生产阶段类似的确认机制来保证消息的可靠传递，客户端从 Broker 拉取消息后，执行用户的消费业务逻辑，成功后，才会给 Broker 发送消费确认响应。如果 Broker 没有收到消费确认响应，下次拉消息的时候还会返回同一条消息，确保消息不会在网络传输过程中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失。 你在写消费代码时需要注意的是，不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。 如何保证消费过程中的重复消息（幂等性）在消息传递过程中，如果出现传递失败的情况，发送方会执行重试，重试的过程中就有可能会产生重复的消息。对使用消息队列的业务系统来说，如果没有对重复消息进行处理，就有可能会导致系统的数据出现错误 消息重复的情况必然存在在 MQTT 协议中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是： At most once: 至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。 At least once: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。 Exactly once：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。 这个服务质量标准不仅适用于 MQTT，对所有的消息队列都是适用的。我们现在常用的绝大部分消息队列提供的服务质量都是 At least once，包括 RocketMQ、RabbitMQ 和 Kafka 都是这样。也就是说，消息队列很难保证消息不重复。 用幂等性解决重复消息问题一个幂等操作的特点是，其任意多次执行所产生的影响均与一次执行的影响相同。 利用数据库的唯一约束实现幂等例如我们刚刚提到的那个不具备幂等特性的转账的例子：将账户 X 的余额加 100 元。在这个例子中，我们可以通过改造业务逻辑，让它具备幂等性。 首先，我们可以限定，对于每个转账单每个账户只可以执行一次变更操作，在分布式系统中，这个限制实现的方法非常多，最简单的是我们在数据库中建一张转账流水表，这个表有三个字段：转账单 ID、账户 ID 和变更金额，然后给转账单 ID 和账户 ID 这两个字段联合起来创建一个唯一约束，这样对于相同的转账单 ID 和账户 ID，表里至多只能存在一条记录。 基于这个思路，不光是可以使用关系型数据库，只要是支持类似“INSERT IF NOT EXIST”语义的存储类系统都可以用于实现幂等，比如，你可以用 Redis 的 SETNX 命令来替代数据库中的唯一约束，来实现幂等消费。 为更新的数据设置前置条件给数据变更设置一个前置条件，如果满足条件就更新数据，否则拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。这样，重复执行这个操作时，由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。 比如，刚刚我们说过，“将账户 X 的余额增加 100 元”这个操作并不满足幂等性，我们可以把这个操作加上一个前置条件，变为：“如果账户 X 当前的余额为 500 元，将余额加 100 元”，这个操作就具备了幂等性。对应到消息队列中的使用时，可以在发消息时在消息体中带上当前的余额，在消费的时候进行判断数据库中，当前余额是否与消息中的余额相等，只有相等才执行变更操作。 更加通用的方法是，给你的数据增加一个版本号属性，每次更数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时将版本号 +1，一样可以实现幂等更新 记录并检查操作我们还有一种通用性最强，适用范围最广的实现幂等性方法：记录并检查操作，也称为“Token 机制或者 GUID（全局唯一 ID）机制”，实现的思路特别简单：在执行数据更新操作之前，先检查一下是否执行过这个更新操作。 具体的实现方法是，在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。 更加麻烦的是，在“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作保证原子性，才能真正实现幂等，否则就会出现 Bug 比如说，对于同一条消息：“全局 ID 为 8，操作为：给 ID 为 666 账户增加 100 元”，有可能出现这样的情况： t0 时刻：Consumer A 收到条消息，检查消息执行状态，发现消息未处理过，开始执行“账户增加 100 元”； t1 时刻：Consumer B 收到条消息，检查消息执行状态，发现消息未处理过，因为这个时刻，Consumer A 还未来得及更新消息执行状态。 这样就会导致账户被错误地增加了两次 100 元，这是一个在分布式系统中非常容易犯的错误，一定要引以为戒。 对于这个问题，当然我们可以用事务来实现，也可以用锁来实现，但是在分布式系统中，无论是分布式事务还是分布式锁都是比较难解决问题。 消息积压了该怎么办优化性能来避免消息积压发送端性能优化优化消息收发性能，预防消息积压的方法有两种，增加批量或者是增加并发，在发送端这两种方法都可以使用。 Producer 发送消息的过程，Producer 发消息给 Broker，Broker 收到消息后返回确认响应，这是一次完整的交互。假设这一次交互的平均时延是 1ms，我们把这 1ms 的时间分解开，它包括了下面这些步骤的耗时： 发送端准备数据、序列化消息、构造请求等逻辑的时间，也就是发送端在发送网络请求之前的耗时； 发送消息和返回响应在网络传输中的耗时； Broker 处理消息的时延 无论是增加每次发送消息的批量大小，还是增加并发，都能成倍地提升发送性能 比如说，你的消息发送端是一个微服务，主要接受 RPC 请求处理在线业务。很自然的，微服务在处理每次请求的时候，就在当前线程直接发送消息就可以了，因为所有 RPC 框架都是多线程支持多并发的，自然也就实现了并行发送消息。并且在线业务比较在意的是请求响应时延，选择批量发送必然会影响 RPC 服务的时延。这种情况，比较明智的方式就是通过并发来提升发送性能。 如果你的系统是一个离线分析系统，离线系统在性能上的需求是什么呢？它不关心时延，更注重整个系统的吞吐量。发送端的数据都是来自于数据库，这种情况就更适合批量发送，你可以批量从数据库读取数据，然后批量来发送消息，同样用少量的并发就可以获得非常高的吞吐量。 消费端性能优化使用消息队列的时候，大部分的性能问题都出现在消费端，如果消费的速度跟不上发送端生产消息的速度，就会造成消息积压。如果这种性能倒挂的问题只是暂时的，那问题不大，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息是可以逐渐被消化掉的。 我们在设计系统的时候，一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。 消费端的性能优化除了优化消费业务逻辑以外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。特别需要注意的一点是，在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。原因我们之前讲过，因为对于消费者来说，在每个分区上实际上只能支持单线程消费 消息积压了该如何处理？能导致积压突然增加，最粗粒度的原因，只有两种：要么是发送变快了，要么是消费变慢了。 大部分消息队列都内置了监控的功能，只要通过监控数据，很容易确定是哪种原因。如果是单位时间发送的消息增多，比如说是赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升消费性能，唯一的方法是通过扩容消费端的实例数来提升总体的消费能力。 如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。 还有一种不太常见的情况，你通过监控发现，无论是发送消息的速度还是消费消息的速度和原来都没什么变化，这时候你需要检查一下你的消费端，是不是消费失败导致的一条消息反复消费这种情况比较多，这种情况也会拖慢整个系统的消费速度。 总结","link":"/2021/05/11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%9F%BA%E7%A1%80%E9%97%AE%E9%A2%98/"},{"title":"算法题","text":"哈哈 第一部分：四种基本情况 1. 无重复数字的二分查找https://leetcode-cn.com/problems/binary-search/ 123456789101112class Solution { public int search(int[] nums, int target) { int n = nums.length; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r + 1 &gt;&gt; 1; if(nums[mid] &gt; target) r = mid-1; else l = mid; } return nums[l] == target ? l : -1; }} 2. 有重复数字的二分查找第一个位置和最后一个位置https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/ 12345678910111213141516171819202122232425262728class Solution { public int[] searchRange(int[] nums, int target) { int[] res = new int[2]; int n = nums.length; if(n == 0) return new int[]{-1,-1}; //找到第一个出现的位置 int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; if(nums[mid] &lt; target) l = mid+1; else r = mid; } if(nums[l] != target) return new int[]{-1,-1}; else res[0] = l; //找到最后一个出现的位置 l = 0; r = n-1; while(l &lt; r){ int mid = l + r +1 &gt;&gt; 1; if(nums[mid] &gt; target) r = mid-1; else l = mid; } res[1] = l; return res; }} 3. 搜索插入位置https://leetcode-cn.com/problems/search-insert-position/ 12345678910111213141516class Solution { public int searchInsert(int[] nums, int target) { int n = nums.length; //1. 注意如果最后一个数小于target的话，就返回数组长度 if (n == 0 || nums[n-1] &lt; target) return n; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; if(nums[mid] &lt; target) l = mid + 1; else r = mid; } return l; }} 4. x的平方根（只保留整数部分）12345678910111213 class Solution { public int mySqrt(int x) { int l = 0 , r = x; while(l &lt; r){ int mid = l + r + 1 &gt;&gt; 1; if(mid &gt; x / mid) r = mid-1; else l = mid; } return l; }} 5. 寻找重复的数https://leetcode-cn.com/problems/find-the-duplicate-number/ 123456789101112131415161718192021class Solution { public int findDuplicate(int[] nums) { int n = nums.length; //对值的范围进而二分 int l = 0 , r = n-1; while (l &lt; r){ int mid = l+r &gt;&gt;1; //看一下数组中比mid小的数有多少 int count = 0; for (int num : nums){ if (num &lt;= mid) count++; } //比mid小的数大于mid，说明在左边,可能是mid if (count &gt; mid) r = mid; else l = mid+1; } return l; }} 6. 实现Pow(x,n)https://leetcode-cn.com/problems/powx-n/comments/ 12345678910111213class Solution { public double myPow(double x, int n) { double res = 1.0; for(int i = n ; i != 0 ; i /=2){ if(i % 2 != 0) res = res * x; x *= x; } return n &lt; 0 ? 1/res : res; }} 7. 寻找两个排序数组的中位数https://leetcode-cn.com/problems/median-of-two-sorted-arrays/ 1234567891011121314151617181920212223242526class Solution { public double findMedianSortedArrays(int[] nums1, int[] nums2) { int n = nums1.length; int m = nums2.length; int l = (n + m + 1)/2; int r = (n + m + 2)/2; return (getK(nums1, 0 , n-1 , nums2 , 0 , m-1 , l) + getK(nums1 , 0 ,n-1 , nums2 ,0,m-1,r))/2.0; } //从两个正序数组中获取第k大的数 int getK(int[] nums1 , int s1 , int e1 , int[] nums2 , int s2 , int e2 , int k){ int len1 = e1 - s1 + 1; int len2 = e2 - s2 + 1; if(len1 &gt; len2) return getK(nums2 , s2 , e2 , nums1 , s1 , e1 , k); if(len1 == 0) return nums2[s2 + k -1]; if(k == 1) return Math.min(nums1[s1] , nums2[s2]); int i = s1 + Math.min(len1 , k/2)-1; //每次取一半的值 int j = s2 + Math.min(len2 , k/2)-1; //每一轮都将较小的那半组数据舍去 if(nums1[i] &gt; nums2[j]) return getK(nums1 , s1 ,e1 , nums2 ,j+1, e2 ,k-(j-s2+1)); else return getK(nums1, i+1 ,e1 , nums2 , s2 , e2 , k-(i-s1+1)); }} 第二部分：旋转排序数组1. 寻找旋转排序数组中的最小值(无重复值)https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array/ 1234567891011121314class Solution { public int findMin(int[] nums) { int n = nums.length; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; //34512 if(nums[mid] &gt; nums[r]) l = mid+1; else r = mid; } return nums[l]; }} 2. 寻找旋转排序数组中的最小值(有重复值)https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array-ii/ 12345678910111213class Solution { public int findMin(int[] nums) { int n = nums.length; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; if(nums[mid] &gt; nums[r]) l = mid+1; else if(nums[mid] &lt; nums[r]) r = mid; else r--; } return nums[l]; }} 3. 寻找旋转排序数组中的指定值(无重复值)https://leetcode-cn.com/problems/search-in-rotated-sorted-array/ 123456789101112131415161718192021class Solution { public int search(int[] nums, int target) { int n = nums.length; if(n == 0) return -1; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; //34512 if(nums[mid] &gt; nums[r]){ if(target &gt;= nums[l] &amp;&amp; target &lt;= nums[mid]) r = mid; else l = mid+1; }else{ //561234 if(target &gt; nums[mid] &amp;&amp; target &lt;= nums[r]) l = mid+1; else r = mid; } } return nums[l] == target ? l : -1; }} 第三部分：二维矩阵1. 搜索二维矩阵https://leetcode-cn.com/problems/search-a-2d-matrix/ 123456789101112131415class Solution { public boolean searchMatrix(int[][] matrix, int target) { int m = matrix.length; //行数 int n = matrix[0].length; //列数 int l = 0 , r = m *n -1; while(l &lt; r){ int mid = l + r + 1 &gt;&gt; 1; //将一维的数组转换成二维的坐标 if(matrix[mid / n][ mid % n] &gt; target) r = mid-1; else l = mid; } return matrix[l/n][l%n] == target; }} 2. 搜索二维矩阵2https://leetcode-cn.com/problems/search-a-2d-matrix-ii/submissions/ 1234567891011121314class Solution { public boolean searchMatrix(int[][] matrix, int target) { int m = matrix.length; //行数 int n = matrix[0].length; //列数 int i = 0 , j = n-1; while(i &lt;= m-1 &amp;&amp; j &gt;= 0){ if(matrix[i][j] &gt; target) j--; else if(matrix[i][j] &lt; target) i++; else return true; } return false; }} 3. 有序矩阵中第k小的数https://leetcode-cn.com/problems/kth-smallest-element-in-a-sorted-matrix/","link":"/2021/05/06/%E7%AE%97%E6%B3%95%E9%A2%98/"}],"tags":[{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Java并发","slug":"Java并发","link":"/tags/Java%E5%B9%B6%E5%8F%91/"},{"name":"消息队列","slug":"消息队列","link":"/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"算法题","slug":"算法题","link":"/tags/%E7%AE%97%E6%B3%95%E9%A2%98/"}],"categories":[{"name":"技术","slug":"技术","link":"/categories/%E6%8A%80%E6%9C%AF/"}]}