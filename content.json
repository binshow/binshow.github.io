{"pages":[],"posts":[{"title":"Java并发理论基础-上","text":"并发编程领域可以抽象成三个核心问题：分配任务、相互协作和互斥： 分配任务：将一个大的任务交给不同的进程/线程来做 相互协作：线程间的协作，比如一个线程执行完了一个任务，如何通知执行后续任务的线程开工 互斥：要实现在同一时刻内只有一个线程访问共享变量 第一部分、并发编程的发展1. 并发编程问题的由来随着CPU 、 内存 、IO设备的不断发展，三者的速度差异一直是存在的（CPU一天 ， 内存一年 ， IO设备十年） 为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为： CPU 增加了缓存，以均衡与内存的速度差异； 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异； 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用 1.1 缓存导致的可见性问题 一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为可见性。 单核时代，电脑只有1个CPU，所有的线程操作的是同一个CPU的缓存，也就不存在可见性问题。 多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存，如下图 1.2 线程切换带来的原子性问题 一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性 在一个时间片内，如果一个进程进行一个 IO 操作，例如读个文件，这个时候该进程可以把自己标记为“休眠状态”并出让 CPU 的使用权，待文件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得 CPU 的使用权了。 早期的操作系统基于进程来调度 CPU，不同进程间是不共享内存空间的，所以进程要做任务切换就要切换内存映射地址，而一个进程创建的所有线程，都是共享一个内存空间的，所以线程做任务切换成本就很低了。现代的操作系统都基于更轻量的线程来调度，现在我们提到的“任务切换”都是指“线程切换”。 Java 并发程序都是基于多线程的，自然也会涉及到任务切换，也许你想不到，任务切换竟然也是并发编程里诡异 Bug 的源头之一。任务切换的时机大多数是在时间片结束的时候，我们现在基本都使用高级语言编程，高级语言里一条语句往往需要多条 CPU 指令完成，例如上面代码中的count += 1，至少需要三条 CPU 指令。 指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器； 指令 2：之后，在寄存器中执行 +1 操作； 指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存） 1.3 编译优化带来的有序性问题有序性指的是程序按照代码的先后顺序执行。编译器为了优化性能，有时候会进行指令重排序。 重排序分3种类型。 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术(Instruction-Level Parallelism，ILP)来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应 机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上 去可能是在乱序执行 例如程序中：“a=6；b=7；”编译器优化后可能变成“b=7；a=6；”，在这个例子中，编译器调整了语句的顺序，但是不影响程序的最终结果，但是有时会出现问题。 比如单例模式中的双重检验模式： 1234567891011121314public class Singleton { static Singleton instance; public Singleton getInstance(){ if (instance == null){ synchronized (Singleton.class){ if (instance == null) instance = new Singleton(); //在CPU指令上并不是一步操作 } } return instance; }} new一个新的对象分为如下几步（先在内存中初始化对象再赋值给变量）： 分配一块内存 M； 在内存 M 上初始化 Singleton 对象； 然后 M 的地址赋值给 instance 变量。 经过指令重排序变成了下面这种情况（先将内存赋值给变量再进行初始化）： 分配一块内存 M； 将 M 的地址赋值给 instance 变量； 最后在内存 M 上初始化 Singleton 对象。 不安全的情况：假设线程 A 先执行 getInstance() 方法，当执行完指令 2 时恰好发生了线程切换，切换到了线程 B 上；如果此时线程 B 也执行 getInstance() 方法，那么线程 B 在执行第一个判断时会发现 instance != null ，所以直接返回 instance，而此时的 instance 是没有初始化过的，如果我们这个时候访问 instance 的成员变量就可能触发空指针异常。 2. 并发编程面临的挑战并发编程的目的是为了让程序运行得更快，但是，并不是启动更多的线程就能让程序最大限度地并发执行。 2.1上下文切换所谓的多线程并发执行是通过CPU给每个线程分配CPU时间片来实现的，因为时间片非常短（一般是几十毫秒ms），所以CPU通过不停地切 换线程执行，让我们感觉多个线程是同时执行的。 上下文切换是指：当前任务执行完一个时间片后需要切换到下一个任务，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这 个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换 多线程一定快吗？不一定，因为线程有创建和上下文切换的开销。 如何减少上下文切换： 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一 些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。 CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。 协程:在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。 2.2 死锁及避免办法 避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。 3. 什么是线程安全？线程安全需要保证几个基本特性： 原子性，简单说就是相关操作不会中途被其他线程干扰，一般通过同步机制实现。 可见性，是一个线程修改了某个共享变量，其状态能够立即被其他线程知晓，通常被解释为将线程本地状态反映到主内存上，volatile就是负责保证可见性的。 有序性，是保证线程内串行语义，避免指令重排等。 第二部分、Java中如何实现并发安全由上一部分可知：解决可见性、有序性最直接的办法就是禁用缓存和编译优化，但是性能上会带来问题。因此需要做到按需禁用。站在程序员的视角看就是 Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括 volatile、synchronized 和 final 三个关键字，以及六项 Happens-Before 规则， 1. volatile保证可见性volatile是轻量级的 synchronized，它在多处理器开发中保证了共享变量的“可见性”,不会引起线程上下文的切换和调度。 1volatile int x = 0; //告诉编译器，对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入 1.1 如何实现的可见性有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码: 0x01a3de1d: movb 0×0,0×1104800(0×0,0×1104800(%esi); 0x01a3de24: lock addl 0×0,0×1104800(0×0,(%esp); Lock前缀的指令： 1)将当前处理器缓存行的数据写回到系统内存。 2)这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存(L1，L2或其他)后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的 变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据 写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操 作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一 致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当 处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状 态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存 里。 1.2 volatile的使用优化追加64字节能够提高并发编程的效率？ 处理器的L1、L2或L3缓存的高速缓存行是64个字节宽，如果队列的头节点和尾节点都不足64字节的话，处理器会将 它们都读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头、尾节点，当一 个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致 其他处理器不能访问自己高速缓存中的尾节点，而队列的入队和出队操作则需要不停修改头 节点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率。Doug lea使 用追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存 行，使头、尾节点在修改时不会互相锁定。 2. synchronized保证原子性2.1 应用方法·对于普通同步方法，锁是当前实例对象。 ·对于静态同步方法，锁是当前类的Class对象。 ·对于同步方法块，锁是Synchonized括号里配置的对象。 123456789101112131415161718class X { // 修饰非静态方法,锁定的是当前实例对象 this synchronized void foo() { // 临界区 } // 修饰静态方法,锁定的是当前类的 Class 对象 synchronized static void bar() { // 临界区 } // 修饰代码块 //当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。 Object obj = new Object()； void baz() { synchronized(obj) { // 临界区 } }} 2.2 实现原理 在Java6之前，synchronized完全依靠操作系统的互斥锁来实现，需要进行用户态和内核态的切换，所以开销较大，但随着一系列的锁优化，synchronized的性能也越来越好了 JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。 代码块同步是使用monitorenter 和monitorexit指令实现的，而方法同步是使用另外一种方式实现的 monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。 任何对象都有 一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter 指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。 源代码获取： 首先，synchronized的行为是JVM runtime的一部分，所以我们需要先找到Runtime相关的功能实现。通过在代码中查询类似“monitor_enter”或“Monitor Enter”，很直观的就 可以定位到： sharedRuntime.cpp/hpp，它是解释器和编译器运行时的基类。 synchronizer.cpp/hpp，JVM同步相关的各种基础逻辑。 在sharedRuntime.cpp中，下面代码体现了synchronized的主要逻辑。 1234567Handle h_obj(THREAD, obj); if (UseBiasedLocking) { //检查是否开启了偏向锁 // Retry fas entry if bias is revoked to avoid unnecessary infation ObjectSynchronizer::fast_enter(h_obj, lock, true, CHECK); //完整的流程 } else { ObjectSynchronizer::slow_enter(h_obj, lock, CHECK); //直接进入轻量级锁获取逻辑 } 偏斜锁并不适合所有应用场景，撤销操作（revoke）是比较重的行为，只有当存在较多不会真正竞争的synchronized块儿时，才能体现出明显改善。实践中对于偏斜锁的一直是有 争议的，有人甚至认为，当你需要大量使用并发类库时，往往意味着你不需要偏斜锁。从具体选择来看，我还是建议需要在实践中进行测试，根据结果再决定是否使用。 还有一方面是，偏斜锁会延缓JIT 预热的进程，所以很多性能测试中会显式地关闭偏斜锁， -XX:-UseBiasedLocking 12345678910111213141516171819void ObjectSynchronizer::fas_enter(Handle obj, BasicLock* lock, bool attempt_rebias, TRAPS) { if (UseBiasedLocking) { if (!SafepointSynchronize::is_at_safepoint()) { //revoke_and_rebias是获取偏斜锁的入口方法 BiasedLocking::Condition cond = BiasedLocking::revoke_and_rebias(obj, attempt_rebias, THREAD); if (cond == BiasedLocking::BIAS_REVOKED_AND_REBIASED) { return; } } else { assert(!attempt_rebias, &quot;can not rebias toward VM thread&quot;); //revoke_at_safepoint则定义了当检测到安全点时的处理逻辑 BiasedLocking::revoke_at_safepoint(obj); } assert(!obj-&gt;mark()-&gt;has_bias_pattern(), &quot;biases should be revoked by now&quot;); } slow_enter(obj, lock, THREAD);} 1234567891011121314151617181920212223void ObjectSynchronizer::slow_enter(Handle obj, BasicLock* lock, TRAPS) { markOop mark = obj-&gt;mark(); if (mark-&gt;is_neutral()) { // 将目前的Mark Word复制到Displaced Header上 lock-&gt;set_displaced_header(mark); // 利用CAS设置对象的Mark Word if (mark == obj()-&gt;cas_set_mark((markOop) lock, mark)) { TEVENT(slow_enter: release sacklock); return; } // 检查存在竞争 } else if (mark-&gt;has_locker() &amp;&amp; THREAD-&gt;is_lock_owned((address)mark-&gt;locker())) { // 清除 lock-&gt;set_displaced_header(NULL); return; } // 重置Displaced Header lock-&gt;set_displaced_header(markOopDesc::unused_mark()); ObjectSynchronizer::infate(THREAD, obj(), infate_cause_monitor_enter)-&gt;enter(THREAD);} 2.3 锁的优化过程synchronized用的锁是存在Java对象头里的。如果对象是数组类型，还会存数组类型： 锁一共有4种状态，级别从低到高依次是: 无锁状态、 偏向锁状态、 轻量级锁状态、 重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级 2.3.1 偏向锁经验：大多数情况下，锁都是由同一个线程多次获得。 偏向锁的加锁： 当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出 同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否 存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需 要再测试一下Mark Word中偏向锁的标识是否设置成1(表示当前是偏向锁):如果没有设置，则 使用CAS竞争锁;如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 偏向锁的撤销： 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时， 持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点(在这个时间点上没有正 在执行的字节码)。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着， 如果线程不处于活动状态，则将对象头设置成无锁状态;如果线程仍然活着，拥有偏向锁的栈 会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他 线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。 偏向锁的启用： 偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活 2.3.2 轻量级锁加锁过程： 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并 将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用 CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁 解锁过程： 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成 功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁 因为自旋会消耗CPU，为了避免无用的自旋(比如获得锁的线程被阻塞住了)，一旦锁升级 成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时， 都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮 的夺锁之争 2.3.3 原子操作的实现原理处理器如何实现： 锁总线：多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入 系统内存中。那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享 变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。 处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个 LOCK#信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该 处理器可以独占共享内存。 锁缓存：总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处 理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下 使用缓存锁定代替总线锁定来进行优化。缓存锁定”是指内存区域如果被缓存在处理器的缓存 行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声 言LOCK#信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子 性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处 理器回写已被锁定的缓存行的数据时，会使缓存行无效 Java如何实现： 使用循环CAS实现原子操作：JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。 从Java 1.5开始，JDK的并发包里提供了一些类来支持原子操作，如AtomicBoolean(用原子 方式更新的boolean值)、AtomicInteger(用原子方式更新的int值)和AtomicLong(用原子方式更 新的long值)。这些原子包装类还提供了有用的工具方法，比如以原子的方式将当前值自增1和 自减1。 CAS实现原子操作的三大问题： 1)ABA问题 2)循环时间长开销大 3)只能保证一个共享变量的原子操作 (3)使用锁机制实现原子操作 2.4 转账为例分析锁保护没有关联关系的多个资源，例如，银行业务中有针对账户余额（余额是一种资源）的取款操作，也有针对账户密码（密码也是一种资源）的更改操作，我们可以为账户余额和账户密码分配不同的锁来解决并发问题，这个还是很简单的。 1234567891011121314151617181920212223242526272829303132333435363738394041//不同的资源用不同的锁保护class Account { // 锁：保护账户余额 private final Object balLock = new Object(); // 账户余额 private Integer balance; // 锁：保护账户密码 private final Object pwLock = new Object(); // 账户密码 private String password; // 取款 void withdraw(Integer amt) { synchronized(balLock) { if (this.balance &gt; amt){ this.balance -= amt; } } } // 查看余额 Integer getBalance() { synchronized(balLock) { return balance; } } // 更改密码 void updatePassword(String pw){ synchronized(pwLock) { this.password = pw; } } // 查看密码 String getPassword() { synchronized(pwLock) { return password; } }} 当然，我们也可以用一把互斥锁来保护多个资源，例如我们可以用 this 这一把锁来管理账户类里所有的资源：账户余额和用户密码。具体实现很简单，示例程序中所有的方法都增加同步关键字 synchronized 就可以了. 但是用一把锁有个问题，就是性能太差，会导致取款、查看余额、修改密码、查看密码这四个操作都是串行的。而我们用两把锁，取款和修改密码是可以并行的。用不同的锁对受保护资源进行精细化管理，能够提升性能。这种锁还有个名字，叫细粒度锁。 保护有关联关系的多个资源 例如银行业务里面的转账操作，账户 A 减少 100 元，账户 B 增加 100 元。这两个账户就是有关联关系的。那对于像转账这种有关联关系的操作，我们应该怎么去解决呢？ 12345678910111213class Account { private int balance; // 转账 //临界区内有两个资源，分别是转出账户的余额 this.balance 和转入账户的余额 target.balance，并且用的是一把锁 this //问题就出在 this 这把锁上，this 这把锁可以保护自己的余额 this.balance，却保护不了别人的余额 target.balance，就像你不能用自家的锁来保护别人家的资产 synchronized void transfer( Account target, int amt){ if (this.balance &gt; amt) { this.balance -= amt; target.balance += amt; } } } ​ 下面我们具体分析一下，假设有 A、B、C 三个账户，余额都是 200 元，我们用两个线程分别执行两个转账操作：账户 A 转给账户 B 100 元，账户 B 转给账户 C 100 元，最后我们期望的结果应该是账户 A 的余额是 100 元，账户 B 的余额是 200 元， 账户 C 的余额是 300 元。 我们假设线程 1 执行账户 A 转账户 B 的操作，线程 2 执行账户 B 转账户 C 的操作。这两个线程分别在两颗 CPU 上同时执行，那它们是互斥的吗？我们期望是，但实际上并不是。因为线程 1 锁定的是账户 A 的实例（A.this），而线程 2 锁定的是账户 B 的实例（B.this），所以这两个线程可以同时进入临界区 transfer()。同时进入临界区的结果是什么呢？线程 1 和线程 2 都会读到账户 B 的余额为 200，导致最终账户 B 的余额可能是 300（线程 1 后于线程 2 写 B.balance，线程 2 写的 B.balance 值被线程 1 覆盖），可能是 100（线程 1 先于线程 2 写 B.balance，线程 1 写的 B.balance 值被线程 2 覆盖），就是不可能是 200。 使用锁的正确姿势 很简单，只要我们的锁能覆盖所有受保护资源就可以了。在上面的例子中，this 是对象级别的锁，所以 A 对象和 B 对象都有自己的锁，如何让 A 对象和 B 对象共享一把锁呢？ 用 Account.class 作为共享的锁, 缺点就是转账操作都成串行了 123456789101112class Account { private int balance; // 转账 void transfer(Account target, int amt){ synchronized(Account.class) { if (this.balance &gt; amt) { this.balance -= amt; target.balance += amt; } } } } 现实世界里，账户转账操作是支持并发的，而且绝对是真正的并行，银行所有的窗口都可以做转账操作。只要我们能仿照现实世界做转账操作，串行的问题就解决了。 我们试想在古代，没有信息化，账户的存在形式真的就是一个账本，而且每个账户都有一个账本，这些账本都统一存放在文件架上。银行柜员在给我们做转账时，要去文件架上把转出账本和转入账本都拿到手，然后做转账。这个柜员在拿账本的时候可能遇到以下三种情况： 文件架上恰好有转出账本和转入账本，那就同时拿走； 如果文件架上只有转出账本和转入账本之一，那这个柜员就先把文件架上有的账本拿到手，同时等着其他柜员把另外一个账本送回来； 转出账本和转入账本都没有，那这个柜员就等着两个账本都被送回来。 上面这个过程在编程的世界里怎么实现呢？其实用两把锁就实现了，转出账本一把，转入账本另一把。在 transfer() 方法内部，我们首先尝试锁定转出账户 this（先把转出账本拿到手），然后尝试锁定转入账户 target（再把转入账本拿到手），只有当两者都成功时，才执行转账操作。 12345678910111213141516class Account { private int balance; // 转账 void transfer(Account target, int amt){ // 锁定转出账户 synchronized(this) { // 锁定转入账户 synchronized(target) { if (this.balance &gt; amt) { this.balance -= amt; target.balance += amt; } } } } } 使用细粒度锁可以提高并行度，是性能优化的一个重要手段,但是会出现死锁的情况，比如下面这种情况： 账户 A 转账户 B 100 元，此时另一个客户找柜员李四也做个转账业务：账户 B 转账户 A 100 元，于是张三和李四同时都去文件架上拿账本，这时候有可能凑巧张三拿到了账本 A，李四拿到了账本 B。张三拿到账本 A 后就等着账本 B（账本 B 已经被李四拿走），而李四拿到账本 B 后就等着账本 A（账本 A 已经被张三拿走），他们要等多久呢？他们会永远等待下去…因为张三不会把账本 A 送回去，李四也不会把账本 B 送回去。我们姑且称为死等吧。 解决死锁在第四节讲。 3. Happens-Before 规则前面一个操作的结果对后续操作是可见的,Happens-Before 约束了编译器的优化行为，虽允许编译器优化，但是要求编译器优化后一定遵守 Happens-Before 规则 3.1 程序的顺序性规则在一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作 12345678910111213class VolatileExample { int x = 0; volatile boolean v = false; public void writer() { x = 42; //先发生 v = true; //后发生 } public void reader() { if (v == true) { // 这里 x 会是多少呢？ } }} 3.2 volatile 变量规则对一个 volatile 变量的写操作， Happens-Before 于后续对这个 volatile 变量的读操作 3.3 传递性规则如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C 3.4 管程中锁的规则对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。 管程是一种通用的同步原语，在 Java 中指的就是 synchronized，synchronized 是 Java 里对管程的实现。 123456synchronized (this) { // 此处自动加锁 // x 是共享变量, 初始值 =10 if (this.x &lt; 12) { this.x = 12; } } // 此处自动解锁 假设 x 的初始值是 10，线程 A 执行完代码块后 x 的值会变成 12（执行完自动释放锁），线程 B 进入代码块时，能够看到线程 A 对 x 的写操作，也就是线程 B 能够看到 x==12。这个也是符合我们直觉的 3.5 线程 start() 规则主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。 123456789Thread B = new Thread(()-&gt;{ // 主线程调用 B.start() 之前 // 所有对共享变量的修改，此处皆可见 // 此例中，var==77});// 此处对共享变量 var 修改var = 77;// 主线程启动子线程B.start(); 3.6 线程 join() 规则主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作。当然所谓的“看到”，指的是对共享变量的操作. 换句话说就是，如果在线程 A 中，调用线程 B 的 join() 并成功返回，那么线程 B 中的任意操作 Happens-Before 于该 join() 操作的返回。 123456789101112Thread B = new Thread(()-&gt;{ // 此处对共享变量 var 修改 var = 66;});// 例如此处对共享变量修改，// 则这个修改结果对线程 B 可见// 主线程启动子线程B.start();B.join()// 子线程所有对共享变量的修改// 在主线程调用 B.join() 之后皆可见// 此例中，var==66 4. 如何预防死锁4.1 死锁发生的四个条件 互斥，共享资源 X 和 Y 只能被一个线程占用； 占有且等待，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X； 不可抢占，其他线程不能强行抢占线程 T1 占有的资源； 循环等待，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等待。 4.2 破坏死锁条件 对于“占用且等待”这个条件，我们可以一次性申请所有的资源，这样就不存在等待了。 对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。 对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不存在循环了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//利用上面转账的例子class Allocator { private List&lt;Object&gt; als = new ArrayList&lt;&gt;(); // 一次性申请所有资源 synchronized boolean apply( Object from, Object to){ if(als.contains(from) || als.contains(to)){ return false; } else { als.add(from); als.add(to); } return true; } // 归还资源 synchronized void free( Object from, Object to){ als.remove(from); als.remove(to); }} class Account { // actr 应该为单例 private Allocator actr; private int balance; // 转账 void transfer(Account target, int amt){ // 一次性申请转出账户和转入账户，直到成功 while(!actr.apply(this, target))； //while 死循环 try{ // 锁定转出账户 synchronized(this){ // 锁定转入账户 synchronized(target){ if (this.balance &gt; amt){ this.balance -= amt; target.balance += amt; } } } } finally { actr.free(this, target) } } } 破坏不可抢占条件看上去很简单，核心是要能够主动释放它占有的资源，这一点 synchronized 是做不到的。原因是 synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。 1234567891011121314151617181920212223class Account { private int id; private int balance; // 转账 void transfer(Account target, int amt){ Account left = this ① Account right = target; ② if (this.id &gt; target.id) { ③ left = target; ④ right = this; ⑤ } ⑥ // 锁定序号小的账户 synchronized(left){ // 锁定序号大的账户 synchronized(right){ if (this.balance &gt; amt){ this.balance -= amt; target.balance += amt; } } } } } 5. 等待通知模式优化循环等待最好的方案应该是：如果线程要求的条件（转出账本和转入账本同在文件架上）不满足，则线程阻塞自己，进入等待状态；当线程要求的条件（转出账本和转入账本同在文件架上）满足后，通知等待的线程重新执行。其中，使用线程阻塞的方式就能避免循环等待消耗 CPU 的问题。 类比就医环节： 就医流程基本上是这样： 患者先去挂号，然后到就诊门口分诊，等待叫号； 当叫到自己的号时，患者就可以找大夫就诊了； 就诊过程中，大夫可能会让患者去做检查，同时叫下一位患者； 当患者做完检查后，拿检测报告重新分诊，等待叫号； 当大夫再次叫到自己的号时，患者再去找大夫就诊。 下面我们来对比看一下前面都忽视了哪些细节。 患者到就诊门口分诊，类似于线程要去获取互斥锁；当患者被叫到时，类似线程已经获取到锁了。 大夫让患者去做检查（缺乏检测报告不能诊断病因），类似于线程要求的条件没有满足。 患者去做检查，类似于线程进入等待状态；然后大夫叫下一个患者，这个步骤我们在前面的等待 - 通知机制中忽视了，这个步骤对应到程序里，本质是线程释放持有的互斥锁。 患者做完检查，类似于线程要求的条件已经满足；患者拿检测报告重新分诊，类似于线程需要重新获取互斥锁，这个步骤我们在前面的等待 - 通知机制中也忽视了。 5.1 synchronized 实现等待 - 通知机制wait方法原理（会释放锁）： notify方法原理： 为什么说是曾经满足过呢？因为notify() 只能保证在通知时间点，条件是满足的。而被通知线程的执行时间点和通知的时间点基本上不会重合，所以当线程执行的时候，很可能条件已经不满足了（保不齐有其他线程插队）。 上面我们一直强调 wait()、notify()、notifyAll() 方法操作的等待队列是互斥锁的等待队列，所以如果 synchronized 锁定的是 this，那么对应的一定是 this.wait()、this.notify()、this.notifyAll()；如果 synchronized 锁定的是 target，那么对应的一定是 target.wait()、target.notify()、target.notifyAll() 。而且 wait()、notify()、notifyAll() 这三个方法能够被调用的前提是已经获取了相应的互斥锁，所以我们会发现 wait()、notify()、notifyAll() 都是在 synchronized{}内部被调用的。如果在 synchronized{}外部调用，或者锁定的 this，而用 target.wait() 调用的话，JVM 会抛出一个运行时异常：java.lang.IllegalMonitorStateException。 等待 - 通知机制的基本原理搞清楚后，我们就来看看它如何解决一次性申请转出账户和转入账户的问题吧。在这个等待 - 通知机制中，我们需要考虑以下四个要素。 互斥锁：上一篇文章我们提到 Allocator 需要是单例的，所以我们可以用 this 作为互斥锁。 线程要求的条件：转出账户和转入账户都没有被分配过。 何时等待：线程要求的条件不满足就等待。 何时通知：当有线程释放账户时就通知。 ps：因为当 wait() 返回时，有可能条件已经发生变化了，曾经条件满足，但是现在已经不满足了，所以要重新检验条件是否满足。 12345678910111213141516171819202122class Allocator { private List&lt;Object&gt; als; // 一次性申请所有资源 synchronized void apply(Object from, Object to){ // 经典写法 while(als.contains(from) || als.contains(to)){ try{ wait(); //不满足就wait }catch(Exception e){ } } als.add(from); als.add(to); } // 归还资源 synchronized void free( Object from, Object to){ als.remove(from); als.remove(to); notifyAll(); }} notify() 是会随机地通知等待队列中的一个线程，而 notifyAll() 会通知等待队列中的所有线程。 尽量使用 notifyAll()，因为使用notify可能会造成有的线程再也不能被唤醒了 6. 管程Java 采用的是管程技术，synchronized 关键字及 wait()、notify()、notifyAll() 这三个方法都是管程的组成部分。而管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。但是管程更容易使用，所以 Java 选择了管程。 管程，对应的英文是 Monitor，很多 Java 领域的同学都喜欢将其翻译成“监视器“。所谓管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。翻译为 Java 领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。那管程是怎么管的呢？ 6.1 MESA 模型在管程的发展史上，先后出现过三种不同的管程模型，分别是：Hasen 模型、Hoare 模型和 MESA 模型。其中，现在广泛应用的是 MESA 模型，并且 Java 管程的实现参考的也是 MESA 模型。所以今天我们重点介绍一下 MESA 模型。 在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。 6.1.1 解决互斥管程解决互斥问题的思路很简单，就是将共享变量及其对共享变量的操作统一封装起来。 在下图中，管程 X 将共享变量 queue 这个队列和相关的操作入队 enq()、出队 deq() 都封装起来了； 线程 A 和线程 B 如果想访问共享变量 queue，只能通过调用管程提供的 enq()、deq() 方法来实现； enq()、deq() 保证互斥性，只允许一个线程进入管程。不知你有没有发现，管程模型和面向对象高度契合的。 6.1.2 解决同步在管程模型里，共享变量和对共享变量的操作是被封装起来的，图中最外层的框就代表封装的意思。框的上面只有一个入口，并且在入口旁边还有一个入口等待队列。当多个线程同时试图进入管程内部时，只允许一个线程进入，其他线程则在入口等待队列中等待。这个过程类似就医流程的分诊，只允许一个患者就诊，其他患者都在门口等待。 管程里还引入了条件变量的概念，而且每个条件变量都对应有一个等待队列，如下图，条件变量 A 和条件变量 B 分别都有自己的等待队列。 那条件变量和等待队列的作用是什么呢？其实就是解决线程同步问题。你也可以结合上面提到的入队出队例子加深一下理解。 假设有个线程 T1 执行数据出队操作，不过需要注意的是执行出队操作，有个前提条件，就是队列中的数据不能是空的，而队列不空这个前提条件就是管程里的条件变量。 如果线程 T1 进入管程后恰好发现队列是空的，那怎么办呢？等待啊，去哪里等呢？就去条件变量对应的等待队列里面等。此时线程 T1 就去“队列不空”这个条件变量的等待队列中等待。这个过程类似于大夫发现你要去验个血，于是给你开了个验血的单子，你呢就去验血的队伍里排队。线程 T1 进入条件变量的等待队列后，是允许其他线程进入管程的。这和你去验血的时候，医生可以给其他患者诊治，道理都是一样的。 再假设之后另外一个线程 T2 执行数据入队操作，入队操作执行成功之后，“队列不空”这个条件对于线程 T1 来说已经满足了，此时线程 T2 要通知 T1，告诉它需要的条件已经满足了。当线程 T1 得到通知后，会从等待队列里面出来，但是出来之后不是马上执行，而是重新进入到入口等待队列里面。这个过程类似你验血完，回来找大夫，需要重新分诊。 条件变量及其等待队列我们讲清楚了，下面再说说 wait()、notify()、notifyAll() 这三个操作。前面提到线程 T1 发现“队列不空”这个条件不满足，需要进到对应的等待队列里等待。这个过程就是通过调用 wait() 来实现的。如果我们用对象 A 代表“队列不空”这个条件，那么线程 T1 需要调用 A.wait()。同理当“队列不空”这个条件满足时，线程 T2 需要调用 A.notify() 来通知 A 等待队列中的一个线程，此时这个队列里面只有线程 T1。至于 notifyAll() 这个方法，它可以通知等待队列中的所有线程。 这里我还是来一段代码再次说明一下吧。下面的代码实现的是一个阻塞队列，阻塞队列有两个操作分别是入队和出队，这两个方法都是先获取互斥锁，类比管程模型中的入口。 对于入队操作，如果队列已满，就需要等待直到队列不满，所以这里用了notFull.await();。 对于出队操作，如果队列为空，就需要等待直到队列不空，所以就用了notEmpty.await();。 如果入队成功，那么队列就不空了，就需要通知条件变量：队列不空notEmpty对应的等待队列。 如果出队成功，那就队列就不满了，就需要通知条件变量：队列不满notFull对应的等待队列。 123456789101112131415161718192021222324252627282930313233343536373839//实现的是一个阻塞队列，阻塞队列有两个操作分别是入队和出队，这两个方法都是先获取互斥锁public class BlockedQueue&lt;T&gt;{ final Lock lock = new ReentrantLock(); // 条件变量：队列不满 final Condition notFull = lock.newCondition(); // 条件变量：队列不空 final Condition notEmpty = lock.newCondition(); // 入队 void enq(T x) { lock.lock(); try { while (队列已满){ // 等待队列不满 notFull.await(); } // 省略入队操作... // 入队后, 通知可出队 notEmpty.signal(); }finally { lock.unlock(); } } // 出队 void deq(){ lock.lock(); try { while (队列已空){ // 等待队列不空 notEmpty.await(); } // 省略出队操作... // 出队后，通知可入队 notFull.signal(); }finally { lock.unlock(); } }} 6.1.3 wait() 的正确姿势1234//编程范式：用if会造成虚假唤醒while(条件不满足) { wait();} Hasen 模型、Hoare 模型和 MESA 模型的一个核心区别就是当条件满足后，如何通知相关线程。管程要求同一时刻只允许一个线程执行，那当线程 T2 的操作使线程 T1 等待的条件满足时，T1 和 T2 究竟谁可以执行呢？ Hasen 模型里面，要求 notify() 放在代码的最后，这样 T2 通知完 T1 后，T2 就结束了，然后 T1 再执行，这样就能保证同一时刻只有一个线程执行。hasen 是执行完，再去唤醒另外一个线程，能够保证线程的执行。 Hoare 模型里面，T2 通知完 T1 后，T2 阻塞，T1 马上执行；等 T1 执行完，再唤醒 T2，也能保证同一时刻只有一个线程执行。但是相比 Hasen 模型，T2 多了一次阻塞唤醒操作。hoare，是中断当前线程，唤醒另外一个线程，执行玩再去唤醒，也能够保证完成。 MESA 管程里面，T2 通知完 T1 后，T2 还是会接着执行，T1 并不立即执行，仅仅是从条件变量的等待队列进到入口等待队列里面。这样做的好处是 notify() 不用放到代码的最后，T2 也没有多余的阻塞唤醒操作。但是也有个副作用，就是当 T1 再次执行的时候，可能曾经满足的条件，现在已经不满足了，所以需要以循环方式检验条件变量。 6.1.4 notify什么时候使用 所有等待线程拥有相同的等待条件； 所有等待线程被唤醒后，执行相同的操作； 只需要唤醒一个线程。 wait和sleep的区别 相同点： 都是让线程阻塞 都可以接受到中断通知 不同点： 在同步代码块中，sleep不会释放锁，wait会释放锁。所以wait方法必须在synchronized 保护的代码中使用，而sleep没有这个要求。 sleep方法必须定义一个时间，时间到期后自动恢复。而wait可以不设置参数，意味着永久等待 wait是Object类的方法，sleep是Thread的方法。 第三部分、Java中的线程现代操作系统调度的最小单元是线程，也叫轻量级进程(Light Weight Process)，在一个进程里可以创建多个线程，这些线程都拥有各自的计数器、堆栈和局部变量等属性，并且能够访问共享的内存变量。处理器在这些线程上高速切换，让使用者感觉到这些线程在同时执行。 1. 线程的发展路程1.1 操作系统的发展操作系统的发展经历了三个阶段： 手工操作： 单道批处理系统：输入机与主机之间增加了一个存储设备磁带(盘)，单道批处理系统是将作业一个一个加入内存的，那么某一个作业因为等待磁带（盘）或者其他I/O操作而暂停时，那计算机就只能一直阻塞，直到该I/O完成。对于CPU操作密集型的程序，I/O操作相对较少，因此浪费的时间也很少。但是对于I/O操作较多的场景来说，CPU的资源是属于严重浪费的。 多道批处理系统： 为了解决单道批处理系统因为输入/输出（I/O）请求后，导致计算机等待I/O完成而造成的计算机的资源的浪费。接下来又出现了多道批处理系统。多道批处理系统与单道批处理系统的主要区别是在内存中允许一个或多个作业，当一个作业在等待I/O处理时，多批处理系统会通过相应调度算法调度另外一个作业让计算机执行。从而使CPU的利用率得到更大的提高 1.2 进程的由来在多道批处理系统中引申出了一个非常重要的模式，即允许多个作业进入内存并运行。由于在内存中存储了多个作业，那么多个作业如何进行区分？当某个作业因为等待I/O暂停时，怎么恢复到之前的运行状态呢？ 所以这个时候，人们就发明了进程这一概念，用进程来保存每个作业的数据与运行状态，同时对每个进程划分对应的内存地址空间（代码、数据、进程空间、打开的文件），并且要求进程只能使用它自己的内存空间。那么就可以达到作业的区分及恢复。 1.3 线程的由来因为一个进程在一个时间段内只能做一件事情。如果某个程序有多个任务，只能逐个执行这些任务。同时进程中存储了大量信息（数据，进程运行状态信息等）。那么当计算机进行进程切换的时候，必然存在着很大的时间与空间消耗（因为每个进程对应不同内存地址空间，进程的切换，实际是处理器处理不同的地址空间） 为了实现一个进程中任务的切换同时又避免地址空间的切换：发明了线程这一概念，用线程表示进程中的不同任务，同时又将计算机实际调度的单元转到线程。这样就避免了进程的内存地址空间的切换，也达到了多任务的并发执行。 1.4 进程和线程的区别 进程是CPU分配系统资源的基本单位，线程是CPU调度和执行的基本单位。 一个进程可以包含多个线程，进程拥有自己独立的地址空间，而进程中的不同线程共享该进程的地址空间 进程的切换会涉及到虚拟地址空间的切换，开销比较大，线程的切换开销比较小 1.5 为什么要使用多线程 更多的处理器核心：一个 单线程程序在运行时只能使用一个处理器核心，那么再多的处理器核心加入也无法显著提升 该程序的执行效率。相反，如果该程序使用多线程技术，将计算逻辑分配到多个处理器核心 上，就会显著减少程序的处理时间，并且随着更多处理器核心的加入而变得更有效率 更快的响应时间：一笔订单的创建，它包括插入订单数据、生成订单快照、发送邮件通知卖家和记录 货品销售数量等。可以使用多线程技术，即将数据一致性不强的操作派发给其他线程处 理(也可以使用消息队列)，如生成订单快照、发送邮件等。这样做的好处是响应用户请求的线 程能够尽可能快地处理完成，缩短了响应时间，提升了用户体验 更好的编程模型 1.6 线程的优先级现代操作系统基本采用时分的形式调度运行的线程，操作系统会分出一个个时间片，线程会分配到若干时间片，当线程的时间片用完了就会发生线程调度，并等待着下次分配。线程分配到的时间片多少也就决定了线程使用处理器资源的多少，而线程优先级就是决定线程需要多或者少分配一些处理器资源的线程属性。 在Java线程中，通过一个整型成员变量priority来控制优先级，优先级的范围从1~10，在线程构建的时候可以通过setPriority(int)方法来修改优先级，默认优先级是5，优先级高的线程分配时间片的数量要多于优先级低的线程。 1.7 线程的6种状态 NEW（初始化状态） RUNNABLE（可运行 / 运行状态） BLOCKED（阻塞状态） WAITING（无时限等待） TIMED_WAITING（有时限等待） TERMINATED（终止状态） 1.8 Daemon线程Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持性工作。这 意味着，当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。可以通过调 用Thread.setDaemon(true)将线程设置为Daemon线程。 2. 启动和终止线程调用线程的start()方法进行启动，随着run()方法的执行完毕，线程也随之终止 2.1 构造线程的三种方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package server.doc.thread;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;public class ThreadTest { public static void main(String[] args) throws ExecutionException, InterruptedException { A a = new A(); Thread threadA = new Thread(a); threadA.start(); B b = new B(); Thread threadB = new Thread(b); threadB.start(); C c = new C(); FutureTask&lt;Integer&gt; integerFutureTask = new FutureTask&lt;&gt;(c); //FutureTask&lt;V&gt;()是Runnable的实现类 Thread threadC = new Thread(integerFutureTask); threadC.start(); System.out.println(integerFutureTask.get());//可通过get方法获得返回值 }}class A extends Thread{ @Override public void run() { System.out.println(&quot;=======继承Thread类创建线程====&quot;); }}class B implements Runnable{ @Override public void run() { System.out.println(&quot;=======实现runnable接口创建线程====&quot;); }}//实现Callable接口创建线程,Integer就是返回值class C implements Callable&lt;Integer&gt; { @Override public Integer call() throws Exception { System.out.println(&quot;=======实现Callable接口创建线程====&quot;); return 2; }} 2.2 启动线程start源码1234567891011121314151617181920212223242526272829// 该方法可以创建一个新的线程出来public synchronized void start() { // 如果没有初始化，抛异常 if (threadStatus != 0) throw new IllegalThreadStateException(); group.add(this); // started 是个标识符，我们在做一些事情的时候，经常这么写 // 动作发生之前标识符是 false，发生完成之后变成 true boolean started = false; try {// 这里会创建一个新的线程，执行完成之后，新的线程已经在运行了，既 target 的内容已经在运行了 start0(); // 这里执行的还是主线程 started = true; } finally { try { // 如果失败，把线程从线程组中删除 if (!started) { group.threadStartFailed(this); } // Throwable 可以捕捉一些 Exception 捕捉不到的异常，比如说子线程抛出的异常 } catch (Throwable ignore) { /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ } }}// 开启新线程使用的是 native 方法private native void start0(); 2.3 正确的停止线程中断可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程的interrupt() 方法对其进行中断操作。 从原理上讲应该用 interrupt 来请求中断，而不是强制停止，因为这样可以避免数据错乱，也可以让线程有时间结束收尾工作。 123while (!Thread.currentThread().islnterrupted() &amp;&amp; more work to do) { do more work} 我们一旦调用某个线程的 interrupt() 之后，这个线程的中断标记位就会被设置成 true。每个线程都有这样的标记位，当线程执行时，应该定期检查这个标记位，如果标记位被设置成 true，就说明有程序想终止该线程。回到源码，可以看到在 while 循环体判断语句中，首先通过 Thread.currentThread().isInterrupt() 判断线程是否被中断，随后检查是否还有工作要做。 被 interrupt 的线程，是怎么收到通知的呢？一种是异常，另一种是主动检测。 异常： 当线程 A 处于 WAITING、TIMED_WAITING 状态时，如果其他线程调用线程 A 的 interrupt() 方法，会使线程 A 返回到 RUNNABLE 状态，同时线程 A 的代码会触发 InterruptedException 异常。上面我们提到转换到 WAITING、TIMED_WAITING 状态的触发条件，都是调用了类似 wait()、join()、sleep() 这样的方法，我们看这些方法的签名，发现都会 throws InterruptedException 这个异常。这个异常的触发条件就是：其他线程调用了该线程的 interrupt() 方法。 当线程 A 处于 RUNNABLE 状态时，并且阻塞在 java.nio.channels.InterruptibleChannel 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 会触发 java.nio.channels.ClosedByInterruptException 这个异常；而阻塞在 java.nio.channels.Selector 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 的 java.nio.channels.Selector 会立即返回。 主动监测： 线程通过检查自身是否被中断来进行响应，线程通过方法isInterrupted()来进行判断是否 被中断，也可以调用静态方法Thread.interrupted()对当前线程的中断标识位进行复位。 sleep情况下能否感召到打断位？ 如果 sleep、wait 等可以让线程进入阻塞的方法使线程休眠了，而处于休眠中的线程被中断，那么线程是可以感受到中断信号的，并且会抛出一个 InterruptedException 异常，同时清除中断信号，将中断标记位设置成 false。这样一来就不用担心长时间休眠中线程感受不到中断了，因为即便线程还在休眠，仍然能够响应中断通知，并抛出异常。 3.线程间通信的几种方式 volatile和synchronized关键字 对于同步块的实现使用了monitorenter和monitorexit指令，而同步方法则 是依靠方法修饰符上的ACC_SYNCHRONIZED来完成的。无论采用哪种方式，其本质是对一 个对象的监视器(monitor)进行获取，而这个获取过程是排他的，也就是同一时刻只能有一个 线程获取到由synchronized所保护对象的监视器。 任意一个对象都拥有自己的监视器，当这个对象由同步块或者这个对象的同步方法调用 时，执行方法的线程必须先获取到该对象的监视器才能进入同步块或者同步方法，而没有获 取到监视器(执行该方法)的线程将会被阻塞在同步块和同步方法的入口处，进入BLOCKED 状态。 等待/通知机制（wait / notify） 等待/通知机制，是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B 调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而 执行后续操作。上述两个线程通过对象O来完成交互，而对象上的wait()和notify/notifyAll()的 关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package _2不同的生产者消费者模式;/** * 线程之间的通信问题：两个线程交替执行A B操作同一个变量+1，-1* */public class A { public static void main(String[] args) { Data data = new Data(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.increment(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;A&quot;).start(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.decrement(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;B&quot;).start(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.increment(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;C&quot;).start(); new Thread(()-&gt;{ for (int i = 0; i &lt; 10; i++) { try { data.decrement(); } catch (InterruptedException e) { e.printStackTrace(); } } },&quot;D&quot;).start(); }}//1.判断是否需要等待//2.执行业务//3.通知其他线程class Data{ //数字，资源类 private int num = 0; //+1 public synchronized void increment() throws InterruptedException { while (num != 0) { //用if会出现虚假唤醒现象 this.wait(); } num++; System.out.println(Thread.currentThread().getName()+&quot;=====&quot;+num); //通知其他线程，+1完毕 this.notifyAll(); } //-1 public synchronized void decrement() throws InterruptedException { while (num == 0) { this.wait(); } num--; System.out.println(Thread.currentThread().getName()+&quot;=====&quot;+num); this.notifyAll(); }}复制代码 Thread.join()方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package server.doc.thread;public class JoinTest implements Runnable { @Override public void run() { System.out.println(&quot;join thread demo&quot;); } public static void main(String[] args) throws InterruptedException { System.out.println(&quot;main thread start...&quot;); JoinTest joinTest = new JoinTest(); Thread thread = new Thread(joinTest); thread.setName(&quot;joinTest thread&quot;); thread.start(); thread.join(); System.out.println(&quot;main thread end&quot;); }}//没有join的时候：main thread start...main thread endjoin thread demo//有join的时候main thread start...join thread demomain thread end也就是说：当main线程去调用t.join()是，会将自己当前线程阻塞，等到t线程执行完成到达完结状态，main线程才可以继续执行复制代码//join 源码public final synchronized void join(long millis) throws InterruptedException { long base = System.currentTimeMillis(); long now = 0; // 首先校验参数是否合法 if (millis &lt; 0) { throw new IllegalArgumentException(&quot;timeout value is negative&quot;); } // 如果join方法没有参数，则相当于直接调用wait方法 if (millis == 0) { while (isAlive()) { wait(0); } } else { while (isAlive()) {//判断当前的线程是否处于活动状态。什么是活动状态呢？活动状态就是线程已经启动且尚未终止 long delay = millis - now; if (delay &lt;= 0) { break; } wait(delay); now = System.currentTimeMillis() - base; } } }复制代码 ThreadLocal（后续讲解）","link":"/2021/05/06/Java%E5%B9%B6%E5%8F%91%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80-%E4%B8%8A/"},{"title":"Java并发理论基础-下","text":"Java并发理论基础下章主要描述了以下内容 Lock接口实现的锁 常见的并发容器 常见的并发工具类 线程池 Lock接口synchronized在1.6之后做了很多的优化，效率提高了很多，但是还有很多问题是synchronized无法解决的，因此Lock接口及其实现方法就出现了： 能够响应中断。synchronized 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程。但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有机会释放曾经持有的锁 A。这样就破坏了不可抢占条件了。 支持超时。如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。 非阻塞地获取锁。如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。 API接口方法123456void lock(); //获取锁，调用该方法的线程会获得锁，获得锁之后从该方法返回void lockInterruptibly() throws InterruptedException; //可中断的获得锁boolean tryLock(); //尝试非阻塞的获取锁，调用该方法后立即返回，如果能获取返回true，否则返回falseboolean tryLock(long time, TimeUnit unit) throws InterruptedException; //超时的获取锁void unlock(); //释放锁Condition newCondition(); //获取等待通知组件，该组件和当前锁绑定，当前线程获得了锁之后才能调用组件的wait方法释放锁 Lock的一般使用实例1234567Lock lock = new ReentrantLock(); lock.lock(); try { //业务逻辑 }finally { lock.unlock();//在finally块中释放锁，目的是保证在获取到锁之后，最终能够被释放。 } synchronized和ReentrantLock的区别 synchronized是JVM内建的同步机制，是一个关键字，ReentrantLock是一个类。 ReentrantLock可以实现公平锁，可以自定义条件，可以定义超时时间，需要显式的释放锁，而synchronized只能是非公平锁。 每一个lock操作，为了保证锁的释放，最好在finally中显式的unlock lock只适用于代码块，而synchronized可以用来修饰方法，代码块 在Java6之前，synchronized完全依靠操作系统的互斥锁来实现，需要进行用户态和内核态的切换，所以开销较大，但随着一系列的锁优化，synchronized的性能也越来越好了 队列同步器AQSAQS的全称是AbstractQueuedSynchronizer，它的定位是为Java中几乎所有的锁和同步器提供一个基础框架。 AQS是基于FIFO的队列实现的，并且内部维护了一个volatile修饰的状态变量state，通过原子更新这个状态变量state即可以实现加锁解锁操作。 AQS的源码解析 主要内部类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647static final class Node { //初始化两个节点引用 static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; static final int CANCELLED = 1; // 标识线程已取消 static final int SIGNAL = -1; // 标识后继节点需要唤醒 static final int CONDITION = -2; // 标识线程等待在一个条件上 static final int PROPAGATE = -3; // 标识后面的共享锁需要无条件的传播（共享锁需要连续唤醒读的线程） volatile int waitStatus; //// 当前节点保存的线程对应的等待状态 volatile Node prev; volatile Node next; volatile Thread thread; // 当前节点保存的线程 Node nextWaiter; final boolean isShared() { return nextWaiter == SHARED; } final Node predecessor() throws NullPointerException { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } Node() { // Used to establish initial head or SHARED marker } Node(Thread thread, Node mode) { // Used by addWaiter this.nextWaiter = mode; this.thread = thread; } Node(Thread thread, int waitStatus) { // Used by Condition this.waitStatus = waitStatus; this.thread = thread; } } 主要属性 123456789101112131415161718 private transient volatile Node head; //维护一个头节点和尾节点的引用 private transient volatile Node tail; private volatile int state; //同步状态，用volatile修饰 //获取当前同步状态 protected final intgetState() { return state; } //设置新的同步状态 protected final void setState(int newState) { state = newState;} //通过unsafe类的CAS修改同步状态 protected final boolean compareAndSetState(int expect, int update) { // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } 子类需要实现的方法–模版方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495//提供给子类重写，独占式的获取同步状态，实现该方法需要查询当前状态并判断是否符合预期，然后用CAS来设置同步状态 protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } //提供给子类重写，独占式的释放同步状态，等待的线程将有机会获取同步状态 protected boolean tryRelease(int arg) { throw new UnsupportedOperationException(); } //共享式的获取同步状态，返回值大于0表示成功 protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException(); } //共享式的释放同步状态 protected boolean tryReleaseShared(int arg) { throw new UnsupportedOperationException(); } //当前同步器是否在独占模式下被线程占用 protected boolean isHeldExclusively() { throw new UnsupportedOperationException(); } //独占式获取同步状态，获取成功则返回，否则进入同步队列等待 public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } //和上面这个方法相同，但是响应中断 public final void acquireInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); } //在上面的方法中增加了时间限制 public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout); } //独占式释放同步状态，释放后唤醒同步队列中的第一个节点 public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } //共享式的获取同步状态，主要区别是同一时间可以有多个线程获取到同步状态 public final void acquireShared(int arg) { if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); } //和上面相同，响应中断 public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); } public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); return tryAcquireShared(arg) &gt;= 0 || doAcquireSharedNanos(arg, nanosTimeout); } //共享式的释放同步状态 public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; } 节点加入等待队列流程同步器将节点加入到同步队列的过程：加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法:**compareAndSetTail(Node expect,Node update)**，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式 与之前的尾节点建立关联。 1234private final boolean compareAndSetTail(Node expect, Node update) { return unsafe.compareAndSwapObject(this, tailOffset, expect, update);} 设置首节点的过程设置首节点的过程：同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。 设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节 点设置成为原首节点的后继节点并断开原首节点的next引用即可。 acquire流程分析123456AQS ----&gt; acquire()public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 123456789101112131415161718192021222324252627282930313233343536373839404142tryAcquire 方法针对公平锁和非公平锁有着不同的实现，总的来说是保证线程安全的获取同步状态 //Fair version of tryAcquire. Don't grant access unless recursive call or no waiters or is first. protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; //hasQueuedPredecessors 是公平锁和非公平锁的区别 compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //可重入锁的实现 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } 如果tryAcquire不能获取锁： 123456789101112131415161718192021222324252627282930313233343536373839404142434445//构造新的尾节点，通过CAS来放入队列尾部//Creates and enqueues node for current thread and given mode.Params://mode – Node.EXCLUSIVE for exclusive, Node.SHARED for sharedReturns://the new nodeprivate Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); ////如果多个线程获取同步状态失败，并发的添加到list，也许会顺序混乱，通过CAS变 得“串行化”了 return node; }/*Inserts node into queue, initializing if necessary. See picture above.Params:node – the node to insertReturns:node's predecessor*/private Node enq(final Node node) { for (;;) { ////通过“死循环”来保证节点的正确添加 Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; //只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线 程不断地尝试设置 if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 12345678910111213141516171819202122//acquireQueued --- 节点进入同步队列之后，就进入了一个自旋的过程，每个节点(或者说每个线程)都在自 省地观察，当条件满足，获取到了同步状态，就可以从这个自旋过程中退出，否则依旧留在这 个自旋过程中(并会阻塞节点的线程):final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { //死循环自旋的过程 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } acquire方法调用流程： 前驱节点为头节点且能够获取同步状态的判断条件和线程进入等待状态是获 取同步状态的自旋过程。当同步状态获取成功之后，当前线程从acquire(int arg)方法返回，如果 对于锁这种并发组件而言，代表着当前线程获取了锁。 当前线程获取同步状态并执行了相应逻辑之后，就需要释放同步状态，使得后续节点能 够继续获取同步状态。通过调用同步器的release(int arg)方法可以释放同步状态，该方法在释 放了同步状态之后，会唤醒其后继节点(进而使后继节点重新尝试获取同步状态)。 12345678910@ReservedStackAccess public final boolean release(int arg) { if (tryRelease(arg)) { //tryRelease针对公平锁和非公平锁也有不同的实现 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } 重入锁重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞，该特性的实现需要解决以下两个问题。 线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。 锁的最终释放。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。 12345678910111213141516171819protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { //如果当前线程就是拥有锁的线程 int nextc = c + acquires; //则共享变量++ if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } 读写锁读写锁，并不是 Java 语言特有的，而是一个广为使用的通用技术，所有的读写锁都遵守以下三条基本原则： 允许多个线程同时读共享变量； 只允许一个线程写共享变量； 如果一个写线程正在执行写操作，此时禁止读线程读共享变量。 读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升。 LockSupport类LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread) 方法来唤醒一个被阻塞的线程： 1234567891011public static void park(Object blocker) { //阻塞当前线程 Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null); }public static void unpark(Thread thread) { //唤醒当前线程 if (thread != null) UNSAFE.unpark(thread); } Condition接口等待通知模式：任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、 wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式 Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式 新版生产者和消费者一般都会将Condition对象作为成员变量。当调用await()方法后，当前线程会释放锁并在此等待，而其他线程调用Condition对象的signal()方法，通知当前线程后，当前线程才从await()方法返回，并且在返回前已经获取了锁 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class SharedDate{ //共享资源类 private int num = 0; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void increment(){ lock.lock(); try { while (num != 0) condition.await(); //1. 判断释放满足条件，注意用while num++; //2. 业务逻辑 System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); condition.signal(); //3. 唤醒其他线程 } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } public void decrement(){ lock.lock(); try { while (num == 0) condition.await(); num--; System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); condition.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }}/** 需求：两个线程操作一个初始值为0的变量，一个线程操作变量+1，另一个线程操作变量-1。操作10次后变量依旧为0 * */public class ConditionDemo { public static void main(String[] args) { // 线程操作资源类 SharedDate sharedDate = new SharedDate(); Thread a = new Thread(()-&gt;{ for (int i = 0; i &lt; 5; i++) { sharedDate.increment(); } },&quot;A&quot;); Thread b = new Thread(()-&gt;{ for (int i = 0; i &lt; 5; i++) { sharedDate.decrement(); } },&quot;B&quot;); a.start(); b.start(); } } 精确通知不同的等待者12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485class SharedDate{ //共享资源类 private int num = 1; //1 A ，2 B ， 3 C private Lock lock = new ReentrantLock(); private Condition c1 = lock.newCondition(); //多个条件实现精确通知 private Condition c2 = lock.newCondition(); private Condition c3 = lock.newCondition(); public void print2(int a){ lock.lock(); try { while (num != 1) c1.await(); for (int i = 0; i &lt; a; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); } num = 2; //要修改状态位，以此来唤醒不同的线程 c2.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } public void print4(int a){ lock.lock(); try { while (num != 2) c2.await(); for (int i = 0; i &lt; a; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); } num = 3;//要修改状态位，以此来唤醒不同的线程 c3.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } public void print8(int a){ lock.lock(); try { while (num != 3) c3.await(); for (int i = 0; i &lt; a; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + num); } num = 1;//要修改状态位，以此来唤醒不同的线程 c1.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }}/** 需求：三个线程依次打印1，2，3。其中A线程打印2次，B线程打印4次，C线程打印6次** */public class ConditionDemo { public static void main(String[] args) { // 线程操作资源类 SharedDate sharedDate = new SharedDate(); Thread a = new Thread(()-&gt;{ sharedDate.print2(2); },&quot;A&quot;); Thread b = new Thread(()-&gt;{ sharedDate.print4(4); },&quot;B&quot;); Thread c = new Thread(()-&gt;{ sharedDate.print8(8); },&quot;C&quot;); a.start(); b.start(); c.start(); }} Java并发容器CopyOnWriteArrayListCopyOnWrite，顾名思义就是写的时候会将共享变量新复制一份出来，这样做的好处是读操作完全无锁 CopyOnWriteArrayList 内部维护了一个数组，成员变量 array 就指向这个内部数组，所有的读操作都是基于 array 进行的。 如果在遍历 array 的同时，还有一个写操作，例如增加元素，CopyOnWriteArrayList 是如何处理的呢？CopyOnWriteArrayList 会将 array 复制一份，然后在新复制处理的数组上执行增加元素的操作，执行完之后再将 array 指向这个新的数组。通过下图你可以看到，读写是可以并行的，遍历操作一直都是基于原 array 执行，而写操作则是基于新 array 进行。 ConcurrentHashMap1.1 为什么要使用ConcurrentHashMap hashMap线程不安全，hashtable效率低下 ConcurrentHashMap的锁分段技术可有效提升并发访问率，首先将数据分成一段一段地存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问 1.2 结构![image-20210502103840847](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210502103840847.png) ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁（ReentrantLock），在ConcurrentHashMap里扮演锁的角色；HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似，是一种数组和链表结构。一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得与它对应的Segment锁 1.3 初始化1.4 定位segment1.5 常用的方法操作2. ConcurrentLinkedQueue3. Java中的阻塞队列3.1 什么是阻塞队列阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。 1）支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。 2）支持阻塞的移除方法：意思是在队列为空时，获取元素的线程会等待队列变为非空。 阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器 3.2 常见的阻塞队列种类JDK 7提供了7个阻塞队列，如下。 ·ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。 ·LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。 ·PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。 ·DelayQueue：一个使用优先级队列实现的无界阻塞队列。 ·SynchronousQueue：一个不存储元素的阻塞队列。 ·LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 ·LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。 3.3 阻塞队列的实现原理ArrayBlockingQueue使用了Condition来实现 1234567891011121314151617181920212223242526272829303132333435363738394041/** Condition for waiting takes */private fnal Condition notEmpty;/** Condition for waiting puts */private fnal Condition notFull;public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); }//put方法public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == items.length) notFull.await(); enqueue(e); } finally { lock.unlock(); } }//take public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) notEmpty.await(); return dequeue(); } finally { lock.unlock(); } } 第七部分、13个原子操作类1. 原子更新基本类型3个·AtomicBoolean：原子更新布尔类型。 ·AtomicInteger：原子更新整型。 ·AtomicLong：原子更新长整型。 1.1 实现原理基于CAS（compare-and-swap）技术来实现的，所谓CAS，表征的是一些列操作的集合，获取当前数值，进行一些运算，利用CAS指令试图进行更新。如果当前数值未变，代表没有其他线程进行并发修改，则成功更新。否则，可能出现不同的选择，要么进行重试，要么就返回一个成功或者失败的结果。 1234567891011121314151617181920public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); //使用了unsafe类 private static final long valueOffset; private volatile int value; //volatile修饰的变量 static { try { valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } public AtomicInteger(int initialValue) { value = initialValue; } public AtomicInteger() { } 12345678910111213141516public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1); //调用的是unsafe类中的方法实现原子自增的 }public final int getAndAddInt(Object o, long offset, int delta) { int v; do { v = getIntVolatile(o, offset); } while (!compareAndSwapInt(o, offset, v, v + delta)); return v; }//cas底层是unsafe类中的本地方法，依赖于CPU提供的特定指令public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); 1.2 CAS的问题 CAS也并不是没有副作用，试想，其常用的失败重试机制，隐含着一个假设，即竞争情况是短暂的。大多数应用场景中，确实大部分重试只会发生一次就获得了成功，但是总是有意外情况，所以在有需要的时候，还是要考虑限制自旋的次数，以免过度消耗CPU。 另外一个就是著名的ABA问题，这是通常只在lock-free算法下暴露的问题。我前面说过CAS是在更新时比较前值，如果对方只是恰好相同，例如期间发生了 A -&gt; B -&gt; A的更新，仅仅判断数值是A，可能导致不合理的修改操作。针对这种情况，Java提供了AtomicStampedReference工具类，通过为引用建立类似版本号（stamp）的方式，来保证CAS的正确性 2. 原子更新数组·AtomicIntegerArray：原子更新整型数组里的元素。 ·AtomicLongArray：原子更新长整型数组里的元素。 ·AtomicReferenceArray：原子更新引用类型数组里的元素。 ·AtomicIntegerArray类主要是提供原子的方式更新数组里的整型，其常用方法如下。 3.原子更新引用类型4. 原子更新字段类第八部分、并发工具类1.倒计时器CountDownLatchCountDownLatch允许一个或多个线程等待其他线程完成操作。 运动员进行跑步比赛时，假设有 6 个运动员参与比赛，裁判员在终点会为这 6 个运动员分别计时，可以想象没当一个运动员到达终点的时候，对于裁判员来说就少了一个计时任务。直到所有运动员都到达终点了，裁判员的任务也才完成。这 6 个运动员可以类比成 6 个线程，当线程调用 CountDownLatch.countDown 方法时就会对计数器的值减一，直到计数器的值为 0 的时候，裁判员（调用 await 方法的线程）才能继续往下执行。 1.1 方法解析12345//整型数 N，之后调用 CountDownLatch 的countDown方法会对 N 减一，知道 N 减到 0 的时候，当前调用await方法的线程继续执行。public CountDownLatch(int count) { if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync = new Sync(count); } public void await() throws InterruptedException：调用await()方法的线程会被挂起，等待直到count值为0再继续执行。 public boolean await(long timeout, TimeUnit unit) throws InterruptedException：同await()，若等待timeout时长后，count值还是没有变为0，不再等待，继续执行。时间单位如下常用的毫秒、天、小时、微秒、分钟、纳秒、秒。 public void countDown()： count值递减1. public long getCount()：获取当前count值。 public String toString()：重写了toString()方法，多打印了count值，具体参考源码。 1.2 使用实例 创建CountDownLatch并设置计数器值。 启动多线程并且调用CountDownLatch实例的countDown()方法。 主线程调用 await() 方法，这样主线程的操作就会在这个方法上阻塞，直到其他线程完成各自的任务，count值为0，停止阻塞，主线程继续执行。 123456789101112131415161718192021222324252627282930313233343536373839404142public class CountDownLatchDemo { //线程数 private static int N = 10; // 单位：min private static int countDownLatchTimeout = 5; public static void main(String[] args) { //创建CountDownLatch并设置计数值，该count值可以根据线程数的需要设置 CountDownLatch countDownLatch = new CountDownLatch(N); //创建线程池 ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; N; i++) { cachedThreadPool.execute(() -&gt; { try { System.out.println(Thread.currentThread().getName() + &quot; do something!&quot;); } catch (Exception e) { System.out.println(&quot;Exception: do something exception&quot;); } finally { //该线程执行完毕-1 countDownLatch.countDown(); } }); } System.out.println(&quot;main thread do something-1&quot;); try { countDownLatch.await(countDownLatchTimeout, TimeUnit.MINUTES); } catch (InterruptedException e) { System.out.println(&quot;Exception: await interrupted exception&quot;); } finally { System.out.println(&quot;countDownLatch: &quot; + countDownLatch.toString()); } System.out.println(&quot;main thread do something-2&quot;); //若需要停止线程池可关闭;// cachedThreadPool.shutdown(); }} 2.循环栅栏：CyclicBarrier 开运动会时，会有跑步这一项运动，我们来模拟下运动员入场时的情况，假设有 6 条跑道，在比赛开始时，就需要 6 个运动员在比赛开始的时候都站在起点了，裁判员吹哨后才能开始跑步。跑道起点就相当于“barrier”，是临界点，而这 6 个运动员就类比成线程的话，就是这 6 个线程都必须到达指定点了，意味着凑齐了一波，然后才能继续执行，否则每个线程都得阻塞等待，直至凑齐一波即可。cyclic 是循环的意思，也就是说 CyclicBarrier 当多个线程凑齐了一波之后，仍然有效，可以继续凑齐下一波 2.1 常用方法12345678910//等到所有的线程都到达指定的临界点await() throws InterruptedException, BrokenBarrierException//与上面的await方法功能基本一致，只不过这里有超时限制，阻塞等待直至到达超时时间为止await(long timeout, TimeUnit unit) throws InterruptedException,BrokenBarrierException, TimeoutException//获取当前有多少个线程阻塞等待在临界点上int getNumberWaiting()//用于查询阻塞等待的线程是否被中断boolean isBroken() 2.2 使用实例123456789101112131415161718192021222324public class CyclicBarrierDemo { //指定必须有6个运动员到达才行 private static CyclicBarrier barrier = new CyclicBarrier(6, () -&gt; { System.out.println(&quot;所有运动员入场，裁判员一声令下！！！！！&quot;); }); public static void main(String[] args) { System.out.println(&quot;运动员准备进场，全场欢呼............&quot;); ExecutorService service = Executors.newFixedThreadPool(6); for (int i = 0; i &amp;lt; 6; i++) { service.execute(() -&amp;gt; { try { System.out.println(Thread.currentThread().getName() + &quot; 运动员，进场&quot;); barrier.await(); System.out.println(Thread.currentThread().getName() + &quot; 运动员出发&quot;); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }); }}} 2.3 CyclicBarrier 和CountDownLatch 的区别 CountDownLatch是不可以重置的，所以无法重用；而CyclicBarrier则没有这种限制，可以重用。 CountDownLatch的基本操作组合是countDown/await。调用await的线程阻塞等待countDown足够的次数，不管你是在一个线程还是多个线程里countDown，只要次数足够即可。所以就像Brain Goetz说过的，CountDownLatch操作的是事件。 CyclicBarrier的基本操作组合，则就是await，当所有的伙伴（parties）都调用了await，才会继续进行任务，并自动进行重置。注意，正常情况下，CyclicBarrier的重置都是自动发生的，如果我们调用reset方法，但还有线程在等待，就会导致等待线程被打扰，抛出BrokenBarrierException异常。CyclicBarrier侧重点是线程，而不是调用事件，它的典型应用场景是用来等待并发线程结束。 3.控制并发线程数的SemaphoreSemaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源 第九部分、线程池1. 为什么要使用线程池第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 第三：提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。但是，要做到合理利用线程池，必须对其实现原理了如指掌。 2. 线程池的实现原理2.1五种不同的标准线程池Executors目前提供了5种不同的线程池创建配置： newCachedThreadPool()，它是一种用来处理大量短时间工作任务的线程池，具有几个鲜明特点：它会试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置的时间超过60秒，则被终止并移出缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用SynchronousQueue作为工作队列。 newFixedThreadPool(int nThreads)，重用指定数目（nThreads）的线程，其背后使用的是无界的工作队列，任何时候最多有nThreads个工作线程是活动的。这意味着，如果任务数量超过了活动队列数目，将在工作队列中等待空闲线程出现；如果有工作线程退出，将会有新的工作线程被创建，以补足指定的数目nThreads。 newSingleThreadExecutor()，它的特点在于工作线程数目被限制为1，操作一个无界的工作队列，所以它保证了所有任务的都是被顺序执行，最多会有一个任务处于活动状态，并且不允许使用者改动线程池实例，因此可以避免其改变线程数目。 newSingleThreadScheduledExecutor()和newScheduledThreadPool(int corePoolSize)，创建的是个ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程。 newWorkStealingPool(int parallelism)，这是一个经常被人忽略的线程池，Java 8才加入这个创建方法，其内部会构建ForkJoinPool，利用Work-Stealing算法，并行地处理任务，不保证处理顺序。 2.2 创建七大参数 corePoolSize：核心线程数 maximumPoolSize：最大线程数 keepAliveTime：线程存活时间 TimeUnit：存活时间的单位 workQueue：工作队列，必须是阻塞队列 ThreadFactory ：创建线程的工厂 RejectedExecutionHandler：拒绝执行的策略 2.3 四大拒绝策略·AbortPolicy：直接抛出异常。 ·CallerRunsPolicy：只用调用者所在线程来运行任务。 ·DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。 ·DiscardPolicy：不处理，丢弃掉。 Ps：可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。如记录日志或持久化存储不能处理的任务。 2.4 任务处理流程![image-20210502114404422](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210502114404422.png) 2.5 提交任务submit和execute execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。 execute()方法输入的任务是一个Runnable类的实例。 submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。 2.6 线程池的大小选择策略 如果是计算型任务，说明CPU是一种稀缺的资源，线程太多会导致上下文切换，所以线程数一般为按照CPU核的数目N或者N+1； 如果是IO密集型任务，线程数 = CPU核数 × （1 + 平均等待时间/平均工作时间） 第十部分、Executor框架1. Executor框架简介1.1Executor框架的两级调度模型 在HotSpot VM的线程模型中，Java线程（java.lang.Thread）被一对一映射为本地操作系统线 程。Java线程启动时会创建一个本地操作系统线程；当该Java线程终止时，这个操作系统线程也会被回收。操作系统会调度所有线程并将它们分配给可用的CPU。 在上层，Java多线程程序通常把应用分解为若干个任务，然后使用用户级的调度器（Executor框架）将这些任务映射为固定数量的线程；在底层，操作系统内核将这些线程映射到硬件处理器上: ![image-20210503091113831](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210503091113831.png) 1.2 三大组成部分 任务。包括被执行任务需要实现的接口：Runnable接口或Callable接口。 任务的执行。包括任务执行机制的核心接口Executor，以及继承自Executor的 ExecutorService接口。Executor框架有两个关键类实现了ExecutorService接口 （ThreadPoolExecutor和ScheduledThreadPoolExecutor）。 异步计算的结果。包括接口Future和实现Future接口的FutureTask类。 ![image-20210503091241378](/Users/shengbinbin/Library/Application Support/typora-user-images/image-20210503091241378.png) 2. ThreadPoolExecutor详解Executor框架最核心的类是ThreadPoolExecutor，它是线程池的实现类，主要由下列4个组件构成。 ·corePool：核心线程池的大小。 ·maximumPool：最大线程池的大小。 ·BlockingQueue：用来暂时保存任务的工作队列。 ·RejectedExecutionHandler：当ThreadPoolExecutor已经关闭或ThreadPoolExecutor已经饱和 时（达到了最大线程池大小且工作队列已满），execute()方法将要调用的Handler。 2.1 FixedThreadPoolFixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads。 123456public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory); } keepAliveTime设置为0L，意味着多余的空闲线程会被立即终止 FixedThreadPool使用无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为 Integer.MAX_VALUE）。使用无界队列作为工作队列会对线程池带来如下影响: 1）当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中 的线程数不会超过corePoolSize。 2）由于1，使用无界队列时maximumPoolSize将是一个无效参数。 3）由于1和2，使用无界队列时keepAliveTime将是一个无效参数。 4）由于使用无界队列，运行中的FixedThreadPool（未执行方法shutdown()或 shutdownNow()）不会拒绝任务（不会调用RejectedExecutionHandler.rejectedExecution方法）。 2.2 SingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); } SingleThreadExecutor的corePoolSize和maximumPoolSize被设置为1。其他参数与 FixedThreadPool相同。SingleThreadExecutor使用无界队列LinkedBlockingQueue作为线程池的工 作队列（队列的容量为Integer.MAX_VALUE）。SingleThreadExecutor使用无界队列作为工作队列 对线程池带来的影响与FixedThreadPool相同. 2.3 CachedThreadPool12345public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); } CachedThreadPool的corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置为 Integer.MAX_VALUE，即maximumPool是无界的。这里把keepAliveTime设置为60L，意味着 CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被 终止。 如果主线程提交任务的速度高于 maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下， CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。","link":"/2021/05/07/Java%E5%B9%B6%E5%8F%91%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80-%E4%B8%8B/"},{"title":"算法题","text":"哈哈 第一部分：四种基本情况 1. 无重复数字的二分查找https://leetcode-cn.com/problems/binary-search/ 123456789101112class Solution { public int search(int[] nums, int target) { int n = nums.length; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r + 1 &gt;&gt; 1; if(nums[mid] &gt; target) r = mid-1; else l = mid; } return nums[l] == target ? l : -1; }} 2. 有重复数字的二分查找第一个位置和最后一个位置https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/ 12345678910111213141516171819202122232425262728class Solution { public int[] searchRange(int[] nums, int target) { int[] res = new int[2]; int n = nums.length; if(n == 0) return new int[]{-1,-1}; //找到第一个出现的位置 int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; if(nums[mid] &lt; target) l = mid+1; else r = mid; } if(nums[l] != target) return new int[]{-1,-1}; else res[0] = l; //找到最后一个出现的位置 l = 0; r = n-1; while(l &lt; r){ int mid = l + r +1 &gt;&gt; 1; if(nums[mid] &gt; target) r = mid-1; else l = mid; } res[1] = l; return res; }} 3. 搜索插入位置https://leetcode-cn.com/problems/search-insert-position/ 12345678910111213141516class Solution { public int searchInsert(int[] nums, int target) { int n = nums.length; //1. 注意如果最后一个数小于target的话，就返回数组长度 if (n == 0 || nums[n-1] &lt; target) return n; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; if(nums[mid] &lt; target) l = mid + 1; else r = mid; } return l; }} 4. x的平方根（只保留整数部分）12345678910111213 class Solution { public int mySqrt(int x) { int l = 0 , r = x; while(l &lt; r){ int mid = l + r + 1 &gt;&gt; 1; if(mid &gt; x / mid) r = mid-1; else l = mid; } return l; }} 5. 寻找重复的数https://leetcode-cn.com/problems/find-the-duplicate-number/ 123456789101112131415161718192021class Solution { public int findDuplicate(int[] nums) { int n = nums.length; //对值的范围进而二分 int l = 0 , r = n-1; while (l &lt; r){ int mid = l+r &gt;&gt;1; //看一下数组中比mid小的数有多少 int count = 0; for (int num : nums){ if (num &lt;= mid) count++; } //比mid小的数大于mid，说明在左边,可能是mid if (count &gt; mid) r = mid; else l = mid+1; } return l; }} 6. 实现Pow(x,n)https://leetcode-cn.com/problems/powx-n/comments/ 12345678910111213class Solution { public double myPow(double x, int n) { double res = 1.0; for(int i = n ; i != 0 ; i /=2){ if(i % 2 != 0) res = res * x; x *= x; } return n &lt; 0 ? 1/res : res; }} 7. 寻找两个排序数组的中位数https://leetcode-cn.com/problems/median-of-two-sorted-arrays/ 1234567891011121314151617181920212223242526class Solution { public double findMedianSortedArrays(int[] nums1, int[] nums2) { int n = nums1.length; int m = nums2.length; int l = (n + m + 1)/2; int r = (n + m + 2)/2; return (getK(nums1, 0 , n-1 , nums2 , 0 , m-1 , l) + getK(nums1 , 0 ,n-1 , nums2 ,0,m-1,r))/2.0; } //从两个正序数组中获取第k大的数 int getK(int[] nums1 , int s1 , int e1 , int[] nums2 , int s2 , int e2 , int k){ int len1 = e1 - s1 + 1; int len2 = e2 - s2 + 1; if(len1 &gt; len2) return getK(nums2 , s2 , e2 , nums1 , s1 , e1 , k); if(len1 == 0) return nums2[s2 + k -1]; if(k == 1) return Math.min(nums1[s1] , nums2[s2]); int i = s1 + Math.min(len1 , k/2)-1; //每次取一半的值 int j = s2 + Math.min(len2 , k/2)-1; //每一轮都将较小的那半组数据舍去 if(nums1[i] &gt; nums2[j]) return getK(nums1 , s1 ,e1 , nums2 ,j+1, e2 ,k-(j-s2+1)); else return getK(nums1, i+1 ,e1 , nums2 , s2 , e2 , k-(i-s1+1)); }} 第二部分：旋转排序数组1. 寻找旋转排序数组中的最小值(无重复值)https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array/ 1234567891011121314class Solution { public int findMin(int[] nums) { int n = nums.length; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; //34512 if(nums[mid] &gt; nums[r]) l = mid+1; else r = mid; } return nums[l]; }} 2. 寻找旋转排序数组中的最小值(有重复值)https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array-ii/ 12345678910111213class Solution { public int findMin(int[] nums) { int n = nums.length; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; if(nums[mid] &gt; nums[r]) l = mid+1; else if(nums[mid] &lt; nums[r]) r = mid; else r--; } return nums[l]; }} 3. 寻找旋转排序数组中的指定值(无重复值)https://leetcode-cn.com/problems/search-in-rotated-sorted-array/ 123456789101112131415161718192021class Solution { public int search(int[] nums, int target) { int n = nums.length; if(n == 0) return -1; int l = 0 , r = n-1; while(l &lt; r){ int mid = l + r &gt;&gt; 1; //34512 if(nums[mid] &gt; nums[r]){ if(target &gt;= nums[l] &amp;&amp; target &lt;= nums[mid]) r = mid; else l = mid+1; }else{ //561234 if(target &gt; nums[mid] &amp;&amp; target &lt;= nums[r]) l = mid+1; else r = mid; } } return nums[l] == target ? l : -1; }} 第三部分：二维矩阵1. 搜索二维矩阵https://leetcode-cn.com/problems/search-a-2d-matrix/ 123456789101112131415class Solution { public boolean searchMatrix(int[][] matrix, int target) { int m = matrix.length; //行数 int n = matrix[0].length; //列数 int l = 0 , r = m *n -1; while(l &lt; r){ int mid = l + r + 1 &gt;&gt; 1; //将一维的数组转换成二维的坐标 if(matrix[mid / n][ mid % n] &gt; target) r = mid-1; else l = mid; } return matrix[l/n][l%n] == target; }} 2. 搜索二维矩阵2https://leetcode-cn.com/problems/search-a-2d-matrix-ii/submissions/ 1234567891011121314class Solution { public boolean searchMatrix(int[][] matrix, int target) { int m = matrix.length; //行数 int n = matrix[0].length; //列数 int i = 0 , j = n-1; while(i &lt;= m-1 &amp;&amp; j &gt;= 0){ if(matrix[i][j] &gt; target) j--; else if(matrix[i][j] &lt; target) i++; else return true; } return false; }} 3. 有序矩阵中第k小的数https://leetcode-cn.com/problems/kth-smallest-element-in-a-sorted-matrix/","link":"/2021/05/06/%E7%AE%97%E6%B3%95%E9%A2%98/"},{"title":"JVM（一）内存区域和对象详解","text":"Java是一门可以跨平台的语言，主要就是通过Java虚拟机来实现的: 编译器将Java文件编译为Java字节码文件（.class），接下来JVM对字节码文件进行解释，翻译成特定底层平台匹配的机器指令(win/linux/mac)并运行。 Java内存区域Java虚拟机定义了若干程序运行时的数据区，分为线程私有和公有的: 运行时数据区程序计数器程序计数器（Program Counter Register）也被称为PC寄存器，是一块较小的内存空间。 可以看作是当前线程所执行的字节码的行号指示器，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 线程私有的，在任意时刻，一条 Java 虚拟机线程只会执行一个方法的代码，这个正在被线程执行的方法称为该线程的当前方法。 程序计数器是唯一一个在虚拟机规范中没有规定OutOfMemoryError的区域 虚拟机栈Java虚拟机栈（Java Virtual Machine Stack）也是线程私有的，它的生命周期与线程相同。 每个方法被执行的时候，Java虚拟机都会同步创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息。每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种Java虚拟机基本数据类型（boolean、byte、char、short、int、 float、long、double）、对象引用（reference类型，它并不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress 类型（指向了一条字节码指令的地址）。 这些数据类型在局部变量表中的存储空间以局部变量槽（Slot）来表示，其中64位长度的long和 double类型的数据会占用两个变量槽，其余的数据类型只占用一个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定 的，在方法运行期间不会改变局部变量表的大小。 虚拟机栈会发生以下两种异常： 如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量时，Java 虚拟机将会抛出一个 StackOverflowError 异常。 如果 Java 虚拟机栈可以动态扩展，并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成扩展，或者在建立新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个 OutOfMemoryError 异常。 本地方法栈地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别只是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的本地（Native）方法服务。 会发生的异常和虚拟机栈相同 Java堆Java堆（Java Heap）是虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，Java里“几乎”所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的内存区域，因此一些资料中它也被称作“GC堆”（Garbage Collected Heap，）。从回收内存的角度看，由于现代垃圾收集器大部分都是基于分代收集理论设计的，所以Java堆中经常会出现“新生代”“老年代”“永久代”“Eden空间”“From Survivor空间”“To Survivor空间”等名词，需要注意的是这些区域划分仅仅是一部分垃圾收集器的共同特性或者说设计风格而已，而非某个Java虚拟机具体实现的固有内存布局，更不是《Java虚拟机规范》里对Java堆的进一步细致划分。 如果从分配内存的角度看，所有线程共享的Java堆中可以划分出多个线程私有的分配缓冲区 （Thread Local Allocation Buffer，TLAB），以提升对象分配时的效率。不过无论从什么角度，无论如何划分，都不会改变Java堆中存储内容的共性，无论是哪个区域，存储的都只能是对象的实例，将Java 堆细分的目的只是为了更好地回收内存，或者更快地分配内存。 方法区方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。 这区域的内存回收目标主要是针对常量池的回收和对类型的卸载 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池表（Constant Pool Table），用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 Class文件经过类加载器加载后，之前Class文件常量池的内容会存放到方法区的运行时常量池，需要注意的是Class文件常量池的符号引用会转变直接引用存入运行时常量池。 运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量 一定只有编译期才能产生，也就是说，并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可以将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。 直接内存在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区 （Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的 DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了 在Java堆和Native堆中来回复制数据。 JDK的内存演变 JDK1.6时期和我们上面讲的JVM内存区域是一致的： JDK1.7时发生了一些变化，将字符串常量池、静态变量，存放在堆上 在JDK1.8时彻底干掉了方法区，而在直接内存中划出一块区域作为元空间，运行时常量池、类常量池都移动到元空间。 思考一下，为什么使用元空间替换永久代？ 表面上看是为了避免OOM异常。因为通常使用PermSize和MaxPermSize设置永久代的大小就决定了永久代的上限，但是不是总能知道应该设置为多大合适, 如果使用默认值很容易遇到OOM错误。 当使用元空间时，可以加载多少类的元数据就不再由MaxPermSize控制, 而由系统的实际可用空间来控制。 更深层的原因还是要合并HotSpot和JRockit的代码，JRockit从来没有所谓的永久代，也不需要开发运维人员设置永久代的大小，但是运行良好。同时也不用担心运行性能问题了,在覆盖到的测试中, 程序启动和运行速度降低不超过1%，但是这点性能损失换来了更大的安全保障。 哪些地方会发生OOM 堆内存不足是最常见的OOM原因之一，抛出的错误信息是“java.lang.OutOfMemoryError:Java heap space”，原因可能千奇百怪，例如，可能存在内存泄漏问题；也很有可能就是堆的大小不合理，比如我们要处理比较可观的数据量，但是没有显式指定JVM堆大小或者指定数值偏小；或者出现JVM处理引用不及时，导致堆积起来，内存无法释放等。 对于Java虚拟机栈和本地方法栈，这里要稍微复杂一点。如果我们写一段程序不断的进行递归调用，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM实际会抛出StackOverFlowError；当然，如果JVM试图去扩展栈空间的的时候失败，则会抛出OutOfMemoryError。 对于老版本的Oracle JDK，因为永久代的大小是有限的，并且JVM对永久代垃圾回收（如，常量池回收、卸载不再需要的类型）非常不积极，所以当我们不断添加新类型的时候，永久代出现OutOfMemoryError也非常多见，尤其是在运行时存在大量动态类型生成的场合；类似Intern字符串缓存占用太多空间，也会导致OOM问题。对应的异常信息，会标记出来和永久代相关：“java.lang.OutOfMemoryError: PermGen space”。随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的OOM有所改观，出现OOM，异常信息则变成了：“java.lang.OutOfMemoryError: Metaspace”。 直接内存不足，也会导致OOM。 对象的创建都是在堆上吗我注意到有一些观点，认为通过逃逸分析，JVM会在栈上分配那些不会逃逸的对象，这在理论上是可行的，但是取决于JVM设计者的选择。据我所知，Oracle Hotspot JVM中并未这么做，这一点在逃逸分析相关的文档里已经说明，所以可以明确所有的对象实例都是创建在堆上。 目前很多书籍还是基于JDK 7以前的版本，JDK已经发生了很大变化，Intern字符串的缓存和静态变量曾经都被分配在永久代上，而永久代已经被元数据区取代。但是，Intern字符串缓存和静态变量并不是被转移到元数据区，而是直接在堆上分配，所以这一点同样符合前面一点的结论：对象实例都是分配在堆上。 字符串常量池的底层原理字符串常量池是全局的，JVM 中独此一份，因此也称为全局字符串常量池，在 jdk1.7（含）之后是在堆内存之中，存储的是字符串对象的引用，字符串实例是在堆中； 在HotSpot VM里实现线程池功能的是一个StringTable类，它是一个Hash表，默认值大小长度是1009；这个StringTable在每个HotSpot VM的实例只有一份，被所有的类共享。字符串常量由一个一个字符组成，放在了StringTable上。 12345678String str1 = &quot;图解Java&quot;; //先到常量池中查询有没有`&quot;图解Java&quot;`字符串的引用，如果没有，则会在`Java堆`上创建`&quot;图解Java&quot;`字符串，在常量池中存储字符串的地址，`str1`则指向字符串常量池的地址String str2 = new String(&quot;图解Java&quot;);//直接在Java堆中创建对象。`str2`指向堆中的地址。System.out.println(str1 == str2); //falseString str3 = &quot;图解Java&quot;; //str3发现字符串常量池中已经有了`&quot;图解Java&quot;`字符串的引用，则直接返回，不会创建新的对象System.out.println(str1 == str3); //true JVM中除了字符串常量池，8种基本数据类型中除了两种浮点类型剩余的6种基本数据类型的包装类，都使用了缓冲池技术，但是 Byte、Short、Integer、Long、Character 这5种整型的包装类也只是在对应值在 [-128,127] 时才会使用缓冲池，超出此范围仍然会去创建新的对象。 Java对象详解创建对象的4种方式 new 关键字： 在方法区的常量池中查看是否有new 后面参数（也就是类名）的符号引用，并检查是否有类的加载信息也就是是否被加载解析和初始化过。如果已经加载过了就不在加载，否则执行类的加载全过程。 给实例分配内存：此内存中存放对象自己的实例变量和从父类继承过来的实例变量（即使这些从超类继承过来的实例变量有可能被隐藏也会被分配空间），同时这些实例变量被赋予默认值（零值）； 调用构造函数，初始化成员字段：在Java对象初始化过程中，主要涉及三种执行对象初始化的结构，分别是实例变量初始化、实例代码块初始化以及构造函数初始化； user对象指向分配的内存空间： 注意：new操作不是原子操作，b和c的顺序可能会调换。 clone方法创建对象： 要想让一个对象支持clone，必须让这个对象对应的类实现Cloneable接口（标识接口），同时此类中也要重写clone方法 clone()方法是属于Object类的，clone是在堆内存中用二进制的方式进行拷贝，重新分配给对象一块内存 反射创建对象： 获取类的Class对象实例 1234获取方式如下：Class.forName(&quot;类全路径&quot;);类名.class; 如：Animal.class;对象名.getClass(); 通过反射创建类对象的实例对象 1Class.newInstance()：调用无参的构造方法，必需确保类中有无参数的可见的构造函数，否则将会抛出异常； 强制转换成用户所需类型 Java 反射机制是指在程序运行时，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性。这种动态的获取信息以及动态调用对象的方法的功能称为java 的反射机制。 反射机制很重要的一点就是“运行时”，其使得我们可以在程序运行时加载、探索以及使用编译期间完全未知的 .class 文件。换句话说，Java 程序可以加载一个运行时才得知名称的 .class 文件，然后获悉其完整构造，并生成其对象实体、或对其 fields（变量）设值、或调用其 methods（方法） 反序列化创建对象 Java中要序列化的类必须实现Serializable接口； 所有可在网络上传输的对象都必须是可序列化的；如RMI（remote method invoke，即远程方法调用），传入的参数或返回的对象都是可序列化的，否则会出错； 所有需要保存到磁盘的java对象都必须是可序列化的；通常建议：程序创建的每个JavaBean类都实现Serializeable接口； New对象创建过程我们以虚拟机遇到一个new指令开始： 首先检查这个指令的参数是否能在常量池中定位到一个类的符号引用 检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，就先执行相应的类加载过程 类加载检查通过后，接下来虚拟机将为新生对象分配内存。 内存分配有两种方式，指针碰撞（Bump The Pointer）、空闲列表（Free List） 指针碰撞：假设Java堆中内存是绝对规整的，所有被使用过的内存都被放在一边，空闲的内存被放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间方向挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞” 如果Java堆中的内存并不是规整的，已被使用的内存和空闲的内存相互交错在一起，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表” 两种方式的选择由Java堆是否规整决定 Java堆规整由所采用的垃圾收集器是否带有空间压缩整理（Compact）的能力决定 内存分配完成之后，虚拟机将分配到的内存空间（但不包括对象头）都初始化为零值。 设置对象头，请求头里包含了对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。 从虚拟机角度来看，设置完对象头信息以后初始化就已经完成了，但是对于Java程序而言，new指令之后会接着执行 ()方法，对对象进行初始化，这样一个真正可用的对象才算完全被构造出来。 分配对象内存的时候如何保证线程安全分配内存线程安全问题：对象创建在虚拟机中是非常频繁的行为，即使仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。 线程安全问题有两种解可选方案： 一种是对分配内存空间的动作进行同步处理——实际上虚拟机是采用CAS配上失败重试的方式保证更新操作的原子性 另外一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer，TLAB），哪个线程要分配内存，就在哪个线程的本地缓冲区中分配，只有本地缓冲区用完了，分配新的缓存区时才需要同步锁定。 对象的内存布局在HotSpot虚拟机里，对象在堆内存中的存储布局可以划分为三个部分：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding） 在64位的HotSpot虚拟机中，如对象未被同步锁锁定的状态下，Mark Word的64个比特存储空间中的31个比特用于存储对象哈希码，4个比特用于存储对象分代年龄，2个比特用于存储锁标志位，在其他状态（轻量级锁、重量级锁、偏向锁）下对象的存储内容变化如图示。 对象头的另外一部分是类型指针，即对象指向它的类型元数据的指针，Java虚拟机通过这个指针来确定该对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，查找对象的元数据信息并不一定要经过对象本身， 如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是如果数组的长度是不确定的，将无法通过元数据中的信息推断出数组的大小。 对象的访问定位Java程序会通过栈上的reference数据来操作堆上的具体对象。由于reference类型在《Java虚拟机规范》里面只规定了它是一个指向对象的引用，并没有定义这个引用应该通过什么方式去定位、访问到堆中对象的具体位置，所以对象访问方式也是由虚拟机实现而定的，主流的访问方式主要有使用句柄和直接指针两种： 如果使用句柄访问的话，Java堆中将可能会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自具体的地址信息，其结构如图所示： 如果使用直接指针访问的话，Java堆中对象的内存布局就必须考虑如何放置访问类型数据的相关信息，reference中存储的直接就是对象地址，如果只是访问对象本身的话，就不需要多一次间接访问的开销，如图所示： 这两种对象访问方式各有优势，使用句柄来访问的最大好处就是reference中存储的是稳定句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要被修改。 使用直接指针来访问最大的好处就是速度更快，它节省了一次指针定位的时间开销，由于对象访问在Java中非常频繁，因此这类开销积少成多也是一项极为可观的执行成本。 HotSpot虚拟机主要使用直接指针来进行对象访问。 总结：","link":"/2021/05/10/JVM%EF%BC%88%E4%B8%80%EF%BC%89%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%92%8C%E5%AF%B9%E8%B1%A1%E8%AF%A6%E8%A7%A3/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/05/06/hello-world/"},{"title":"测试图上传","text":"","link":"/2021/05/06/%E6%B5%8B%E8%AF%95%E5%9B%BE%E4%B8%8A%E4%BC%A0/"}],"tags":[{"name":"Java并发","slug":"Java并发","link":"/tags/Java%E5%B9%B6%E5%8F%91/"},{"name":"算法题","slug":"算法题","link":"/tags/%E7%AE%97%E6%B3%95%E9%A2%98/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"}],"categories":[{"name":"技术","slug":"技术","link":"/categories/%E6%8A%80%E6%9C%AF/"}]}